{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nimport pandas as pd\\nimport numpy as np\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nimport pandas as pd\\nimport numpy as np\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.model_selection import cross_val_score\\nfrom numpy import average\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nimport itertools\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.model_selection import cross_val_score\\nfrom numpy import average\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nimport itertools\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import average\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"randomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"randomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Rf_list\";\n",
       "                var nbb_formatted_code = \"# Rf_list\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rf_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2.Read dataset\n",
    " ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 19)\n",
      "(185843, 2)\n",
      "(169024, 20)\n",
      "(56542, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"# read the data set\\nx_original = pd.read_csv(\\\"../../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\\n\\ny_original = pd.read_csv(\\\"../../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\\n\\ndata = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\\n\\n\\n\\n# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\\n\\ndata = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"# read the data set\\nx_original = pd.read_csv(\\\"../../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\\n\\ny_original = pd.read_csv(\\\"../../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\\n\\ndata = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\\n\\n\\n# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\\n\\ndata = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the data set\n",
    "x_original = pd.read_csv(\"../../../dataset/XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)\n",
    "\n",
    "y_original = pd.read_csv(\"../../../dataset/TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)\n",
    "\n",
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 17331 38166\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_formatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_formatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_formatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17131, 1: 17131, 0: 17131})\n",
      "17131 17131 17131\n",
      "(51393, 12) (51393,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTE(random_state=randomseed, sampling_strategy=\\\"minority\\\")\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTE(random_state=randomseed, sampling_strategy=\\\"minority\\\")\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "randomseed = 42\n",
    "\n",
    "sm = SMOTE(random_state=randomseed, sampling_strategy=\"minority\")\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Train and Generate models \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"weakmodles = []\\nestimators = []\";\n",
       "                var nbb_formatted_code = \"weakmodles = []\\nestimators = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles = []\n",
    "estimators = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"def changelist(strlist):\\n    test_list = (strlist).replace(\\\"[\\\", \\\"\\\").replace(\\\"]\\\", \\\"\\\").replace(\\\"'\\\", \\\"\\\").split(\\\",\\\")\\n    test_list = [int(i) for i in test_list]\\n    return test_list\";\n",
       "                var nbb_formatted_code = \"def changelist(strlist):\\n    test_list = (strlist).replace(\\\"[\\\", \\\"\\\").replace(\\\"]\\\", \\\"\\\").replace(\\\"'\\\", \\\"\\\").split(\\\",\\\")\\n    test_list = [int(i) for i in test_list]\\n    return test_list\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def changelist(strlist):\n",
    "    test_list = (strlist).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\",\")\n",
    "    test_list = [int(i) for i in test_list]\n",
    "    return test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"rf_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=150,\\n    max_depth=30,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\n\\nrf_12_pip = make_pipeline(ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11]), rf_12)\\n\\nxgb_model_12 = xgb.XGBClassifier(random_state=0, max_depth=8, n_estimators=20)\\nxgb_model_12_pip = make_pipeline(\\n    ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11]), xgb_model_12\\n)\\n\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.naive_bayes import GaussianNB\\n\\n# scv_12 = svmgpu(\\n#     C=100,\\n#     cache_size=None,\\n#     class_weight={},\\n#     coef0=0.0,\\n#     decision_function_shape=\\\"ovo\\\",\\n#     degree=3,\\n#     gamma=0.1,\\n#     gpu_id=0,\\n#     kernel=\\\"linear\\\",\\n#     max_iter=-1,\\n#     max_mem_size=-1,\\n#     n_jobs=-1,\\n#     probability=True,\\n#     random_state=None,\\n#     shrinking=False,\\n#     tol=0.001,\\n#     verbose=False,\\n# )\";\n",
       "                var nbb_formatted_code = \"rf_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=150,\\n    max_depth=30,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\n\\nrf_12_pip = make_pipeline(ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11]), rf_12)\\n\\nxgb_model_12 = xgb.XGBClassifier(random_state=0, max_depth=8, n_estimators=20)\\nxgb_model_12_pip = make_pipeline(\\n    ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11]), xgb_model_12\\n)\\n\\n\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.naive_bayes import GaussianNB\\n\\n# scv_12 = svmgpu(\\n#     C=100,\\n#     cache_size=None,\\n#     class_weight={},\\n#     coef0=0.0,\\n#     decision_function_shape=\\\"ovo\\\",\\n#     degree=3,\\n#     gamma=0.1,\\n#     gpu_id=0,\\n#     kernel=\\\"linear\\\",\\n#     max_iter=-1,\\n#     max_mem_size=-1,\\n#     n_jobs=-1,\\n#     probability=True,\\n#     random_state=None,\\n#     shrinking=False,\\n#     tol=0.001,\\n#     verbose=False,\\n# )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_12 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=150,\n",
    "    max_depth=30,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "rf_12_pip = make_pipeline(ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11]), rf_12)\n",
    "\n",
    "xgb_model_12 = xgb.XGBClassifier(random_state=0, max_depth=8, n_estimators=20)\n",
    "xgb_model_12_pip = make_pipeline(\n",
    "    ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11]), xgb_model_12\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# scv_12 = svmgpu(\n",
    "#     C=100,\n",
    "#     cache_size=None,\n",
    "#     class_weight={},\n",
    "#     coef0=0.0,\n",
    "#     decision_function_shape=\"ovo\",\n",
    "#     degree=3,\n",
    "#     gamma=0.1,\n",
    "#     gpu_id=0,\n",
    "#     kernel=\"linear\",\n",
    "#     max_iter=-1,\n",
    "#     max_mem_size=-1,\n",
    "#     n_jobs=-1,\n",
    "#     probability=True,\n",
    "#     random_state=None,\n",
    "#     shrinking=False,\n",
    "#     tol=0.001,\n",
    "#     verbose=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Train ensemble modles\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1.CIM\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"weakmodles = [rf_12, xgb_model_12,rf_12_pip,xgb_model_12_pip]\\nestimators = [(\\\"rf_12\\\", rf_12), (\\\"xgb_model_12\\\", xgb_model_12),(\\\"rf_12_pip\\\",rf_12_pip),(\\\"xgb_model_12_pip\\\",xgb_model_12_pip)]\";\n",
       "                var nbb_formatted_code = \"weakmodles = [rf_12, xgb_model_12, rf_12_pip, xgb_model_12_pip]\\nestimators = [\\n    (\\\"rf_12\\\", rf_12),\\n    (\\\"xgb_model_12\\\", xgb_model_12),\\n    (\\\"rf_12_pip\\\", rf_12_pip),\\n    (\\\"xgb_model_12_pip\\\", xgb_model_12_pip),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles = [rf_12, xgb_model_12, rf_12_pip, xgb_model_12_pip]\n",
    "estimators = [\n",
    "    (\"rf_12\", rf_12),\n",
    "    (\"xgb_model_12\", xgb_model_12),\n",
    "    (\"rf_12_pip\", rf_12_pip),\n",
    "    (\"xgb_model_12_pip\", xgb_model_12_pip),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"acclist = []\\npredprobalist = []\\npredprobalist2 = []\\nconfmatrxlist = []\\nypredconfprob_all = []\";\n",
       "                var nbb_formatted_code = \"acclist = []\\npredprobalist = []\\npredprobalist2 = []\\nconfmatrxlist = []\\nypredconfprob_all = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acclist = []\n",
    "predprobalist = []\n",
    "predprobalist2 = []\n",
    "confmatrxlist = []\n",
    "ypredconfprob_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0.725\n",
      "0.7166666666666667\n",
      "0.73\n",
      "0.7316666666666667\n",
      "final cim ==== >\n",
      "0.73\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"counter = 0\\nfor f in weakmodles:\\n\\n    print(counter)\\n    counter = counter + 1\\n\\n    rfclf = f\\n    rfclf.fit(xtrain, ytrain)\\n    ypred = rfclf.predict(xtest)\\n    ypredprob = rfclf.predict_proba(xtest)\\n\\n    accuracy = m.accuracy_score(ytest, ypred)\\n    acclist.append(accuracy)\\n    predprobalist.append(ypredprob)\\n    predprobalist2.append(ypred)\\n\\n    confmat = m.confusion_matrix(ytest, ypred)\\n    confmatrxlist.append(confmat)\\n\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n\\ncimc2 = np.zeros((ytest.shape[0], 3))\\n# # for each classifier\\nfor j in range(len(weakmodles)):\\n    #     #for each data point\\n    cimc = []\\n    for i in range(ytest.shape[0]):\\n        # print(i,ypredconfprob_all[j],predprobalist[j][i])\\n\\n        c1 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][0])\\n        c2 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][1])\\n        c3 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][2])\\n\\n        # print([c1,c2,c3])\\n        cimc.append([c1, c2, c3])\\n\\n    cimc = np.array(cimc)\\n    ypred2 = np.argmax(cimc, axis=1)\\n    print((m.accuracy_score(ytest, ypred2)))\\n    cimc2 = cimc2 + cimc\\n\\nprint(\\\"final cim ==== >\\\")\\ncimc2 = np.array(cimc2)\\nypred3 = np.argmax(cimc2, axis=1)\\nprint((m.accuracy_score(ytest, ypred3)))\";\n",
       "                var nbb_formatted_code = \"counter = 0\\nfor f in weakmodles:\\n\\n    print(counter)\\n    counter = counter + 1\\n\\n    rfclf = f\\n    rfclf.fit(xtrain, ytrain)\\n    ypred = rfclf.predict(xtest)\\n    ypredprob = rfclf.predict_proba(xtest)\\n\\n    accuracy = m.accuracy_score(ytest, ypred)\\n    acclist.append(accuracy)\\n    predprobalist.append(ypredprob)\\n    predprobalist2.append(ypred)\\n\\n    confmat = m.confusion_matrix(ytest, ypred)\\n    confmatrxlist.append(confmat)\\n\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n\\ncimc2 = np.zeros((ytest.shape[0], 3))\\n# # for each classifier\\nfor j in range(len(weakmodles)):\\n    #     #for each data point\\n    cimc = []\\n    for i in range(ytest.shape[0]):\\n        # print(i,ypredconfprob_all[j],predprobalist[j][i])\\n\\n        c1 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][0])\\n        c2 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][1])\\n        c3 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][2])\\n\\n        # print([c1,c2,c3])\\n        cimc.append([c1, c2, c3])\\n\\n    cimc = np.array(cimc)\\n    ypred2 = np.argmax(cimc, axis=1)\\n    print((m.accuracy_score(ytest, ypred2)))\\n    cimc2 = cimc2 + cimc\\n\\nprint(\\\"final cim ==== >\\\")\\ncimc2 = np.array(cimc2)\\nypred3 = np.argmax(cimc2, axis=1)\\nprint((m.accuracy_score(ytest, ypred3)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = 0\n",
    "for f in weakmodles:\n",
    "\n",
    "    print(counter)\n",
    "    counter = counter + 1\n",
    "\n",
    "    rfclf = f\n",
    "    rfclf.fit(xtrain, ytrain)\n",
    "    ypred = rfclf.predict(xtest)\n",
    "    ypredprob = rfclf.predict_proba(xtest)\n",
    "\n",
    "    accuracy = m.accuracy_score(ytest, ypred)\n",
    "    acclist.append(accuracy)\n",
    "    predprobalist.append(ypredprob)\n",
    "    predprobalist2.append(ypred)\n",
    "\n",
    "    confmat = m.confusion_matrix(ytest, ypred)\n",
    "    confmatrxlist.append(confmat)\n",
    "\n",
    "    confsumh = np.sum(confmat, axis=1)\n",
    "    propconfmat = confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\n",
    "    ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "\n",
    "cimc2 = np.zeros((ytest.shape[0], 3))\n",
    "# # for each classifier\n",
    "for j in range(len(weakmodles)):\n",
    "    #     #for each data point\n",
    "    cimc = []\n",
    "    for i in range(ytest.shape[0]):\n",
    "        # print(i,ypredconfprob_all[j],predprobalist[j][i])\n",
    "\n",
    "        c1 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][0])\n",
    "        c2 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][1])\n",
    "        c3 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][2])\n",
    "\n",
    "        # print([c1,c2,c3])\n",
    "        cimc.append([c1, c2, c3])\n",
    "\n",
    "    cimc = np.array(cimc)\n",
    "    ypred2 = np.argmax(cimc, axis=1)\n",
    "    print((m.accuracy_score(ytest, ypred2)))\n",
    "    cimc2 = cimc2 + cimc\n",
    "\n",
    "print(\"final cim ==== >\")\n",
    "cimc2 = np.array(cimc2)\n",
    "ypred3 = np.argmax(cimc2, axis=1)\n",
    "print((m.accuracy_score(ytest, ypred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final cim ==== >\n",
      "0.73\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"print(\\\"final cim ==== >\\\")\\ncimc2 = np.array(cimc2)\\nypred3 = np.argmax(cimc2, axis=1)\\nprint((m.accuracy_score(ytest, ypred3)))\";\n",
       "                var nbb_formatted_code = \"print(\\\"final cim ==== >\\\")\\ncimc2 = np.array(cimc2)\\nypred3 = np.argmax(cimc2, axis=1)\\nprint((m.accuracy_score(ytest, ypred3)))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"final cim ==== >\")\n",
    "cimc2 = np.array(cimc2)\n",
    "ypred3 = np.argmax(cimc2, axis=1)\n",
    "print((m.accuracy_score(ytest, ypred3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>152</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          152           48         0\n",
       "Prediabetes      60          120        20\n",
       "diabetes          4           30       166"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"confmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred3),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"confmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred3),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred3),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       200\n",
      "           1       0.61      0.60      0.60       200\n",
      "           2       0.89      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"print(m.classification_report(ytest, ypred3))\";\n",
       "                var nbb_formatted_code = \"print(m.classification_report(ytest, ypred3))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(m.classification_report(ytest, ypred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross val\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "0\n",
      "0.7737354085603113\n",
      "0.7795719844357977\n",
      "0.7702334630350195\n",
      "0.7791828793774319\n",
      "final cim ==== >\n",
      "0.7799610894941634\n",
      "1\n",
      "0.7819066147859922\n",
      "0.7801556420233463\n",
      "0.7671206225680934\n",
      "0.7708171206225681\n",
      "final cim ==== >\n",
      "0.7836575875486381\n",
      "2\n",
      "0.7852140077821012\n",
      "0.791828793774319\n",
      "0.7735408560311284\n",
      "0.7885214007782101\n",
      "final cim ==== >\n",
      "0.7908560311284046\n",
      "3\n",
      "0.7736913796458454\n",
      "0.7795290912628916\n",
      "0.7676590776415645\n",
      "0.7711617046117922\n",
      "final cim ==== >\n",
      "0.7779723681650127\n",
      "4\n",
      "0.7880910683012259\n",
      "0.7915936952714536\n",
      "0.7771940066160732\n",
      "0.7810858143607706\n",
      "final cim ==== >\n",
      "0.78945320101187\n",
      "5\n",
      "0.7880910683012259\n",
      "0.7927612375948628\n",
      "0.772913018096906\n",
      "0.7803074528118311\n",
      "final cim ==== >\n",
      "0.78945320101187\n",
      "6\n",
      "0.778945320101187\n",
      "0.7793345008756567\n",
      "0.766880716092625\n",
      "0.7752481027437245\n",
      "final cim ==== >\n",
      "0.7773885970033081\n",
      "7\n",
      "0.7787507297139521\n",
      "0.7803074528118311\n",
      "0.7731076084841408\n",
      "0.7773885970033081\n",
      "final cim ==== >\n",
      "0.7816695855224752\n",
      "8\n",
      "0.7840046701692936\n",
      "0.7898423817863398\n",
      "0.7699941622883829\n",
      "0.7832263086203541\n",
      "final cim ==== >\n",
      "0.7875072971395213\n",
      "9\n",
      "0.7859505740416424\n",
      "0.7927612375948628\n",
      "0.7727184277096711\n",
      "0.7915936952714536\n",
      "final cim ==== >\n",
      "0.7884802490756957\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(xtrain)\\n\\nprint(kf)\\n\\ndata_cv = []\\ncv_acc = []\\ncv_precision = []\\ncv_recall = []\\ncv_f1 = []\\n\\ncounter = 0\\nfor train_index, test_index in kf.split(xtrain):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    cv_xtrain, cv_xtest = xtrain[train_index], xtrain[test_index]\\n    cv_ytrain, cv_ytest = ytrain[train_index], ytrain[test_index]\\n\\n    acclist = []\\n    predprobalist = []\\n    predprobalist2 = []\\n    confmatrxlist = []\\n    ypredconfprob_all = []\\n\\n    print(counter)\\n    counter = counter + 1\\n\\n    for f in weakmodles:\\n\\n        rfclf = f\\n        rfclf.fit(cv_xtrain, cv_ytrain)\\n        ypred = rfclf.predict(cv_xtest)\\n        ypredprob = rfclf.predict_proba(cv_xtest)\\n\\n        accuracy = m.accuracy_score(cv_ytest, ypred)\\n        acclist.append(accuracy)\\n        predprobalist.append(ypredprob)\\n        predprobalist2.append(ypred)\\n\\n        confmat = m.confusion_matrix(cv_ytest, ypred)\\n        confmatrxlist.append(confmat)\\n\\n        confsumh = np.sum(confmat, axis=1)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    cimc2 = np.zeros((cv_ytest.shape[0], 3))\\n    # # for each classifier\\n    for j in range(len(weakmodles)):\\n        #     #for each data point\\n        cimc = []\\n        for i in range(cv_ytest.shape[0]):\\n            # print(i,ypredconfprob_all[j],predprobalist[j][i])\\n\\n            c1 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][0])\\n            c2 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][1])\\n            c3 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][2])\\n\\n            # print([c1,c2,c3])\\n            cimc.append([c1, c2, c3])\\n\\n        cimc = np.array(cimc)\\n        ypred2 = np.argmax(cimc, axis=1)\\n        print((m.accuracy_score(cv_ytest, ypred2)))\\n        cimc2 = cimc2 + cimc\\n\\n    print(\\\"final cim ==== >\\\")\\n    cimc2 = np.array(cimc2)\\n    ypred3 = np.argmax(cimc2, axis=1)\\n    print((m.accuracy_score(cv_ytest, ypred3)))\\n\\n    cv_acc.append((m.accuracy_score(cv_ytest, ypred3)))\\n    cv_precision.append((m.precision_score(cv_ytest, ypred3, average=\\\"weighted\\\")))\\n    cv_recall.append((m.recall_score(cv_ytest, ypred3, average=\\\"weighted\\\")))\\n    cv_f1.append((m.f1_score(cv_ytest, ypred3, average=\\\"weighted\\\")))\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(xtrain)\\n\\nprint(kf)\\n\\ndata_cv = []\\ncv_acc = []\\ncv_precision = []\\ncv_recall = []\\ncv_f1 = []\\n\\ncounter = 0\\nfor train_index, test_index in kf.split(xtrain):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    cv_xtrain, cv_xtest = xtrain[train_index], xtrain[test_index]\\n    cv_ytrain, cv_ytest = ytrain[train_index], ytrain[test_index]\\n\\n    acclist = []\\n    predprobalist = []\\n    predprobalist2 = []\\n    confmatrxlist = []\\n    ypredconfprob_all = []\\n\\n    print(counter)\\n    counter = counter + 1\\n\\n    for f in weakmodles:\\n\\n        rfclf = f\\n        rfclf.fit(cv_xtrain, cv_ytrain)\\n        ypred = rfclf.predict(cv_xtest)\\n        ypredprob = rfclf.predict_proba(cv_xtest)\\n\\n        accuracy = m.accuracy_score(cv_ytest, ypred)\\n        acclist.append(accuracy)\\n        predprobalist.append(ypredprob)\\n        predprobalist2.append(ypred)\\n\\n        confmat = m.confusion_matrix(cv_ytest, ypred)\\n        confmatrxlist.append(confmat)\\n\\n        confsumh = np.sum(confmat, axis=1)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    cimc2 = np.zeros((cv_ytest.shape[0], 3))\\n    # # for each classifier\\n    for j in range(len(weakmodles)):\\n        #     #for each data point\\n        cimc = []\\n        for i in range(cv_ytest.shape[0]):\\n            # print(i,ypredconfprob_all[j],predprobalist[j][i])\\n\\n            c1 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][0])\\n            c2 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][1])\\n            c3 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][2])\\n\\n            # print([c1,c2,c3])\\n            cimc.append([c1, c2, c3])\\n\\n        cimc = np.array(cimc)\\n        ypred2 = np.argmax(cimc, axis=1)\\n        print((m.accuracy_score(cv_ytest, ypred2)))\\n        cimc2 = cimc2 + cimc\\n\\n    print(\\\"final cim ==== >\\\")\\n    cimc2 = np.array(cimc2)\\n    ypred3 = np.argmax(cimc2, axis=1)\\n    print((m.accuracy_score(cv_ytest, ypred3)))\\n\\n    cv_acc.append((m.accuracy_score(cv_ytest, ypred3)))\\n    cv_precision.append((m.precision_score(cv_ytest, ypred3, average=\\\"weighted\\\")))\\n    cv_recall.append((m.recall_score(cv_ytest, ypred3, average=\\\"weighted\\\")))\\n    cv_f1.append((m.f1_score(cv_ytest, ypred3, average=\\\"weighted\\\")))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\n",
    "kf.get_n_splits(xtrain)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "data_cv = []\n",
    "cv_acc = []\n",
    "cv_precision = []\n",
    "cv_recall = []\n",
    "cv_f1 = []\n",
    "\n",
    "counter = 0\n",
    "for train_index, test_index in kf.split(xtrain):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    cv_xtrain, cv_xtest = xtrain[train_index], xtrain[test_index]\n",
    "    cv_ytrain, cv_ytest = ytrain[train_index], ytrain[test_index]\n",
    "\n",
    "    acclist = []\n",
    "    predprobalist = []\n",
    "    predprobalist2 = []\n",
    "    confmatrxlist = []\n",
    "    ypredconfprob_all = []\n",
    "\n",
    "    print(counter)\n",
    "    counter = counter + 1\n",
    "\n",
    "    for f in weakmodles:\n",
    "\n",
    "        rfclf = f\n",
    "        rfclf.fit(cv_xtrain, cv_ytrain)\n",
    "        ypred = rfclf.predict(cv_xtest)\n",
    "        ypredprob = rfclf.predict_proba(cv_xtest)\n",
    "\n",
    "        accuracy = m.accuracy_score(cv_ytest, ypred)\n",
    "        acclist.append(accuracy)\n",
    "        predprobalist.append(ypredprob)\n",
    "        predprobalist2.append(ypred)\n",
    "\n",
    "        confmat = m.confusion_matrix(cv_ytest, ypred)\n",
    "        confmatrxlist.append(confmat)\n",
    "\n",
    "        confsumh = np.sum(confmat, axis=1)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "    cimc2 = np.zeros((cv_ytest.shape[0], 3))\n",
    "    # # for each classifier\n",
    "    for j in range(len(weakmodles)):\n",
    "        #     #for each data point\n",
    "        cimc = []\n",
    "        for i in range(cv_ytest.shape[0]):\n",
    "            # print(i,ypredconfprob_all[j],predprobalist[j][i])\n",
    "\n",
    "            c1 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][0])\n",
    "            c2 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][1])\n",
    "            c3 = np.sum(predprobalist[j][i] * ypredconfprob_all[j][2])\n",
    "\n",
    "            # print([c1,c2,c3])\n",
    "            cimc.append([c1, c2, c3])\n",
    "\n",
    "        cimc = np.array(cimc)\n",
    "        ypred2 = np.argmax(cimc, axis=1)\n",
    "        print((m.accuracy_score(cv_ytest, ypred2)))\n",
    "        cimc2 = cimc2 + cimc\n",
    "\n",
    "    print(\"final cim ==== >\")\n",
    "    cimc2 = np.array(cimc2)\n",
    "    ypred3 = np.argmax(cimc2, axis=1)\n",
    "    print((m.accuracy_score(cv_ytest, ypred3)))\n",
    "\n",
    "    cv_acc.append((m.accuracy_score(cv_ytest, ypred3)))\n",
    "    cv_precision.append((m.precision_score(cv_ytest, ypred3, average=\"weighted\")))\n",
    "    cv_recall.append((m.recall_score(cv_ytest, ypred3, average=\"weighted\")))\n",
    "    cv_f1.append((m.f1_score(cv_ytest, ypred3, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7846399207100959  +/-  0.004864798211224427\n",
      "0.7800153156275351  +/-  0.005099740386223017\n",
      "0.7846399207100959  +/-  0.004864798211224427\n",
      "0.7797836612085387  +/-  0.005349165015689856\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"print(np.mean(cv_acc), \\\" +/- \\\", np.std(cv_acc))\\nprint(np.mean(cv_precision), \\\" +/- \\\", np.std(cv_precision))\\nprint(np.mean(cv_recall), \\\" +/- \\\", np.std(cv_recall))\\nprint(np.mean(cv_f1), \\\" +/- \\\", np.std(cv_f1))\";\n",
       "                var nbb_formatted_code = \"print(np.mean(cv_acc), \\\" +/- \\\", np.std(cv_acc))\\nprint(np.mean(cv_precision), \\\" +/- \\\", np.std(cv_precision))\\nprint(np.mean(cv_recall), \\\" +/- \\\", np.std(cv_recall))\\nprint(np.mean(cv_f1), \\\" +/- \\\", np.std(cv_f1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.mean(cv_acc), \" +/- \", np.std(cv_acc))\n",
    "print(np.mean(cv_precision), \" +/- \", np.std(cv_precision))\n",
    "print(np.mean(cv_recall), \" +/- \", np.std(cv_recall))\n",
    "print(np.mean(cv_f1), \" +/- \", np.std(cv_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7799610894941634,\n",
       " 0.7836575875486381,\n",
       " 0.7908560311284046,\n",
       " 0.7779723681650127,\n",
       " 0.78945320101187,\n",
       " 0.78945320101187,\n",
       " 0.7773885970033081,\n",
       " 0.7816695855224752,\n",
       " 0.7875072971395213,\n",
       " 0.7884802490756957]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 57;\n",
       "                var nbb_unformatted_code = \"cv_acc\";\n",
       "                var nbb_formatted_code = \"cv_acc\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7749645863369719,\n",
       " 0.779856360665907,\n",
       " 0.7867829872294209,\n",
       " 0.7730762379010668,\n",
       " 0.7848578093227923,\n",
       " 0.7844284063039038,\n",
       " 0.772617670326658,\n",
       " 0.7761076936551519,\n",
       " 0.7839013373697553,\n",
       " 0.7835600671637242]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 58;\n",
       "                var nbb_unformatted_code = \"cv_precision\";\n",
       "                var nbb_formatted_code = \"cv_precision\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7799610894941634,\n",
       " 0.7836575875486381,\n",
       " 0.7908560311284046,\n",
       " 0.7779723681650127,\n",
       " 0.78945320101187,\n",
       " 0.78945320101187,\n",
       " 0.7773885970033081,\n",
       " 0.7816695855224752,\n",
       " 0.7875072971395213,\n",
       " 0.7884802490756957]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"cv_recall\";\n",
       "                var nbb_formatted_code = \"cv_recall\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7751509135515129,\n",
       " 0.7789412910213099,\n",
       " 0.7867405504679623,\n",
       " 0.7719863528100721,\n",
       " 0.7853714647214599,\n",
       " 0.7852480405432741,\n",
       " 0.7718285898978403,\n",
       " 0.7766198125236584,\n",
       " 0.7830857027850595,\n",
       " 0.7828638937632374]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"cv_f1\";\n",
       "                var nbb_formatted_code = \"cv_f1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.Stacking approach\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# stacking classifier\\nsclf = StackingClassifier(\\n    classifiers=weakmodles,\\n    verbose=2,\\n    meta_classifier=RandomForestClassifier(n_estimators=500),\\n)\\nsclf.fit(xtrain, ytrain)\\nypred = sclf.predict((xtest))\";\n",
       "                var nbb_formatted_code = \"# stacking classifier\\nsclf = StackingClassifier(\\n    classifiers=weakmodles,\\n    verbose=2,\\n    meta_classifier=RandomForestClassifier(n_estimators=500),\\n)\\nsclf.fit(xtrain, ytrain)\\nypred = sclf.predict((xtest))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stacking classifier\n",
    "sclf = StackingClassifier(\n",
    "    classifiers=weakmodles,\n",
    "    verbose=2,\n",
    "    meta_classifier=RandomForestClassifier(n_estimators=500),\n",
    ")\n",
    "sclf.fit(xtrain, ytrain)\n",
    "ypred = sclf.predict((xtest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7233333333333334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>56</td>\n",
       "      <td>135</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          150           50         0\n",
       "Prediabetes      56          135         9\n",
       "diabetes          4           47       149"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"print(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"print(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.58      0.68      0.62       200\n",
      "           2       0.94      0.74      0.83       200\n",
      "\n",
      "    accuracy                           0.72       600\n",
      "   macro avg       0.75      0.72      0.73       600\n",
      "weighted avg       0.75      0.72      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"print(m.classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(m.classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(m.classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Accuracy: 0.7655 (+/- 0.0419) [SVC_clf] \n",
      " [[0.64785992 0.74143969 0.76692607 0.78497762 0.78731271 0.79568009\n",
      " 0.78575598 0.78089122 0.79023156 0.77427515]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    sclf, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "precision: 0.7620 (+/- 0.0400) [SVC_clf] \n",
      " [[0.6503139  0.73744987 0.76382517 0.7804443  0.78272996 0.79212666\n",
      " 0.77991641 0.77548609 0.78738795 0.77078251]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"precision_weighted\\\"\\n)\\nprint(\\n    \\\"precision: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"precision_weighted\\\"\\n)\\nprint(\\n    \\\"precision: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    sclf, xtrain, ytrain, cv=10, scoring=\"precision_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"precision: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "recall: 0.7656 (+/- 0.0418) [SVC_clf] \n",
      " [[0.64805447 0.74143969 0.76712062 0.78497762 0.78731271 0.79568009\n",
      " 0.78575598 0.78089122 0.79023156 0.77427515]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"recall_weighted\\\"\\n)\\nprint(\\n    \\\"recall: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"recall_weighted\\\"\\n)\\nprint(\\n    \\\"recall: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    sclf, xtrain, ytrain, cv=10, scoring=\"recall_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"recall: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Fitting 4 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/4)\n",
      "RandomForestClassifier(max_depth=30, min_samples_leaf=10, n_estimators=150,\n",
      "                       random_state=42)\n",
      "Fitting classifier2: xgbclassifier (2/4)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=8,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=20, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
      "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Fitting classifier3: pipeline (3/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(max_depth=30, min_samples_leaf=10,\n",
      "                                        n_estimators=150, random_state=42))])\n",
      "Fitting classifier4: pipeline (4/4)\n",
      "Pipeline(steps=[('columnselector',\n",
      "                 ColumnSelector(cols=[0, 1, 3, 8, 9, 10, 11])),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints='',\n",
      "                               learning_rate=0.300000012, max_delta_step=0,\n",
      "                               max_depth=8, min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints='()', n_estimators=20,\n",
      "                               n_jobs=0, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method='exact',\n",
      "                               validate_parameters=1, verbosity=None))])\n",
      "Accuracy: 0.7616 (+/- 0.0443) [SVC_clf] \n",
      " [[0.63654944 0.73693974 0.76377316 0.78160748 0.78454335 0.79325085\n",
      " 0.78183694 0.77722588 0.78822779 0.7718339 ]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"f1_weighted\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    sclf, xtrain, ytrain, cv=10, scoring=\\\"f1_weighted\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    sclf, xtrain, ytrain, cv=10, scoring=\"f1_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.Softvoting classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 49;\n",
       "                var nbb_unformatted_code = \"weakmodles = [rf_12, xgb_model_12, LogisticRegression(random_state=0), GaussianNB()]\\nestimators = [\\n    (\\\"rf_12\\\", rf_12),\\n    (\\\"xgb_model_12\\\", xgb_model_12),\\n    (\\\"LogisticRegression\\\", LogisticRegression(random_state=0)),\\n    (\\\"GaussianNB\\\", GaussianNB()),\\n    (\\\"rf_12_pip\\\", rf_12_pip),\\n    (\\\"xgb_model_12_pip\\\", xgb_model_12_pip)\\n]\";\n",
       "                var nbb_formatted_code = \"weakmodles = [rf_12, xgb_model_12, LogisticRegression(random_state=0), GaussianNB()]\\nestimators = [\\n    (\\\"rf_12\\\", rf_12),\\n    (\\\"xgb_model_12\\\", xgb_model_12),\\n    (\\\"LogisticRegression\\\", LogisticRegression(random_state=0)),\\n    (\\\"GaussianNB\\\", GaussianNB()),\\n    (\\\"rf_12_pip\\\", rf_12_pip),\\n    (\\\"xgb_model_12_pip\\\", xgb_model_12_pip),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles = [rf_12, xgb_model_12, LogisticRegression(random_state=0), GaussianNB()]\n",
    "estimators = [\n",
    "    (\"rf_12\", rf_12),\n",
    "    (\"xgb_model_12\", xgb_model_12),\n",
    "    (\"LogisticRegression\", LogisticRegression(random_state=0)),\n",
    "    (\"GaussianNB\", GaussianNB()),\n",
    "    (\"rf_12_pip\", rf_12_pip),\n",
    "    (\"xgb_model_12_pip\", xgb_model_12_pip),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf_12',\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     min_samples_leaf=10,\n",
       "                                                     n_estimators=150,\n",
       "                                                     random_state=42)),\n",
       "                             ('xgb_model_12',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1, gamma=0,\n",
       "                                            gpu_id=-1, importance_type='gain',\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.300000012,\n",
       "                                            max_del...\n",
       "                                                             interaction_constraints='',\n",
       "                                                             learning_rate=0.300000012,\n",
       "                                                             max_delta_step=0,\n",
       "                                                             max_depth=8,\n",
       "                                                             min_child_weight=1,\n",
       "                                                             missing=nan,\n",
       "                                                             monotone_constraints='()',\n",
       "                                                             n_estimators=20,\n",
       "                                                             n_jobs=0,\n",
       "                                                             num_parallel_tree=1,\n",
       "                                                             objective='multi:softprob',\n",
       "                                                             random_state=0,\n",
       "                                                             reg_alpha=0,\n",
       "                                                             reg_lambda=1,\n",
       "                                                             scale_pos_weight=None,\n",
       "                                                             subsample=1,\n",
       "                                                             tree_method='exact',\n",
       "                                                             validate_parameters=1,\n",
       "                                                             verbosity=None))]))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"soft\\\")\\nvotingclf2.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"soft\\\")\\nvotingclf2.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf2 = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "votingclf2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.73\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>149</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>63</td>\n",
       "      <td>126</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          149           51         0\n",
       "Prediabetes      63          126        11\n",
       "diabetes          4           33       163"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"ypred = votingclf2.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"ypred = votingclf2.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = votingclf2.predict(xtest.astype(float))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.72       200\n",
      "           1       0.60      0.63      0.61       200\n",
      "           2       0.94      0.81      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7526 (+/- 0.0380) [SVC_clf] \n",
      " [[0.64455253 0.73657588 0.75466926 0.77388597 0.7793345  0.78069663\n",
      " 0.76863203 0.76123759 0.76571317 0.76045923]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 53;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7503 (+/- 0.0352) [SVC_clf] \n",
      " [[0.6502968  0.73532183 0.75224161 0.77043597 0.77586626 0.77609906\n",
      " 0.76253697 0.75701411 0.76446455 0.75840535]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"precision_weighted\\\"\\n)\\nprint(\\n    \\\"precision: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"precision_weighted\\\"\\n)\\nprint(\\n    \\\"precision: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"precision_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"precision: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7526 (+/- 0.0380) [SVC_clf] \n",
      " [[0.64455253 0.73657588 0.75466926 0.77388597 0.7793345  0.78069663\n",
      " 0.76863203 0.76123759 0.76571317 0.76045923]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"recall_weighted\\\"\\n)\\nprint(\\n    \\\"recall: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"recall_weighted\\\"\\n)\\nprint(\\n    \\\"recall: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"recall_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"recall: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7489 (+/- 0.0397) [SVC_clf] \n",
      " [[0.63605908 0.73207258 0.75153257 0.7704589  0.77731033 0.77767858\n",
      " 0.76431101 0.75734653 0.76379727 0.7580235 ]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"f1_weighted\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"f1_weighted\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"f1_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.HardVoting\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf_12',\n",
       "                              RandomForestClassifier(max_depth=30,\n",
       "                                                     min_samples_leaf=10,\n",
       "                                                     n_estimators=150,\n",
       "                                                     random_state=42)),\n",
       "                             ('xgb_model_12',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=1, gamma=0,\n",
       "                                            gpu_id=-1, importance_type='gain',\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.300000012,\n",
       "                                            max_del...,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=20, n_jobs=0,\n",
       "                                            num_parallel_tree=1,\n",
       "                                            objective='multi:softprob',\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=None,\n",
       "                                            subsample=1, tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None)),\n",
       "                             ('LogisticRegression',\n",
       "                              LogisticRegression(random_state=0)),\n",
       "                             ('GaussianNB', GaussianNB())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"hard\\\")\\nvotingclf2.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"hard\\\")\\nvotingclf2.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf2 = VotingClassifier(estimators=estimators, voting=\"hard\")\n",
    "votingclf2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.745\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>160</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>54</td>\n",
       "      <td>126</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          160           39         1\n",
       "Prediabetes      54          126        20\n",
       "diabetes          0           39       161"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"ypred = votingclf2.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"ypred = votingclf2.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = votingclf2.predict(xtest.astype(float))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77       200\n",
      "           1       0.62      0.63      0.62       200\n",
      "           2       0.88      0.81      0.84       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7165 (+/- 0.0369) [SVC_clf] \n",
      " [[0.61401297 0.69848703 0.71253602 0.73054755 0.74675793 0.74153458\n",
      " 0.73487032 0.72136167 0.74184832 0.72275266]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.7219 (+/- 0.0351) [SVC_clf] \n",
      " [[0.62486382 0.7038619  0.71892722 0.73475415 0.75268389 0.74527056\n",
      " 0.73563173 0.72390087 0.74675516 0.73186627]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"precision_weighted\\\"\\n)\\nprint(\\n    \\\"precision: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"precision_weighted\\\"\\n)\\nprint(\\n    \\\"precision: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"precision_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"precision: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.7165 (+/- 0.0369) [SVC_clf] \n",
      " [[0.61401297 0.69848703 0.71253602 0.73054755 0.74675793 0.74153458\n",
      " 0.73487032 0.72136167 0.74184832 0.72275266]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"recall_weighted\\\"\\n)\\nprint(\\n    \\\"recall: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"recall_weighted\\\"\\n)\\nprint(\\n    \\\"recall: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"recall_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"recall: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7167 (+/- 0.0398) [SVC_clf] \n",
      " [[0.60552926 0.69765651 0.71388999 0.73193422 0.7490811  0.74307919\n",
      " 0.73486595 0.72174652 0.74352326 0.72524385]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"f1_weighted\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"f1_weighted\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.4f (+/- %0.4f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"f1_weighted\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.4f (+/- %0.4f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
