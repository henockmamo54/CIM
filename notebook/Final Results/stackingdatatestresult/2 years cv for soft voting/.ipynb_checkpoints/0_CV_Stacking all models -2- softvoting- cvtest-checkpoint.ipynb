{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "\n",
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"xtrain = pd.read_csv(\\\"traintestdata/0/X_train.txt\\\")\\nytrain = pd.read_csv(\\\"traintestdata/0/y_train.txt\\\")\\nxtest = pd.read_csv(\\\"traintestdata/0/X_test.txt\\\")\\nytest = pd.read_csv(\\\"traintestdata/0/y_test.txt\\\")\";\n",
       "                var nbb_formatted_code = \"xtrain = pd.read_csv(\\\"traintestdata/0/X_train.txt\\\")\\nytrain = pd.read_csv(\\\"traintestdata/0/y_train.txt\\\")\\nxtest = pd.read_csv(\\\"traintestdata/0/X_test.txt\\\")\\nytest = pd.read_csv(\\\"traintestdata/0/y_test.txt\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = pd.read_csv(\"traintestdata/0/X_train.txt\")\n",
    "ytrain = pd.read_csv(\"traintestdata/0/y_train.txt\")\n",
    "xtest = pd.read_csv(\"traintestdata/0/X_test.txt\")\n",
    "ytest = pd.read_csv(\"traintestdata/0/y_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate the classifier models based on the selected  features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_formatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "cols = []\n",
    "weakmodles = []\n",
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(np.arange(0, 12))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_formatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(np.arange(0, 12))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_12 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=\"log2\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_12 = svmgpu(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_12 = SVC(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cols.append(np.arange(0, 12))\n",
    "\n",
    "# weakmodles.append(rf_model_12)\n",
    "# weakmodles.append(xgb_model_12)\n",
    "# weakmodles.append(scv_model_12)\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\n",
    "\n",
    "\n",
    "estimators.append((\"rf_model_12\", rf_model_12))\n",
    "estimators.append((\"xgb_model_12\", xgb_model_12))\n",
    "estimators.append((\"scv_model_12\", scv_model_cpu_12))\n",
    "\n",
    "# estimators = [\n",
    "#     (\"rf_model_12\", rf_model_12),\n",
    "#     (\"xgb_model_12\", xgb_model_12),\n",
    "#     (\"scv_model_12\", scv_model_12),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), scv_model_5))\\n    \\n\\ncols.append([0,1,3,10,11])\\ncols.append([0,1,3,10,11])\\ncols.append([0,1,3,10,11])\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_formatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), scv_model_5))\\n\\n\\ncols.append([0, 1, 3, 10, 11])\\ncols.append([0, 1, 3, 10, 11])\\ncols.append([0, 1, 3, 10, 11])\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "xgb_model_5 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_5 = svmgpu(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "scv_model_cpu_5 = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# weakmodles.append(rf_model_5)\n",
    "# weakmodles.append(xgb_model_5)\n",
    "# weakmodles.append(scv_model_5)\n",
    "\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), rf_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), xgb_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), scv_model_5))\n",
    "    \n",
    "\n",
    "cols.append([0,1,3,10,11])\n",
    "cols.append([0,1,3,10,11])\n",
    "cols.append([0,1,3,10,11])\n",
    "\n",
    "estimators.append((\"rf_model_5\", rf_model_5))\n",
    "estimators.append((\"xgb_model_5\", xgb_model_5))\n",
    "estimators.append((\"scv_model_5\", scv_model_cpu_5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"top10colscomb = [\\n    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\\n    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_formatted_code = \"top10colscomb = [\\n    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\\n    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10colscomb = [\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_10 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_10 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=42,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_10 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_10 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_10)\n",
    "    #     weakmodles.append(xgb_model_10)\n",
    "    #     weakmodles.append(scv_model_10)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_10\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + top10colscomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. 9 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"topcols9comb = [\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_formatted_code = \"topcols9comb = [\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topcols9comb = [\n",
    "    (0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
    "    (0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_9 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_9 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_9 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_9 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    #     weakmodles.append(rf_model_9)\n",
    "    #     weakmodles.append(xgb_model_9)\n",
    "    #     weakmodles.append(scv_model_9)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_9\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + topcols9comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"top8colscomb = [\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top8colscomb = [\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top8colscomb = [\n",
    "    (0, 1, 2, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 10, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top8colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_8 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_8 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_8 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_8 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\n",
    "\n",
    "#     weakmodles.append(rf_model_8)\n",
    "#     weakmodles.append(xgb_model_8)\n",
    "#     weakmodles.append(scv_model_8)\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_8\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"top7colscomb = [\\n    (0, 1, 3, 5, 6, 10, 11),\\n    (0, 1, 3, 4, 5, 10, 11),\\n    (0, 1, 2, 3, 4, 10, 11),\\n    (0, 1, 2, 3, 5, 10, 11),\\n    (0, 1, 3, 6, 8, 10, 11),\\n    (0, 1, 6, 8, 9, 10, 11),\\n    (0, 1, 6, 7, 8, 9, 10),\\n    (0, 1, 2, 3, 8, 10, 11),\\n    (0, 1, 2, 6, 8, 10, 11),\\n    (0, 1, 3, 8, 9, 10, 11),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top7colscomb = [\\n    (0, 1, 3, 5, 6, 10, 11),\\n    (0, 1, 3, 4, 5, 10, 11),\\n    (0, 1, 2, 3, 4, 10, 11),\\n    (0, 1, 2, 3, 5, 10, 11),\\n    (0, 1, 3, 6, 8, 10, 11),\\n    (0, 1, 6, 8, 9, 10, 11),\\n    (0, 1, 6, 7, 8, 9, 10),\\n    (0, 1, 2, 3, 8, 10, 11),\\n    (0, 1, 2, 6, 8, 10, 11),\\n    (0, 1, 3, 8, 9, 10, 11),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top7colscomb = [\n",
    "    (0, 1, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 10, 11),\n",
    "    (0, 1, 3, 6, 8, 10, 11),\n",
    "    (0, 1, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 6, 7, 8, 9, 10),\n",
    "    (0, 1, 2, 3, 8, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top7colscomb\n",
    "\n",
    "rf_model_7 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_7 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_7 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_7 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\n",
    "\n",
    "#     weakmodles.append(rf_model_7)\n",
    "#     weakmodles.append(xgb_model_7)\n",
    "#     weakmodles.append(scv_model_7)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_7\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"top6colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top6colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top6colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top6colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_6 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_6 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_6 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_6 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\n",
    "\n",
    "#     weakmodles.append(rf_model_6)\n",
    "#     weakmodles.append(xgb_model_6)\n",
    "#     weakmodles.append(scv_model_6)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_6\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8. 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"top5colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top5colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top5colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top5colscomb\n",
    "\n",
    "rf_model_5_2 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_5_2 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_5_2 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_5_2 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    # max_mem_size=-1,   n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_5_2)\n",
    "    #     weakmodles.append(xgb_model_5_2)\n",
    "    #     weakmodles.append(scv_model_5_2)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_52\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"originalweakmodles = weakmodles.copy()\\noriginalestimators = estimators.copy()\";\n",
       "                var nbb_formatted_code = \"originalweakmodles = weakmodles.copy()\\noriginalestimators = estimators.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "originalweakmodles = weakmodles.copy()\n",
    "originalestimators = estimators.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"weakmodles = []\\nestimators = []\\nselected_index = [\\n    3,\\n    22,\\n    25,\\n    37,\\n    40,\\n    43,\\n    46,\\n    49,\\n    52,\\n    55,\\n    58,\\n    61,\\n    64,\\n    66,\\n    69,\\n    70,\\n    71,\\n    72,\\n    80,\\n    81,\\n    84,\\n    85,\\n    86,\\n    87,\\n    95,\\n]\\n\\nfor i in selected_index:\\n    weakmodles.append(originalweakmodles[i])\\n\\nfor i in selected_index:\\n    estimators.append(originalestimators[i])\";\n",
       "                var nbb_formatted_code = \"weakmodles = []\\nestimators = []\\nselected_index = [\\n    3,\\n    22,\\n    25,\\n    37,\\n    40,\\n    43,\\n    46,\\n    49,\\n    52,\\n    55,\\n    58,\\n    61,\\n    64,\\n    66,\\n    69,\\n    70,\\n    71,\\n    72,\\n    80,\\n    81,\\n    84,\\n    85,\\n    86,\\n    87,\\n    95,\\n]\\n\\nfor i in selected_index:\\n    weakmodles.append(originalweakmodles[i])\\n\\nfor i in selected_index:\\n    estimators.append(originalestimators[i])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles = []\n",
    "estimators = []\n",
    "selected_index = [\n",
    "    3,\n",
    "    22,\n",
    "    25,\n",
    "    37,\n",
    "    40,\n",
    "    43,\n",
    "    46,\n",
    "    49,\n",
    "    52,\n",
    "    55,\n",
    "    58,\n",
    "    61,\n",
    "    64,\n",
    "    66,\n",
    "    69,\n",
    "    70,\n",
    "    71,\n",
    "    72,\n",
    "    80,\n",
    "    81,\n",
    "    84,\n",
    "    85,\n",
    "    86,\n",
    "    87,\n",
    "    95,\n",
    "]\n",
    "\n",
    "for i in selected_index:\n",
    "    weakmodles.append(originalweakmodles[i])\n",
    "\n",
    "for i in selected_index:\n",
    "    estimators.append(originalestimators[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"len(weakmodles)\";\n",
       "                var nbb_formatted_code = \"len(weakmodles)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(weakmodles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_formatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = np.array(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"len(estimators)\";\n",
       "                var nbb_formatted_code = \"len(estimators)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6  Generate Votting Classifer soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"\\nscv_model_cpu_withProb = SVC(\\n  C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n#     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n#     max_mem_size=-1,\\n#     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_formatted_code = \"scv_model_cpu_withProb = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scv_model_cpu_withProb = SVC(\n",
    "  C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "#     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "#     max_mem_size=-1,\n",
    "#     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"soft\\\")\";\n",
       "                var nbb_formatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"soft\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf2 = VotingClassifier(estimators=estimators, voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "votingclf2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = votingclf2.predict(xtest.astype(float))\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "print(\"precision_score \\t\", m.precision_score(ytest, ypred, average=\"weighted\"))\n",
    "print(\"recall_score \\t\", m.recall_score(ytest, ypred, average=\"weighted\"))\n",
    "print(\"f1_score \\t\", m.f1_score(ytest, ypred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.61      0.62       200\n",
      "           2       0.88      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "0\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "1\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "2\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7533333333333333\n",
      "Accuracy =  0.7533333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.65      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "3\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "4\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      54          122        24\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "5\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "6\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "7\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "8\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "9\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "10\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "11\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          130        18\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "13\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "14\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "15\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "16\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "17\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.60      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "18\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      53          128        19\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.64      0.63       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "19\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      53          131        16\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.66      0.64       200\n",
      "           2       0.91      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "20\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      50          126        24\n",
      "diabetes          3           24       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.63      0.63      0.63       200\n",
      "           2       0.88      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "21\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7516666666666667\n",
      "Accuracy =  0.7516666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       200\n",
      "           1       0.64      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "22\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          130        15\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.65      0.64       200\n",
      "           2       0.92      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "23\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "24\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"stackedmodels = votingclf2.estimators_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(stackedmodels[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_formatted_code = \"stackedmodels = votingclf2.estimators_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(stackedmodels[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stackedmodels = votingclf2.estimators_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(stackedmodels[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73 (+/- 0.03) [SVC_clf] \n",
      " [[0.63287938 0.71089494 0.7311284  0.75287021 0.74197315 0.74956217\n",
      " 0.73847052 0.73418953 0.75014594 0.73749757]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.2f (+/- %0.2f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_formatted_code = \"scores = model_selection.cross_val_score(\\n    votingclf2, xtrain, ytrain, cv=10, scoring=\\\"accuracy\\\"\\n)\\nprint(\\n    \\\"Accuracy: %0.2f (+/- %0.2f) [%s] \\\\n [%s]\\\"\\n    % (scores.mean(), scores.std(), \\\"SVC_clf\\\", scores)\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(\n",
    "    votingclf2, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    ")\n",
    "print(\n",
    "    \"Accuracy: %0.2f (+/- %0.2f) [%s] \\n [%s]\"\n",
    "    % (scores.mean(), scores.std(), \"SVC_clf\", scores)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiscorer import MultiScorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scorer = MultiScorer({                                               # Create a MultiScorer instance\n",
    "  'accuracy_score': (m.accuracy_score, {}),\n",
    "  'precision_score': (m.precision_score, {'average': 'weighted'}),  \n",
    "  'recall_score': (m.recall_score, {'average': 'weighted'}),  \n",
    "  'f1_score': (m.f1_score, {'average': 'weighted'})               # Param 'average' will be passed to precision_score as kwarg \n",
    "})\n",
    "\n",
    "cross_val_score(votingclf2, xtrain, ytrain, scoring=scorer, cv=5)               # Use the function with our socrer. Ignore its result \n",
    "results = scorer.get_results()                                       # Get a dict of lists containing the scores for each metric\n",
    "\n",
    "from numpy import average\n",
    "for metric in results.keys():  # Iterate and use the results\n",
    "    print(\"%s: %.3f\" % (metric, average(results[metric])))\n",
    "    print(\"%s: %.3f\" % (metric, np.std(results[metric])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
