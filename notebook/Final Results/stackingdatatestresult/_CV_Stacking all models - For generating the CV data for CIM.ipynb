{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "\n",
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 19)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"x_original = pd.read_csv(\\\"../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_formatted_code = \"x_original = pd.read_csv(\\\"../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original = pd.read_csv(\"../../dataset/XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"y_original = pd.read_csv(\\\"../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_formatted_code = \"y_original = pd.read_csv(\\\"../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_original = pd.read_csv(\"../../dataset/TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\";\n",
       "                var nbb_formatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56542, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"data = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downsample the majority class and upsample the minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 17331 38166\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_formatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_formatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_formatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17131, 1: 17131, 0: 17131})\n",
      "17131 17131 17131\n",
      "(51393, 12) (51393,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "randomseed = 42\n",
    "\n",
    "sm = SMOTENC(\n",
    "    random_state=randomseed,\n",
    "    categorical_features=[6, 7, 8, 9, 10],\n",
    "    sampling_strategy=\"minority\",\n",
    ")\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"x = xtrain\\ny = ytrain\";\n",
       "                var nbb_formatted_code = \"x = xtrain\\ny = ytrain\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = xtrain\n",
    "y = ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"pd.DataFrame(xtrain).to_csv(\\\"cv_resulsts/original_xtrain.txt\\\", index=False)\\npd.DataFrame(xtest).to_csv(\\\"cv_resulsts/original_xtest.txt\\\", index=False)\\npd.DataFrame(ytrain).to_csv(\\\"cv_resulsts/original_ytrain.txt\\\", index=False)\\npd.DataFrame(ytest).to_csv(\\\"cv_resulsts/original_ytest.txt\\\", index=False)\";\n",
       "                var nbb_formatted_code = \"pd.DataFrame(xtrain).to_csv(\\\"cv_resulsts/original_xtrain.txt\\\", index=False)\\npd.DataFrame(xtest).to_csv(\\\"cv_resulsts/original_xtest.txt\\\", index=False)\\npd.DataFrame(ytrain).to_csv(\\\"cv_resulsts/original_ytrain.txt\\\", index=False)\\npd.DataFrame(ytest).to_csv(\\\"cv_resulsts/original_ytest.txt\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(xtrain).to_csv(\"cv_resulsts/original_xtrain.txt\", index=False)\n",
    "pd.DataFrame(xtest).to_csv(\"cv_resulsts/original_xtest.txt\", index=False)\n",
    "pd.DataFrame(ytrain).to_csv(\"cv_resulsts/original_ytrain.txt\", index=False)\n",
    "pd.DataFrame(ytest).to_csv(\"cv_resulsts/original_ytest.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=42, shuffle=True)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"from sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(x)\\n\\nprint(kf)\\n\\ndata_cv = []\\n\\nfor train_index, test_index in kf.split(x):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    X_train, X_test = x[train_index], x[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    data_cv.append([[X_train, X_test], [y_train, y_test]])\";\n",
       "                var nbb_formatted_code = \"from sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(x)\\n\\nprint(kf)\\n\\ndata_cv = []\\n\\nfor train_index, test_index in kf.split(x):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    X_train, X_test = x[train_index], x[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    data_cv.append([[X_train, X_test], [y_train, y_test]])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "data_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    data_cv.append([[X_train, X_test], [y_train, y_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate the classifier models based on the selected  features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_formatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "cols = []\n",
    "weakmodles = []\n",
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(np.arange(0, 12))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_formatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(np.arange(0, 12))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_12 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=\"log2\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_12 = svmgpu(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_12 = SVC(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cols.append(np.arange(0, 12))\n",
    "\n",
    "# weakmodles.append(rf_model_12)\n",
    "# weakmodles.append(xgb_model_12)\n",
    "# weakmodles.append(scv_model_12)\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\n",
    "\n",
    "\n",
    "estimators.append((\"rf_model_12\", rf_model_12))\n",
    "estimators.append((\"xgb_model_12\", xgb_model_12))\n",
    "estimators.append((\"scv_model_12\", scv_model_cpu_12))\n",
    "\n",
    "# estimators = [\n",
    "#     (\"rf_model_12\", rf_model_12),\n",
    "#     (\"xgb_model_12\", xgb_model_12),\n",
    "#     (\"scv_model_12\", scv_model_12),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), scv_model_5))\\n    \\n\\ncols.append([0,1,3,10,11])\\ncols.append([0,1,3,10,11])\\ncols.append([0,1,3,10,11])\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_formatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), scv_model_5))\\n\\n\\ncols.append([0, 1, 3, 10, 11])\\ncols.append([0, 1, 3, 10, 11])\\ncols.append([0, 1, 3, 10, 11])\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "xgb_model_5 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_5 = svmgpu(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "scv_model_cpu_5 = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# weakmodles.append(rf_model_5)\n",
    "# weakmodles.append(xgb_model_5)\n",
    "# weakmodles.append(scv_model_5)\n",
    "\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), rf_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), xgb_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), scv_model_5))\n",
    "    \n",
    "\n",
    "cols.append([0,1,3,10,11])\n",
    "cols.append([0,1,3,10,11])\n",
    "cols.append([0,1,3,10,11])\n",
    "\n",
    "estimators.append((\"rf_model_5\", rf_model_5))\n",
    "estimators.append((\"xgb_model_5\", xgb_model_5))\n",
    "estimators.append((\"scv_model_5\", scv_model_cpu_5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"top10colscomb = [\\n    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\\n    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_formatted_code = \"top10colscomb = [\\n    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\\n    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10colscomb = [\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_10 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_10 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=42,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_10 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_10 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_10)\n",
    "    #     weakmodles.append(xgb_model_10)\n",
    "    #     weakmodles.append(scv_model_10)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_10\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + top10colscomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. 9 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"topcols9comb = [\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_formatted_code = \"topcols9comb = [\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topcols9comb = [\n",
    "    (0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
    "    (0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_9 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_9 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_9 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_9 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    #     weakmodles.append(rf_model_9)\n",
    "    #     weakmodles.append(xgb_model_9)\n",
    "    #     weakmodles.append(scv_model_9)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_9\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + topcols9comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"top8colscomb = [\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top8colscomb = [\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top8colscomb = [\n",
    "    (0, 1, 2, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 10, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top8colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_8 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_8 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_8 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_8 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\n",
    "\n",
    "#     weakmodles.append(rf_model_8)\n",
    "#     weakmodles.append(xgb_model_8)\n",
    "#     weakmodles.append(scv_model_8)\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_8\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"top7colscomb = [\\n    (0, 1, 3, 5, 6, 10, 11),\\n    (0, 1, 3, 4, 5, 10, 11),\\n    (0, 1, 2, 3, 4, 10, 11),\\n    (0, 1, 2, 3, 5, 10, 11),\\n    (0, 1, 3, 6, 8, 10, 11),\\n    (0, 1, 6, 8, 9, 10, 11),\\n    (0, 1, 6, 7, 8, 9, 10),\\n    (0, 1, 2, 3, 8, 10, 11),\\n    (0, 1, 2, 6, 8, 10, 11),\\n    (0, 1, 3, 8, 9, 10, 11),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top7colscomb = [\\n    (0, 1, 3, 5, 6, 10, 11),\\n    (0, 1, 3, 4, 5, 10, 11),\\n    (0, 1, 2, 3, 4, 10, 11),\\n    (0, 1, 2, 3, 5, 10, 11),\\n    (0, 1, 3, 6, 8, 10, 11),\\n    (0, 1, 6, 8, 9, 10, 11),\\n    (0, 1, 6, 7, 8, 9, 10),\\n    (0, 1, 2, 3, 8, 10, 11),\\n    (0, 1, 2, 6, 8, 10, 11),\\n    (0, 1, 3, 8, 9, 10, 11),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top7colscomb = [\n",
    "    (0, 1, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 10, 11),\n",
    "    (0, 1, 3, 6, 8, 10, 11),\n",
    "    (0, 1, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 6, 7, 8, 9, 10),\n",
    "    (0, 1, 2, 3, 8, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top7colscomb\n",
    "\n",
    "rf_model_7 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_7 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_7 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_7 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\n",
    "\n",
    "#     weakmodles.append(rf_model_7)\n",
    "#     weakmodles.append(xgb_model_7)\n",
    "#     weakmodles.append(scv_model_7)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_7\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"top6colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top6colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top6colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top6colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_6 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_6 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_6 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_6 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\n",
    "\n",
    "#     weakmodles.append(rf_model_6)\n",
    "#     weakmodles.append(xgb_model_6)\n",
    "#     weakmodles.append(scv_model_6)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_6\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8. 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"top5colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top5colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top5colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top5colscomb\n",
    "\n",
    "rf_model_5_2 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_5_2 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_5_2 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_5_2 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    # max_mem_size=-1,   n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_5_2)\n",
    "    #     weakmodles.append(xgb_model_5_2)\n",
    "    #     weakmodles.append(scv_model_5_2)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_52\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"originalweakmodles = weakmodles.copy()\";\n",
       "                var nbb_formatted_code = \"originalweakmodles = weakmodles.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "originalweakmodles = weakmodles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"weakmodles = []\\nselected_index = [\\n    3,\\n    22,\\n    25,\\n    37,\\n    40,\\n    43,\\n    46,\\n    49,\\n    52,\\n    55,\\n    58,\\n    61,\\n    64,\\n    66,\\n    69,\\n    70,\\n    71,\\n    72,\\n    80,\\n    81,\\n    84,\\n    85,\\n    86,\\n    87,\\n    95,\\n]\\n\\nfor i in selected_index:\\n    weakmodles.append(originalweakmodles[i])\";\n",
       "                var nbb_formatted_code = \"weakmodles = []\\nselected_index = [\\n    3,\\n    22,\\n    25,\\n    37,\\n    40,\\n    43,\\n    46,\\n    49,\\n    52,\\n    55,\\n    58,\\n    61,\\n    64,\\n    66,\\n    69,\\n    70,\\n    71,\\n    72,\\n    80,\\n    81,\\n    84,\\n    85,\\n    86,\\n    87,\\n    95,\\n]\\n\\nfor i in selected_index:\\n    weakmodles.append(originalweakmodles[i])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles = []\n",
    "selected_index = [\n",
    "    3,\n",
    "    22,\n",
    "    25,\n",
    "    37,\n",
    "    40,\n",
    "    43,\n",
    "    46,\n",
    "    49,\n",
    "    52,\n",
    "    55,\n",
    "    58,\n",
    "    61,\n",
    "    64,\n",
    "    66,\n",
    "    69,\n",
    "    70,\n",
    "    71,\n",
    "    72,\n",
    "    80,\n",
    "    81,\n",
    "    84,\n",
    "    85,\n",
    "    86,\n",
    "    87,\n",
    "    95,\n",
    "]\n",
    "\n",
    "for i in selected_index:\n",
    "    weakmodles.append(originalweakmodles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"len(weakmodles)\";\n",
       "                var nbb_formatted_code = \"len(weakmodles)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(weakmodles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_formatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = np.array(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv  0\n",
      "0\n",
      "0.7618409706313277\n",
      "1\n",
      "0.7412039977532486\n",
      "2\n",
      "0.7425203913673362\n",
      "3\n",
      "0.7442701486160391\n",
      "4\n",
      "0.7418425151668396\n",
      "5\n",
      "0.7438679852938954\n",
      "6\n",
      "0.743834181067839\n",
      "7\n",
      "0.7416458215757645\n",
      "8\n",
      "0.7454995684379262\n",
      "9\n",
      "0.7451146269851486\n",
      "10\n",
      "0.7428047817022667\n",
      "11\n",
      "0.7467440477425907\n",
      "12\n",
      "0.7439782085563539\n",
      "13\n",
      "0.7472507102658713\n",
      "14\n",
      "0.7501215040744491\n",
      "15\n",
      "0.7391859662666816\n",
      "16\n",
      "0.7218448886178804\n",
      "17\n",
      "0.7484045296127538\n",
      "18\n",
      "0.7186764224714214\n",
      "19\n",
      "0.7472507102658713\n",
      "20\n",
      "0.7501215040744491\n",
      "21\n",
      "0.7391859662666816\n",
      "22\n",
      "0.7218448886178804\n",
      "23\n",
      "0.7484045296127538\n",
      "24\n",
      "0.7186764224714214\n",
      "cv  1\n",
      "0\n",
      "0.758518727112141\n",
      "1\n",
      "0.7418275991825792\n",
      "2\n",
      "0.74359771061851\n",
      "3\n",
      "0.7369300449815696\n",
      "4\n",
      "0.7386446135565603\n",
      "5\n",
      "0.7405050723868685\n",
      "6\n",
      "0.7389530620145061\n",
      "7\n",
      "0.739486204937693\n",
      "8\n",
      "0.7382853738738256\n",
      "9\n",
      "0.7389236810792315\n",
      "10\n",
      "0.738240353234491\n",
      "11\n",
      "0.7385634611975463\n",
      "12\n",
      "0.7390535266925411\n",
      "13\n",
      "0.7475556248479986\n",
      "14\n",
      "0.75007300151001\n",
      "15\n",
      "0.734658702698209\n",
      "16\n",
      "0.7253481712867188\n",
      "17\n",
      "0.7508885585455447\n",
      "18\n",
      "0.7258651923220931\n",
      "19\n",
      "0.7475556248479986\n",
      "20\n",
      "0.75007300151001\n",
      "21\n",
      "0.734658702698209\n",
      "22\n",
      "0.7253481712867188\n",
      "23\n",
      "0.7508885585455447\n",
      "24\n",
      "0.7258651923220931\n",
      "cv  2\n",
      "0\n",
      "0.7710196465197305\n",
      "1\n",
      "0.7507096258310424\n",
      "2\n",
      "0.7503710059100261\n",
      "3\n",
      "0.7470421332478399\n",
      "4\n",
      "0.7500059287989581\n",
      "5\n",
      "0.7503045771225614\n",
      "6\n",
      "0.7474418767170516\n",
      "7\n",
      "0.7477671691261897\n",
      "8\n",
      "0.7464346820845013\n",
      "9\n",
      "0.7518430192469552\n",
      "10\n",
      "0.7508882059665243\n",
      "11\n",
      "0.7471342853182666\n",
      "12\n",
      "0.7481626989595126\n",
      "13\n",
      "0.7606797135323852\n",
      "14\n",
      "0.7576999771899471\n",
      "15\n",
      "0.7451979517922971\n",
      "16\n",
      "0.48594531401593205\n",
      "17\n",
      "0.762417642107318\n",
      "18\n",
      "0.7291926152420101\n",
      "19\n",
      "0.7606797135323852\n",
      "20\n",
      "0.7576999771899471\n",
      "21\n",
      "0.7451979517922971\n",
      "22\n",
      "0.48594531401593205\n",
      "23\n",
      "0.762417642107318\n",
      "24\n",
      "0.7291926152420101\n",
      "cv  3\n",
      "0\n",
      "0.7573309617334625\n",
      "1\n",
      "0.738227277119423\n",
      "2\n",
      "0.7332570703615447\n",
      "3\n",
      "0.7387378034822518\n",
      "4\n",
      "0.7351660968358356\n",
      "5\n",
      "0.7327476572762687\n",
      "6\n",
      "0.7362556469723204\n",
      "7\n",
      "0.7348230456832969\n",
      "8\n",
      "0.7388546349242351\n",
      "9\n",
      "0.7364667333972894\n",
      "10\n",
      "0.7332013008888256\n",
      "11\n",
      "0.7392037256748321\n",
      "12\n",
      "0.7378926098743156\n",
      "13\n",
      "0.7468778258672273\n",
      "14\n",
      "0.7480438704926708\n",
      "15\n",
      "0.7349927854967364\n",
      "16\n",
      "0.7197028838370607\n",
      "17\n",
      "0.7443863854354028\n",
      "18\n",
      "0.7184788188329304\n",
      "19\n",
      "0.7468778258672273\n",
      "20\n",
      "0.7480438704926708\n",
      "21\n",
      "0.7349927854967364\n",
      "22\n",
      "0.7197028838370607\n",
      "23\n",
      "0.7443863854354028\n",
      "24\n",
      "0.7184788188329304\n",
      "cv  4\n",
      "0\n",
      "0.7658184254617397\n",
      "1\n",
      "0.7434577322495144\n",
      "2\n",
      "0.7428960879576256\n",
      "3\n",
      "0.7441634900844636\n",
      "4\n",
      "0.741475808797043\n",
      "5\n",
      "0.7431825566532587\n",
      "6\n",
      "0.7459687617158387\n",
      "7\n",
      "0.7455606114550172\n",
      "8\n",
      "0.7443671498940272\n",
      "9\n",
      "0.7430665474118451\n",
      "10\n",
      "0.7408430885462655\n",
      "11\n",
      "0.745285813758345\n",
      "12\n",
      "0.7419411253275238\n",
      "13\n",
      "0.7543156734555088\n",
      "14\n",
      "0.7550990538946138\n",
      "15\n",
      "0.7414292527011174\n",
      "16\n",
      "0.719318319823898\n",
      "17\n",
      "0.7533721585361776\n",
      "18\n",
      "0.7270731259238266\n",
      "19\n",
      "0.7543156734555088\n",
      "20\n",
      "0.7550990538946138\n",
      "21\n",
      "0.7414292527011174\n",
      "22\n",
      "0.719318319823898\n",
      "23\n",
      "0.7533721585361776\n",
      "24\n",
      "0.7270731259238266\n",
      "cv  5\n",
      "0\n",
      "0.7650887430008497\n",
      "1\n",
      "0.7428450736214777\n",
      "2\n",
      "0.7403909101644783\n",
      "3\n",
      "0.7402672927267865\n",
      "4\n",
      "0.7433739356355663\n",
      "5\n",
      "0.7406683871452888\n",
      "6\n",
      "0.7400634680747993\n",
      "7\n",
      "0.7444673746878103\n",
      "8\n",
      "0.7417753630806408\n",
      "9\n",
      "0.7430868220354452\n",
      "10\n",
      "0.7444415485662735\n",
      "11\n",
      "0.7417300988207032\n",
      "12\n",
      "0.7430657254052458\n",
      "13\n",
      "0.7519013348184821\n",
      "14\n",
      "0.7519776627264192\n",
      "15\n",
      "0.7387340914644721\n",
      "16\n",
      "0.7264054461903544\n",
      "17\n",
      "0.7529087002003937\n",
      "18\n",
      "0.7261345995426689\n",
      "19\n",
      "0.7519013348184821\n",
      "20\n",
      "0.7519776627264192\n",
      "21\n",
      "0.7387340914644721\n",
      "22\n",
      "0.7264054461903544\n",
      "23\n",
      "0.7529087002003937\n",
      "24\n",
      "0.7261345995426689\n",
      "cv  6\n",
      "0\n",
      "0.7626401506596907\n",
      "1\n",
      "0.7403255104348527\n",
      "2\n",
      "0.7398384013220498\n",
      "3\n",
      "0.7409790178165643\n",
      "4\n",
      "0.7380741374601576\n",
      "5\n",
      "0.7392798360657848\n",
      "6\n",
      "0.7424277017273175\n",
      "7\n",
      "0.7399564719534254\n",
      "8\n",
      "0.7425935903746713\n",
      "9\n",
      "0.7392058754251236\n",
      "10\n",
      "0.7396228803663245\n",
      "11\n",
      "0.7404176415651728\n",
      "12\n",
      "0.7412034634103359\n",
      "13\n",
      "0.7466615458420575\n",
      "14\n",
      "0.748043840419525\n",
      "15\n",
      "0.7354497282062749\n",
      "16\n",
      "0.497672442063627\n",
      "17\n",
      "0.7512026302228819\n",
      "18\n",
      "0.7234774836299707\n",
      "19\n",
      "0.7466615458420575\n",
      "20\n",
      "0.748043840419525\n",
      "21\n",
      "0.7354497282062749\n",
      "22\n",
      "0.497672442063627\n",
      "23\n",
      "0.7512026302228819\n",
      "24\n",
      "0.7234774836299707\n",
      "cv  7\n",
      "0\n",
      "0.7634292419725853\n",
      "1\n",
      "0.7436848144947393\n",
      "2\n",
      "0.7428295972979135\n",
      "3\n",
      "0.7417450446404759\n",
      "4\n",
      "0.744506568440878\n",
      "5\n",
      "0.7427551892519674\n",
      "6\n",
      "0.7413261976860589\n",
      "7\n",
      "0.7440782719040794\n",
      "8\n",
      "0.7428272587560332\n",
      "9\n",
      "0.7441352851021663\n",
      "10\n",
      "0.7441720498563322\n",
      "11\n",
      "0.7405114644342645\n",
      "12\n",
      "0.7449670826402126\n",
      "13\n",
      "0.7541485772613636\n",
      "14\n",
      "0.7532531250031582\n",
      "15\n",
      "0.7415571500040905\n",
      "16\n",
      "0.7279669567477393\n",
      "17\n",
      "0.7540186318546801\n",
      "18\n",
      "0.7285357124589846\n",
      "19\n",
      "0.7541485772613636\n",
      "20\n",
      "0.7532531250031582\n",
      "21\n",
      "0.7415571500040905\n",
      "22\n",
      "0.7279669567477393\n",
      "23\n",
      "0.7540186318546801\n",
      "24\n",
      "0.7285357124589846\n",
      "cv  8\n",
      "0\n",
      "0.7686668303757308\n",
      "1\n",
      "0.7486367583982791\n",
      "2\n",
      "0.7516402171191864\n",
      "3\n",
      "0.7484551300749921\n",
      "4\n",
      "0.7483195046708002\n",
      "5\n",
      "0.7501779206234955\n",
      "6\n",
      "0.7507512267611528\n",
      "7\n",
      "0.751494907583224\n",
      "8\n",
      "0.7474655247914415\n",
      "9\n",
      "0.7482717725934511\n",
      "10\n",
      "0.7487158153190769\n",
      "11\n",
      "0.7476959048506993\n",
      "12\n",
      "0.7470056628558671\n",
      "13\n",
      "0.7569420639106639\n",
      "14\n",
      "0.7589273505814282\n",
      "15\n",
      "0.743938557732162\n",
      "16\n",
      "0.6335906706946\n",
      "17\n",
      "0.7493312445448388\n",
      "18\n",
      "0.6386395470148168\n",
      "19\n",
      "0.7569420639106639\n",
      "20\n",
      "0.7589273505814282\n",
      "21\n",
      "0.743938557732162\n",
      "22\n",
      "0.6335906706946\n",
      "23\n",
      "0.7493312445448388\n",
      "24\n",
      "0.6386395470148168\n",
      "cv  9\n",
      "0\n",
      "0.7675348665320343\n",
      "1\n",
      "0.7538186856486475\n",
      "2\n",
      "0.7510558748867174\n",
      "3\n",
      "0.7527624901920159\n",
      "4\n",
      "0.7543835722142977\n",
      "5\n",
      "0.7518982212058046\n",
      "6\n",
      "0.7542808580553105\n",
      "7\n",
      "0.7522731594564809\n",
      "8\n",
      "0.7574076297268758\n",
      "9\n",
      "0.7521863167266462\n",
      "10\n",
      "0.7548096714110486\n",
      "11\n",
      "0.7558089438493375\n",
      "12\n",
      "0.7517208226852725\n",
      "13\n",
      "0.756327152505238\n",
      "14\n",
      "0.7532746317441024\n",
      "15\n",
      "0.7434692334664117\n",
      "16\n",
      "0.7313514825174049\n",
      "17\n",
      "0.7602624669785594\n",
      "18\n",
      "0.7340997849805401\n",
      "19\n",
      "0.756327152505238\n",
      "20\n",
      "0.7532746317441024\n",
      "21\n",
      "0.7434692334664117\n",
      "22\n",
      "0.7313514825174049\n",
      "23\n",
      "0.7602624669785594\n",
      "24\n",
      "0.7340997849805401\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"for d in range(len(data_cv)):\\n    \\n    print(\\\"cv \\\", d)\\n    tempdata = data_cv[d]\\n\\n    _tempxtrain = tempdata[0][0]\\n    _tempxtest = tempdata[0][1]\\n\\n    _tempytrain = tempdata[1][0]\\n    _tempytest = tempdata[1][1]\\n\\n    clf = []\\n    acc = []\\n    finalacc = []\\n    ypredproba_all = []\\n    ypredconfprob_all = []\\n\\n    for j, classifier in enumerate(weakmodles):\\n        print(j)\\n        rf = classifier\\n        rf.fit(_tempxtrain, _tempytrain)\\n        rfpred = rf.predict(_tempxtest)\\n        print(m.f1_score(_tempytest, rfpred, average=\\\"weighted\\\"))\\n\\n        clf.append(rf)\\n        acc.append(m.f1_score(_tempytest, rfpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(rf.predict_proba(_tempxtest))\\n\\n        confmat = m.confusion_matrix(_tempytest, rfpred)\\n        confsumh = np.sum(confmat, axis=1)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n        \\n        \\n    np.array(ypredconfprob_all)[0].ravel()\\n    tempval = []\\n    for i in range(len(weakmodles)):\\n        tempval.append(np.array(ypredconfprob_all)[i].ravel())\\n    \\n    pd.DataFrame(acc).to_csv(\\\"cv_resulsts/CV_\\\"+str(d)+\\\"_acc.txt\\\", index=False)\\n    pd.DataFrame(_tempytest).to_csv(\\\"cv_resulsts/CV_\\\"+str(d)+\\\"_tempytest.txt\\\", index=False)\\n    pd.DataFrame(_tempxtest).to_csv(\\\"cv_resulsts/CV_\\\"+str(d)+\\\"_tempxtest.txt\\\", index=False)\\n    pd.DataFrame(_tempytrain).to_csv(\\\"cv_resulsts/CV_\\\"+str(d)+\\\"_tempytrain.txt\\\", index=False)\\n    pd.DataFrame(_tempxtrain).to_csv(\\\"cv_resulsts/CV_\\\"+str(d)+\\\"_tempxtrain.txt\\\", index=False)\\n\\n\\n    pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\\n        \\\"cv_resulsts/CV_\\\"+str(d)+\\\"_ypredproba_all_class_0.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\\n        \\\"cv_resulsts/CV_\\\"+str(d)+\\\"_ypredproba_all_class_1.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\\n        \\\"cv_resulsts/CV_\\\"+str(d)+\\\"_ypredproba_all_class_2.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(tempval).to_csv(\\\"cv_resulsts/CV_\\\"+str(d)+\\\"_confmatrix.txt\\\", index=False)\";\n",
       "                var nbb_formatted_code = \"for d in range(len(data_cv)):\\n\\n    print(\\\"cv \\\", d)\\n    tempdata = data_cv[d]\\n\\n    _tempxtrain = tempdata[0][0]\\n    _tempxtest = tempdata[0][1]\\n\\n    _tempytrain = tempdata[1][0]\\n    _tempytest = tempdata[1][1]\\n\\n    clf = []\\n    acc = []\\n    finalacc = []\\n    ypredproba_all = []\\n    ypredconfprob_all = []\\n\\n    for j, classifier in enumerate(weakmodles):\\n        print(j)\\n        rf = classifier\\n        rf.fit(_tempxtrain, _tempytrain)\\n        rfpred = rf.predict(_tempxtest)\\n        print(m.f1_score(_tempytest, rfpred, average=\\\"weighted\\\"))\\n\\n        clf.append(rf)\\n        acc.append(m.f1_score(_tempytest, rfpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(rf.predict_proba(_tempxtest))\\n\\n        confmat = m.confusion_matrix(_tempytest, rfpred)\\n        confsumh = np.sum(confmat, axis=1)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    np.array(ypredconfprob_all)[0].ravel()\\n    tempval = []\\n    for i in range(len(weakmodles)):\\n        tempval.append(np.array(ypredconfprob_all)[i].ravel())\\n\\n    pd.DataFrame(acc).to_csv(\\\"cv_resulsts/CV_\\\" + str(d) + \\\"_acc.txt\\\", index=False)\\n    pd.DataFrame(_tempytest).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_tempytest.txt\\\", index=False\\n    )\\n    pd.DataFrame(_tempxtest).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_tempxtest.txt\\\", index=False\\n    )\\n    pd.DataFrame(_tempytrain).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_tempytrain.txt\\\", index=False\\n    )\\n    pd.DataFrame(_tempxtrain).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_tempxtrain.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_ypredproba_all_class_0.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_ypredproba_all_class_1.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_ypredproba_all_class_2.txt\\\", index=False\\n    )\\n\\n    pd.DataFrame(tempval).to_csv(\\n        \\\"cv_resulsts/CV_\\\" + str(d) + \\\"_confmatrix.txt\\\", index=False\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in range(len(data_cv)):\n",
    "    \n",
    "    print(\"cv \", d)\n",
    "    tempdata = data_cv[d]\n",
    "\n",
    "    _tempxtrain = tempdata[0][0]\n",
    "    _tempxtest = tempdata[0][1]\n",
    "\n",
    "    _tempytrain = tempdata[1][0]\n",
    "    _tempytest = tempdata[1][1]\n",
    "\n",
    "    clf = []\n",
    "    acc = []\n",
    "    finalacc = []\n",
    "    ypredproba_all = []\n",
    "    ypredconfprob_all = []\n",
    "\n",
    "    for j, classifier in enumerate(weakmodles):\n",
    "        print(j)\n",
    "        rf = classifier\n",
    "        rf.fit(_tempxtrain, _tempytrain)\n",
    "        rfpred = rf.predict(_tempxtest)\n",
    "        print(m.f1_score(_tempytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(rf)\n",
    "        acc.append(m.f1_score(_tempytest, rfpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(rf.predict_proba(_tempxtest))\n",
    "\n",
    "        confmat = m.confusion_matrix(_tempytest, rfpred)\n",
    "        confsumh = np.sum(confmat, axis=1)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "        \n",
    "        \n",
    "    np.array(ypredconfprob_all)[0].ravel()\n",
    "    tempval = []\n",
    "    for i in range(len(weakmodles)):\n",
    "        tempval.append(np.array(ypredconfprob_all)[i].ravel())\n",
    "    \n",
    "    pd.DataFrame(acc).to_csv(\"cv_resulsts/CV_\"+str(d)+\"_acc.txt\", index=False)\n",
    "    pd.DataFrame(_tempytest).to_csv(\"cv_resulsts/CV_\"+str(d)+\"_tempytest.txt\", index=False)\n",
    "    pd.DataFrame(_tempxtest).to_csv(\"cv_resulsts/CV_\"+str(d)+\"_tempxtest.txt\", index=False)\n",
    "    pd.DataFrame(_tempytrain).to_csv(\"cv_resulsts/CV_\"+str(d)+\"_tempytrain.txt\", index=False)\n",
    "    pd.DataFrame(_tempxtrain).to_csv(\"cv_resulsts/CV_\"+str(d)+\"_tempxtrain.txt\", index=False)\n",
    "\n",
    "\n",
    "    pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\n",
    "        \"cv_resulsts/CV_\"+str(d)+\"_ypredproba_all_class_0.txt\", index=False\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\n",
    "        \"cv_resulsts/CV_\"+str(d)+\"_ypredproba_all_class_1.txt\", index=False\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\n",
    "        \"cv_resulsts/CV_\"+str(d)+\"_ypredproba_all_class_2.txt\", index=False\n",
    "    )\n",
    "\n",
    "    pd.DataFrame(tempval).to_csv(\"cv_resulsts/CV_\"+str(d)+\"_confmatrix.txt\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
