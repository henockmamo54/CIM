{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "from multiscorer import MultiScorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import average\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Read the data set\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data set\n",
    "x_original = pd.read_csv(\"../../../../../dataset/XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_original = pd.read_csv(\"../../../../../dataset/TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Downsample the majority class and upsample the minority\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = MultiScorer({                                               # Create a MultiScorer instance\n",
    "  'accuracy_score': (m.accuracy_score, {}),\n",
    "  'precision_score': (m.precision_score, {'average': 'weighted'}),  \n",
    "  'recall_score': (m.recall_score, {'average': 'weighted'}),  \n",
    "  'f1_score': (m.f1_score, {'average': 'weighted'})               # Param 'average' will be passed to precision_score as kwarg \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Generate the classifier models \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    [0, 1, 8, 9, 10],[0, 1, 6, 8, 10],[0, 1, 7, 9, 10],[0, 1, 2, 8, 10],\n",
    "    [0, 1, 5, 8, 10],[0, 1, 5, 6, 11],[0, 1, 7, 8, 10],[0, 1, 9, 10, 11],\n",
    "    [0, 1, 5, 10, 11],[0, 1, 2, 5, 11]\n",
    "]\n",
    "\n",
    "RF_acc = []\n",
    "RF_pre = []\n",
    "RF_rec = []\n",
    "RF_f1 = []\n",
    "\n",
    "RF_acc_cv = []\n",
    "RF_pre_cv = []\n",
    "RF_rec_cv = []\n",
    "RF_f1_cv = []\n",
    "\n",
    "RF_acc_cv_std = []\n",
    "RF_pre_cv_std = []\n",
    "RF_rec_cv_std = []\n",
    "RF_f1_cv_std = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    print(f)\n",
    "    f = list(f)\n",
    "    xtrain = train.iloc[:, f]\n",
    "    xtest = test.iloc[:, f]\n",
    "\n",
    "    ytest = test.iloc[:, -1]\n",
    "    ytrain = train.iloc[:, -1]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "    randomseed = 42\n",
    "\n",
    "    # sm = SMOTENC(\n",
    "    #     random_state=randomseed,\n",
    "    #     categorical_features=[1],  # [6, 7, 8, 9, 10],\n",
    "    #     sampling_strategy=\"minority\",\n",
    "    # )\n",
    "\n",
    "    sm = SMOTE(random_state=randomseed, sampling_strategy=\"minority\")\n",
    "\n",
    "    X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "    xtrain = X_res\n",
    "    ytrain = y_res\n",
    "\n",
    "    rf_12 = RandomForestClassifier(\n",
    "        random_state=randomseed,\n",
    "        n_estimators=100,\n",
    "        max_depth=12,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=10,\n",
    "        max_features=\"auto\",\n",
    "    )\n",
    "    rf_12.fit(xtrain, ytrain)\n",
    "\n",
    "    ypred = rf_12.predict(xtest)\n",
    "\n",
    "    RF_acc.append(m.accuracy_score(ytest, ypred))\n",
    "    RF_pre.append(m.precision_score(ytest, ypred, average=\"weighted\"))\n",
    "    RF_rec.append(m.recall_score(ytest, ypred, average=\"weighted\"))\n",
    "    RF_f1.append(m.f1_score(ytest, ypred, average=\"weighted\"))\n",
    "\n",
    "    scores = model_selection.cross_val_score(\n",
    "        rf_12, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    RF_acc_cv.append(scores.mean())\n",
    "    RF_acc_cv_std.append(scores.std())\n",
    "\n",
    "#     cross_val_score(rf_12, xtrain, ytrain, scoring=scorer, cv=10)\n",
    "#     results = scorer.get_results()\n",
    "\n",
    "#     RF_acc_cv.append(average(results[\"accuracy_score\"]))\n",
    "#     RF_acc_cv_std.append(np.std(results[\"accuracy_score\"]))\n",
    "#     RF_pre_cv.append(average(results[\"precision_score\"]))\n",
    "#     RF_pre_cv_std.append(np.std(results[\"precision_score\"]))\n",
    "#     RF_rec_cv.append(average(results[\"recall_score\"]))\n",
    "#     RF_rec_cv_std.append(np.std(results[\"recall_score\"]))\n",
    "#     RF_f1_cv.append(average(results[\"f1_score\"]))\n",
    "#     RF_f1_cv_std.append(np.std(results[\"f1_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(RF_acc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_acc = []\n",
    "XGB_pre = []\n",
    "XGB_rec = []\n",
    "XGB_f1 = []\n",
    "\n",
    "XGB_acc_cv = []\n",
    "XGB_pre_cv = []\n",
    "XGB_rec_cv = []\n",
    "XGB_f1_cv = []\n",
    "\n",
    "XGB_acc_cv_std = []\n",
    "XGB_pre_cv_std = []\n",
    "XGB_rec_cv_std = []\n",
    "XGB_f1_cv_std = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    print(f)\n",
    "    f = list(f)\n",
    "    xtrain = train.iloc[:, f]\n",
    "    xtest = test.iloc[:, f]\n",
    "\n",
    "    ytest = test.iloc[:, -1]\n",
    "    ytrain = train.iloc[:, -1]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "    randomseed = 42\n",
    "\n",
    "    # sm = SMOTENC(\n",
    "    #     random_state=randomseed,\n",
    "    #     categorical_features=[1],  # [6, 7, 8, 9, 10],\n",
    "    #     sampling_strategy=\"minority\",\n",
    "    # )\n",
    "\n",
    "    sm = SMOTE(random_state=randomseed, sampling_strategy=\"minority\")\n",
    "\n",
    "    X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "    xtrain = X_res\n",
    "    ytrain = y_res\n",
    "\n",
    "    xgb_model_12 = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\", random_state=randomseed\n",
    "    )\n",
    "    xgb_model_12.fit(xtrain, ytrain)\n",
    "\n",
    "    ypred = xgb_model_12.predict(xtest)\n",
    "\n",
    "    XGB_acc.append(m.accuracy_score(ytest, ypred))\n",
    "    XGB_pre.append(m.precision_score(ytest, ypred, average=\"weighted\"))\n",
    "    XGB_rec.append(m.recall_score(ytest, ypred, average=\"weighted\"))\n",
    "    XGB_f1.append(m.f1_score(ytest, ypred, average=\"weighted\"))\n",
    "\n",
    "    scores = model_selection.cross_val_score(\n",
    "        xgb_model_12, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    XGB_acc_cv.append(scores.mean())\n",
    "    XGB_acc_cv_std.append(scores.std())\n",
    "\n",
    "#     cross_val_score(xgb_model_12, xtrain, ytrain, scoring=scorer, cv=10)\n",
    "#     results = scorer.get_results()\n",
    "\n",
    "#     XGB_acc_cv.append(average(results[\"accuracy_score\"]))\n",
    "#     XGB_acc_cv_std.append(np.std(results[\"accuracy_score\"]))\n",
    "#     XGB_pre_cv.append(average(results[\"precision_score\"]))\n",
    "#     XGB_pre_cv_std.append(np.std(results[\"precision_score\"]))\n",
    "#     XGB_rec_cv.append(average(results[\"recall_score\"]))\n",
    "#     XGB_rec_cv_std.append(np.std(results[\"recall_score\"]))\n",
    "#     XGB_f1_cv.append(average(results[\"f1_score\"]))\n",
    "#     XGB_f1_cv_std.append(np.std(results[\"f1_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_acc = []\n",
    "SVM_pre = []\n",
    "SVM_rec = []\n",
    "SVM_f1 = []\n",
    "\n",
    "SVM_acc_cv = []\n",
    "SVM_pre_cv = []\n",
    "SVM_rec_cv = []\n",
    "SVM_f1_cv = []\n",
    "\n",
    "SVM_acc_cv_std = []\n",
    "SVM_pre_cv_std = []\n",
    "SVM_rec_cv_std = []\n",
    "SVM_f1_cv_std = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    print(f)\n",
    "    f = list(f)\n",
    "    xtrain = train.iloc[:, f]\n",
    "    xtest = test.iloc[:, f]\n",
    "\n",
    "    ytest = test.iloc[:, -1]\n",
    "    ytrain = train.iloc[:, -1]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    xtrain = scaler.fit_transform(xtrain)\n",
    "    xtest = scaler.transform(xtest)\n",
    "    randomseed = 42\n",
    "\n",
    "    # sm = SMOTENC(\n",
    "    #     random_state=randomseed,\n",
    "    #     categorical_features=[1],  # [6, 7, 8, 9, 10],\n",
    "    #     sampling_strategy=\"minority\",\n",
    "    # )\n",
    "\n",
    "    sm = SMOTE(random_state=randomseed, sampling_strategy=\"minority\")\n",
    "\n",
    "    X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "    xtrain = X_res\n",
    "    ytrain = y_res\n",
    "\n",
    "    scv_12 = svmgpu(\n",
    "        C=100,\n",
    "        cache_size=None,\n",
    "        class_weight={},\n",
    "        coef0=0.0,\n",
    "        decision_function_shape=\"ovo\",\n",
    "        degree=3,\n",
    "        gamma=0.1,\n",
    "        gpu_id=0,\n",
    "        kernel=\"linear\",\n",
    "        max_iter=-1,\n",
    "        max_mem_size=-1,\n",
    "        n_jobs=-1,\n",
    "        probability=False,\n",
    "        random_state=None,\n",
    "        shrinking=False,\n",
    "        tol=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    scv_12.fit(xtrain, ytrain)\n",
    "\n",
    "    ypred = scv_12.predict(xtest)\n",
    "\n",
    "    SVM_acc.append(m.accuracy_score(ytest, ypred))\n",
    "    SVM_pre.append(m.precision_score(ytest, ypred, average=\"weighted\"))\n",
    "    SVM_rec.append(m.recall_score(ytest, ypred, average=\"weighted\"))\n",
    "    SVM_f1.append(m.f1_score(ytest, ypred, average=\"weighted\"))\n",
    "\n",
    "    scores = model_selection.cross_val_score(\n",
    "        scv_12, xtrain, ytrain, cv=10, scoring=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    SVM_acc_cv.append(scores.mean())\n",
    "    SVM_acc_cv_std.append(scores.std())\n",
    "    \n",
    "#     cross_val_score(scv_12, xtrain, ytrain, scoring=scorer, cv=10)\n",
    "#     results = scorer.get_results()\n",
    "\n",
    "#     SVM_acc_cv.append(average(results[\"accuracy_score\"]))\n",
    "#     SVM_acc_cv_std.append(np.std(results[\"accuracy_score\"]))\n",
    "#     SVM_pre_cv.append(average(results[\"precision_score\"]))\n",
    "#     SVM_pre_cv_std.append(np.std(results[\"precision_score\"]))\n",
    "#     SVM_rec_cv.append(average(results[\"recall_score\"]))\n",
    "#     SVM_rec_cv_std.append(np.std(results[\"recall_score\"]))\n",
    "#     SVM_f1_cv.append(average(results[\"f1_score\"]))\n",
    "#     SVM_f1_cv_std.append(np.std(results[\"f1_score\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_Result = pd.DataFrame(\n",
    "    np.array([SVM_acc, SVM_pre, SVM_rec, SVM_f1, SVM_acc_cv, SVM_acc_cv_std]).T,\n",
    "    columns=[\"SVM_acc\", \"SVM_pre\", \"SVM_rec\", \"SVM_f1\", \"SVM_acc_cv\", \"SVM_acc_cv_std\"],\n",
    ")\n",
    "SVM_Result.to_csv(\" SVM_Result.csv\", index=False)\n",
    "\n",
    "\n",
    "XGB_Result = pd.DataFrame(\n",
    "    np.array([XGB_acc, XGB_pre, XGB_rec, XGB_f1, XGB_acc_cv, XGB_acc_cv_std]).T,\n",
    "    columns=[\"XGB_acc\", \"XGB_pre\", \"XGB_rec\", \"XGB_f1\", \"XGB_acc_cv\", \"XGB_acc_cv_std\"],\n",
    ")\n",
    "XGB_Result.to_csv(\" XGB_Result.csv\", index=False)\n",
    "\n",
    "RF_Result2 = pd.DataFrame(\n",
    "    data=np.array([RF_acc, RF_pre, RF_rec, RF_f1, RF_acc_cv, RF_acc_cv_std]).T,\n",
    "    columns=[\"RF_acc\", \"RF_pre\", \"RF_rec\", \"RF_f1\", \"RF_acc_cv\", \"RF_acc_cv_std\"],\n",
    ")\n",
    "RF_Result2.to_csv(\" RF_Result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
