{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\n# from multiscorer import MultiScorer\\nfrom sklearn.model_selection import cross_val_score\\nfrom numpy import average\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nimport itertools\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\nfrom sklearn.preprocessing import MinMaxScaler\\nfrom imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\n# from multiscorer import MultiScorer\\nfrom sklearn.model_selection import cross_val_score\\nfrom numpy import average\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nimport itertools\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "# from multiscorer import MultiScorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from numpy import average\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"randomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"randomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 19)\n",
      "(185843, 2)\n",
      "(169024, 20)\n",
      "(56542, 13)\n",
      "1045 17331 38166\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# read the data set\\nx_original = pd.read_csv(\\\"../../../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\\n\\ny_original = pd.read_csv(\\\"../../../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\\n\\ndata = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\\n\\n# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\\n\\ndata = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\\n\\ndiabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\\n\\ndiabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\\n\\n\\nxtrain = train.iloc[:, :-1]\\nxtest = test.iloc[:, :-1]\\n\\nytest = test.iloc[:, -1]\\nytrain = train.iloc[:, -1]\\n\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\\nrandomseed = 42\\n\\nsm = SMOTE(random_state=randomseed, sampling_strategy=\\\"minority\\\")\\n\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"# read the data set\\nx_original = pd.read_csv(\\\"../../../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\\n\\ny_original = pd.read_csv(\\\"../../../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\\n\\ndata = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\\n\\n# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\\n\\ndata = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\\n\\ndiabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\\n\\ndiabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\\n\\n\\nxtrain = train.iloc[:, :-1]\\nxtest = test.iloc[:, :-1]\\n\\nytest = test.iloc[:, -1]\\nytrain = train.iloc[:, -1]\\n\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\\nrandomseed = 42\\n\\nsm = SMOTE(random_state=randomseed, sampling_strategy=\\\"minority\\\")\\n\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read the data set\n",
    "x_original = pd.read_csv(\"../../../../dataset/XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)\n",
    "\n",
    "y_original = pd.read_csv(\"../../../../dataset/TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)\n",
    "\n",
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")\n",
    "\n",
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()\n",
    "\n",
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\n",
    "\n",
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\n",
    "\n",
    "\n",
    "xtrain = train.iloc[:, :-1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "\n",
    "ytest = test.iloc[:, -1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)\n",
    "randomseed = 42\n",
    "\n",
    "sm = SMOTE(random_state=randomseed, sampling_strategy=\"minority\")\n",
    "\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "xtrain = X_res\n",
    "ytrain = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"from keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import Dropout\\nfrom keras.layers.normalization import BatchNormalization\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom sklearn import preprocessing\\nfrom sklearn.preprocessing import MinMaxScaler\";\n",
       "                var nbb_formatted_code = \"from keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom keras.layers import Dropout\\nfrom keras.layers.normalization import BatchNormalization\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nfrom sklearn import preprocessing\\nfrom sklearn.preprocessing import MinMaxScaler\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51393, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"xtrain.shape\";\n",
       "                var nbb_formatted_code = \"xtrain.shape\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 8.8565 - accuracy: 0.3369\n",
      "Epoch 2/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.3893 - accuracy: 0.3349\n",
      "Epoch 3/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 0.3083 - accuracy: 0.3349\n",
      "Epoch 4/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 0.0609 - accuracy: 0.3333\n",
      "Epoch 5/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 0.0279 - accuracy: 0.3333\n",
      "Epoch 6/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 0.0635 - accuracy: 0.3333\n",
      "Epoch 7/150\n",
      "2570/2570 [==============================] - 4s 2ms/step - loss: 0.0061 - accuracy: 0.3333\n",
      "Epoch 8/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 0.0011 - accuracy: 0.3333\n",
      "Epoch 9/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.2518e-04 - accuracy: 0.3333\n",
      "Epoch 10/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 6.2296e-04 - accuracy: 0.3333\n",
      "Epoch 11/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.3044e-04 - accuracy: 0.3333\n",
      "Epoch 12/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.5486e-04 - accuracy: 0.3333\n",
      "Epoch 13/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.7018e-08 - accuracy: 0.3333\n",
      "Epoch 14/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.1542e-08 - accuracy: 0.3333\n",
      "Epoch 15/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.5664e-08 - accuracy: 0.3333\n",
      "Epoch 16/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.5460e-08 - accuracy: 0.3333\n",
      "Epoch 17/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 4.1938e-08 - accuracy: 0.3333\n",
      "Epoch 18/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.1724e-07 - accuracy: 0.3333\n",
      "Epoch 19/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.5068e-08 - accuracy: 0.3333\n",
      "Epoch 20/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.0429e-08 - accuracy: 0.3333\n",
      "Epoch 21/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.6053e-08 - accuracy: 0.3333\n",
      "Epoch 22/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.4272e-08 - accuracy: 0.3333\n",
      "Epoch 23/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.2043e-08 - accuracy: 0.3333\n",
      "Epoch 24/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -5.1958e-08 - accuracy: 0.3333\n",
      "Epoch 25/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -4.6020e-08 - accuracy: 0.3333\n",
      "Epoch 26/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.5216e-08 - accuracy: 0.3333\n",
      "Epoch 27/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -5.8453e-09 - accuracy: 0.3333\n",
      "Epoch 28/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.9216e-09 - accuracy: 0.3333\n",
      "Epoch 29/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 6.2721e-08 - accuracy: 0.3333\n",
      "Epoch 30/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -4.0639e-09 - accuracy: 0.3333\n",
      "Epoch 31/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.1245e-08 - accuracy: 0.3333\n",
      "Epoch 32/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.5979e-09 - accuracy: 0.3333\n",
      "Epoch 33/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.8585e-08 - accuracy: 0.3333\n",
      "Epoch 34/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -7.4226e-09 - accuracy: 0.3333\n",
      "Epoch 35/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.0653e-08 - accuracy: 0.3333\n",
      "Epoch 36/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.2322e-08 - accuracy: 0.3333\n",
      "Epoch 37/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.0392e-09 - accuracy: 0.3333\n",
      "Epoch 38/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 3.9748e-08 - accuracy: 0.3333\n",
      "Epoch 39/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.9431e-08 - accuracy: 0.3333\n",
      "Epoch 40/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.2721e-08 - accuracy: 0.3333\n",
      "Epoch 41/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.6849e-08 - accuracy: 0.3333\n",
      "Epoch 42/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.8354e-08 - accuracy: 0.3333\n",
      "Epoch 43/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 7.3113e-09 - accuracy: 0.3333\n",
      "Epoch 44/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 4.8989e-09 - accuracy: 0.3333\n",
      "Epoch 45/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 7.7956e-08 - accuracy: 0.3333\n",
      "Epoch 46/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 7.4226e-09 - accuracy: 0.3333\n",
      "Epoch 47/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.4437e-08 - accuracy: 0.3333\n",
      "Epoch 48/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 8.3133e-09 - accuracy: 0.3333\n",
      "Epoch 49/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 7.4968e-09 - accuracy: 0.3333\n",
      "Epoch 50/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.2249e-08 - accuracy: 0.3333\n",
      "Epoch 51/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.2350e-09 - accuracy: 0.3333\n",
      "Epoch 52/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.4177e-08 - accuracy: 0.3333\n",
      "Epoch 53/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -3.4125e-08 - accuracy: 0.3333\n",
      "Epoch 54/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.8575e-08 - accuracy: 0.3333\n",
      "Epoch 55/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.4381e-08 - accuracy: 0.3333\n",
      "Epoch 56/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.7649e-08 - accuracy: 0.3333\n",
      "Epoch 57/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.7546e-09 - accuracy: 0.3333\n",
      "Epoch 58/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.8649e-08 - accuracy: 0.3333\n",
      "Epoch 59/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 6.3278e-09 - accuracy: 0.3333\n",
      "Epoch 60/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 6.6432e-09 - accuracy: 0.3333\n",
      "Epoch 61/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.7556e-08 - accuracy: 0.3333\n",
      "Epoch 62/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.1154e-08 - accuracy: 0.3333\n",
      "Epoch 63/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.6849e-08 - accuracy: 0.3333\n",
      "Epoch 64/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.5216e-08 - accuracy: 0.3333\n",
      "Epoch 65/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 7.4968e-09 - accuracy: 0.3333\n",
      "Epoch 66/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -4.8989e-09 - accuracy: 0.3333\n",
      "Epoch 67/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.4938e-08 - accuracy: 0.3333\n",
      "Epoch 68/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -4.8989e-09 - accuracy: 0.3333\n",
      "Epoch 69/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.6888e-08 - accuracy: 0.3333\n",
      "Epoch 70/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 3.1546e-09 - accuracy: 0.3333\n",
      "Epoch 71/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -7.2741e-09 - accuracy: 0.3333\n",
      "Epoch 72/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 4.4981e-08 - accuracy: 0.3333\n",
      "Epoch 73/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -4.3738e-08 - accuracy: 0.3333\n",
      "Epoch 74/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 3.7373e-08 - accuracy: 0.3333\n",
      "Epoch 75/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 5.4148e-08 - accuracy: 0.3333\n",
      "Epoch 76/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 3.7113e-08 - accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 3.4441e-08 - accuracy: 0.3333\n",
      "Epoch 78/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.3268e-08 - accuracy: 0.3333\n",
      "Epoch 79/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.3620e-08 - accuracy: 0.3333\n",
      "Epoch 80/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.2305e-08 - accuracy: 0.3333\n",
      "Epoch 81/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.5291e-08 - accuracy: 0.3333\n",
      "Epoch 82/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: -1.9874e-08 - accuracy: 0.3333\n",
      "Epoch 83/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 2.5422e-09 - accuracy: 0.3333\n",
      "Epoch 84/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: -1.3268e-08 - accuracy: 0.3333\n",
      "Epoch 85/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.8651e-08 - accuracy: 0.3333\n",
      "Epoch 86/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -8.1092e-09 - accuracy: 0.3333\n",
      "Epoch 87/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -3.0804e-09 - accuracy: 0.3333\n",
      "Epoch 88/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.3732e-08 - accuracy: 0.3333\n",
      "Epoch 89/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.2535e-09 - accuracy: 0.3333\n",
      "Epoch 90/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -5.3072e-08 - accuracy: 0.3333\n",
      "Epoch 91/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -3.3216e-08 - accuracy: 0.3333\n",
      "Epoch 92/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.9030e-09 - accuracy: 0.3333\n",
      "Epoch 93/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.2080e-08 - accuracy: 0.3333\n",
      "Epoch 94/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 7.1257e-08 - accuracy: 0.3333\n",
      "Epoch 95/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 4.1567e-09 - accuracy: 0.3333\n",
      "Epoch 96/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 4.5018e-08 - accuracy: 0.3333\n",
      "Epoch 97/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 1.2025e-08 - accuracy: 0.3333\n",
      "Epoch 98/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: -3.0099e-08 - accuracy: 0.3333\n",
      "Epoch 99/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.8707e-08 - accuracy: 0.3333\n",
      "Epoch 100/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.4623e-08 - accuracy: 0.3333\n",
      "Epoch 101/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.0243e-08 - accuracy: 0.3333\n",
      "Epoch 102/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.4289e-08 - accuracy: 0.3333\n",
      "Epoch 103/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.1618e-08 - accuracy: 0.3333\n",
      "Epoch 104/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 6.6803e-10 - accuracy: 0.3333\n",
      "Epoch 105/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 6.3092e-10 - accuracy: 0.3333\n",
      "Epoch 106/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 8.4989e-09 - accuracy: 0.3333\n",
      "Epoch 107/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -4.1492e-08 - accuracy: 0.3333\n",
      "Epoch 108/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.5587e-09 - accuracy: 0.3333\n",
      "Epoch 109/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.8911e-08 - accuracy: 0.3333\n",
      "Epoch 110/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 8.2391e-09 - accuracy: 0.3333\n",
      "Epoch 111/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 7.8680e-09 - accuracy: 0.3333\n",
      "Epoch 112/150\n",
      "2570/2570 [==============================] - 4s 2ms/step - loss: -2.1897e-09 - accuracy: 0.3333\n",
      "Epoch 113/150\n",
      "2570/2570 [==============================] - 4s 1ms/step - loss: 1.3843e-08 - accuracy: 0.3333\n",
      "Epoch 114/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.6803e-10 - accuracy: 0.3333\n",
      "Epoch 115/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 3.3402e-09 - accuracy: 0.3333\n",
      "Epoch 116/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -7.1071e-09 - accuracy: 0.3333\n",
      "Epoch 117/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.1144e-04 - accuracy: 0.3333\n",
      "Epoch 118/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -0.0042 - accuracy: 0.3333\n",
      "Epoch 119/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 0.0016 - accuracy: 0.3333\n",
      "Epoch 120/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 0.0011 - accuracy: 0.3333 \n",
      "Epoch 121/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -7.8865e-09 - accuracy: 0.3333\n",
      "Epoch 122/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -3.0989e-08 - accuracy: 0.3333\n",
      "Epoch 123/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.8948e-08 - accuracy: 0.3333\n",
      "Epoch 124/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.5216e-09 - accuracy: 0.3333\n",
      "Epoch 125/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.1600e-08 - accuracy: 0.3333\n",
      "Epoch 126/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -3.0433e-09 - accuracy: 0.3333\n",
      "Epoch 127/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.8519e-08 - accuracy: 0.3333\n",
      "Epoch 128/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -6.7917e-09 - accuracy: 0.3333\n",
      "Epoch 129/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.1060e-08 - accuracy: 0.3333\n",
      "Epoch 130/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.8111e-08 - accuracy: 0.3333\n",
      "Epoch 131/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 7.0515e-09 - accuracy: 0.3333\n",
      "Epoch 132/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.5587e-09 - accuracy: 0.3333\n",
      "Epoch 133/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.4845e-10 - accuracy: 0.3333\n",
      "Epoch 134/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 5.5670e-11 - accuracy: 0.3333\n",
      "Epoch 135/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.5518e-04 - accuracy: 0.3333\n",
      "Epoch 136/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.0948e-08 - accuracy: 0.3333\n",
      "Epoch 137/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 5.3164e-08 - accuracy: 0.3333\n",
      "Epoch 138/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.1950e-08 - accuracy: 0.3333\n",
      "Epoch 139/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.8577e-09 - accuracy: 0.3333\n",
      "Epoch 140/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -2.5738e-08 - accuracy: 0.3333\n",
      "Epoch 141/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.0412e-08 - accuracy: 0.3333\n",
      "Epoch 142/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.8391e-08 - accuracy: 0.3333\n",
      "Epoch 143/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 5.5447e-08 - accuracy: 0.3333\n",
      "Epoch 144/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -7.6824e-09 - accuracy: 0.3333\n",
      "Epoch 145/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 5.3072e-09 - accuracy: 0.3333\n",
      "Epoch 146/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.8557e-08 - accuracy: 0.3333\n",
      "Epoch 147/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.3159e-08 - accuracy: 0.3333\n",
      "Epoch 148/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 2.0301e-08 - accuracy: 0.3333\n",
      "Epoch 149/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: -1.9410e-08 - accuracy: 0.3333\n",
      "Epoch 150/150\n",
      "2570/2570 [==============================] - 3s 1ms/step - loss: 1.0985e-08 - accuracy: 0.3333\n",
      "19/19 [==============================] - 0s 630us/step - loss: -3.0518e-07 - accuracy: 0.3333\n",
      "accuracy: 33.33%\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Using Relu activation, and Adam optimizer, 50 epochs\\nmodel = Sequential()\\nmodel.add(Dense(16, input_dim=12, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\n\\n\\nmodel.add(Dense(16, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(16, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(8, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(8, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(8, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(4, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(4, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(2, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(2, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(1, activation=\\\"relu\\\"))\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=\\\"adam\\\", metrics=[\\\"accuracy\\\"])\\n# Train model\\nhistory = model.fit(xtrain, ytrain, epochs=150, batch_size=20, verbose=1)\\n# Print Accuracy\\nscores = model.evaluate(xtest, ytest)\\nprint(\\\"%s: %.2f%%\\\" % (model.metrics_names[1], scores[1] * 100))\";\n",
       "                var nbb_formatted_code = \"# Using Relu activation, and Adam optimizer, 50 epochs\\nmodel = Sequential()\\nmodel.add(Dense(16, input_dim=12, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\n\\n\\nmodel.add(Dense(16, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(16, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(8, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(8, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(8, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(4, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(4, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(2, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(2, activation=\\\"relu\\\"))\\nmodel.add(Dropout(0.2, input_shape=(60,)))\\nmodel.add(BatchNormalization())\\n\\nmodel.add(Dense(1, activation=\\\"relu\\\"))\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=\\\"adam\\\", metrics=[\\\"accuracy\\\"])\\n# Train model\\nhistory = model.fit(xtrain, ytrain, epochs=150, batch_size=20, verbose=1)\\n# Print Accuracy\\nscores = model.evaluate(xtest, ytest)\\nprint(\\\"%s: %.2f%%\\\" % (model.metrics_names[1], scores[1] * 100))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using Relu activation, and Adam optimizer, 50 epochs\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=12, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(2, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(2, activation=\"relu\"))\n",
    "model.add(Dropout(0.2, input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation=\"relu\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# Train model\n",
    "history = model.fit(xtrain, ytrain, epochs=150, batch_size=20, verbose=1)\n",
    "# Print Accuracy\n",
    "scores = model.evaluate(xtest, ytest)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"from sklearn.ensemble import RandomForestClassifier\";\n",
       "                var nbb_formatted_code = \"from sklearn.ensemble import RandomForestClassifier\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"from sklearn.base import clone\\n\\n\\ndef drop_col_feat_imp(model, X_train, y_train, random_state=42):\\n\\n    # clone the model to have the exact same specification as the one initially trained\\n    model_clone = clone(model)\\n    # set random_state for comparability\\n    model_clone.random_state = random_state\\n    # training and scoring the benchmark model\\n    model_clone.fit(X_train, y_train)\\n    benchmark_score = model_clone.score(X_train, y_train)\\n    # list for storing feature importances\\n    importances = []\\n\\n    # iterating over all columns and storing feature importance (difference between benchmark and new model)\\n    for col in X_train.columns:\\n        model_clone = clone(model)\\n        model_clone.random_state = random_state\\n        model_clone.fit(X_train.drop(col, axis=1), y_train)\\n        drop_col_score = model_clone.score(X_train.drop(col, axis=1), y_train)\\n        importances.append(benchmark_score - drop_col_score)\\n\\n    importances_df = imp_df(X_train.columns, importances)\\n    return importances_df\";\n",
       "                var nbb_formatted_code = \"from sklearn.base import clone\\n\\n\\ndef drop_col_feat_imp(model, X_train, y_train, random_state=42):\\n\\n    # clone the model to have the exact same specification as the one initially trained\\n    model_clone = clone(model)\\n    # set random_state for comparability\\n    model_clone.random_state = random_state\\n    # training and scoring the benchmark model\\n    model_clone.fit(X_train, y_train)\\n    benchmark_score = model_clone.score(X_train, y_train)\\n    # list for storing feature importances\\n    importances = []\\n\\n    # iterating over all columns and storing feature importance (difference between benchmark and new model)\\n    for col in X_train.columns:\\n        model_clone = clone(model)\\n        model_clone.random_state = random_state\\n        model_clone.fit(X_train.drop(col, axis=1), y_train)\\n        drop_col_score = model_clone.score(X_train.drop(col, axis=1), y_train)\\n        importances.append(benchmark_score - drop_col_score)\\n\\n    importances_df = imp_df(X_train.columns, importances)\\n    return importances_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "def drop_col_feat_imp(model, X_train, y_train, random_state=42):\n",
    "\n",
    "    # clone the model to have the exact same specification as the one initially trained\n",
    "    model_clone = clone(model)\n",
    "    # set random_state for comparability\n",
    "    model_clone.random_state = random_state\n",
    "    # training and scoring the benchmark model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = model_clone.score(X_train, y_train)\n",
    "    # list for storing feature importances\n",
    "    importances = []\n",
    "\n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in X_train.columns:\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis=1), y_train)\n",
    "        drop_col_score = model_clone.score(X_train.drop(col, axis=1), y_train)\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "\n",
    "    importances_df = imp_df(X_train.columns, importances)\n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"rf = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"rf = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"from sklearn.base import clone\\n\\n\\ndef imp_df(column_names, importances):\\n    df = (\\n        pd.DataFrame({\\\"feature\\\": column_names, \\\"feature_importance\\\": importances})\\n        #         .sort_values(\\\"feature_importance\\\", ascending=False)\\n        #         .reset_index(drop=True)\\n    )\\n    return df\\n\\n\\ndef drop_col_feat_imp(model, X_train, y_train, xtest, ytest, random_state=42):\\n\\n    # clone the model to have the exact same specification as the one initially trained\\n    model_clone = clone(model)\\n    # set random_state for comparability\\n    model_clone.random_state = random_state\\n    # training and scoring the benchmark model\\n    model_clone.fit(X_train, y_train)\\n    benchmark_score = model_clone.score(xtest, ytest)\\n    benchmark_featureimportance = model_clone.feature_importances_\\n\\n    print(benchmark_score)\\n    # list for storing feature importances\\n    importances = []\\n\\n    # iterating over all columns and storing feature importance (difference between benchmark and new model)\\n    for col in X_train.columns:\\n        print(col)\\n        model_clone = clone(model)\\n        model_clone.random_state = random_state\\n        model_clone.fit(X_train.drop(col, axis=1), y_train)\\n        drop_col_score = model_clone.score(xtest.drop(col, axis=1), ytest)\\n        importances.append(benchmark_score - drop_col_score)\\n        print(benchmark_score - drop_col_score, drop_col_score)\\n\\n    importances_df = imp_df(X_train.columns, importances)\\n    return importances_df, benchmark_score, benchmark_featureimportance\";\n",
       "                var nbb_formatted_code = \"from sklearn.base import clone\\n\\n\\ndef imp_df(column_names, importances):\\n    df = (\\n        pd.DataFrame({\\\"feature\\\": column_names, \\\"feature_importance\\\": importances})\\n        #         .sort_values(\\\"feature_importance\\\", ascending=False)\\n        #         .reset_index(drop=True)\\n    )\\n    return df\\n\\n\\ndef drop_col_feat_imp(model, X_train, y_train, xtest, ytest, random_state=42):\\n\\n    # clone the model to have the exact same specification as the one initially trained\\n    model_clone = clone(model)\\n    # set random_state for comparability\\n    model_clone.random_state = random_state\\n    # training and scoring the benchmark model\\n    model_clone.fit(X_train, y_train)\\n    benchmark_score = model_clone.score(xtest, ytest)\\n    benchmark_featureimportance = model_clone.feature_importances_\\n\\n    print(benchmark_score)\\n    # list for storing feature importances\\n    importances = []\\n\\n    # iterating over all columns and storing feature importance (difference between benchmark and new model)\\n    for col in X_train.columns:\\n        print(col)\\n        model_clone = clone(model)\\n        model_clone.random_state = random_state\\n        model_clone.fit(X_train.drop(col, axis=1), y_train)\\n        drop_col_score = model_clone.score(xtest.drop(col, axis=1), ytest)\\n        importances.append(benchmark_score - drop_col_score)\\n        print(benchmark_score - drop_col_score, drop_col_score)\\n\\n    importances_df = imp_df(X_train.columns, importances)\\n    return importances_df, benchmark_score, benchmark_featureimportance\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "def imp_df(column_names, importances):\n",
    "    df = (\n",
    "        pd.DataFrame({\"feature\": column_names, \"feature_importance\": importances})\n",
    "        #         .sort_values(\"feature_importance\", ascending=False)\n",
    "        #         .reset_index(drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_col_feat_imp(model, X_train, y_train, xtest, ytest, random_state=42):\n",
    "\n",
    "    # clone the model to have the exact same specification as the one initially trained\n",
    "    model_clone = clone(model)\n",
    "    # set random_state for comparability\n",
    "    model_clone.random_state = random_state\n",
    "    # training and scoring the benchmark model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = model_clone.score(xtest, ytest)\n",
    "    benchmark_featureimportance = model_clone.feature_importances_\n",
    "\n",
    "    print(benchmark_score)\n",
    "    # list for storing feature importances\n",
    "    importances = []\n",
    "\n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in X_train.columns:\n",
    "        print(col)\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis=1), y_train)\n",
    "        drop_col_score = model_clone.score(xtest.drop(col, axis=1), ytest)\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "        print(benchmark_score - drop_col_score, drop_col_score)\n",
    "\n",
    "    importances_df = imp_df(X_train.columns, importances)\n",
    "    return importances_df, benchmark_score, benchmark_featureimportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "L100800\n",
      "0.046666666666666634 0.6866666666666666\n",
      "L104600\n",
      "0.011666666666666603 0.7216666666666667\n",
      "L103000\n",
      "0.0 0.7333333333333333\n",
      "S000300\n",
      "0.0016666666666665941 0.7316666666666667\n",
      "L101700\n",
      "0.0 0.7333333333333333\n",
      "L100700\n",
      "-0.0050000000000000044 0.7383333333333333\n",
      "FIELD_33\n",
      "0.0 0.7333333333333333\n",
      "FIELD_38\n",
      "-0.0033333333333334103 0.7366666666666667\n",
      "FIELD_40\n",
      "0.004999999999999893 0.7283333333333334\n",
      "FIELD_31\n",
      "0.004999999999999893 0.7283333333333334\n",
      "SEX\n",
      "0.009999999999999898 0.7233333333333334\n",
      "AGE\n",
      "0.009999999999999898 0.7233333333333334\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"importances_df, benchmark_score, benchmark_featureimportance = drop_col_feat_imp(\\n    rf,\\n    pd.DataFrame(xtrain, columns=data.columns[:-1]),\\n    ytrain,\\n    pd.DataFrame(xtest, columns=data.columns[:-1]),\\n    ytest,\\n    randomseed,\\n)\";\n",
       "                var nbb_formatted_code = \"importances_df, benchmark_score, benchmark_featureimportance = drop_col_feat_imp(\\n    rf,\\n    pd.DataFrame(xtrain, columns=data.columns[:-1]),\\n    ytrain,\\n    pd.DataFrame(xtest, columns=data.columns[:-1]),\\n    ytest,\\n    randomseed,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_df, benchmark_score, benchmark_featureimportance = drop_col_feat_imp(\n",
    "    rf,\n",
    "    pd.DataFrame(xtrain, columns=data.columns[:-1]),\n",
    "    ytrain,\n",
    "    pd.DataFrame(xtest, columns=data.columns[:-1]),\n",
    "    ytest,\n",
    "    randomseed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"Finalvalue = pd.DataFrame()\\nFinalvalue[\\\"features\\\"] = data.columns[:-1]\\nFinalvalue[\\\"benchmark_featureimportance\\\"] = benchmark_featureimportance\\nFinalvalue[\\\"importances_df\\\"] = -importances_df.feature_importance\\nFinalvalue[\\\"newScore\\\"] = benchmark_score - importances_df.feature_importance\\nFinalvalue = Finalvalue.sort_values(\\n    by=\\\"benchmark_featureimportance\\\", ascending=False\\n).reset_index(drop=True)\";\n",
       "                var nbb_formatted_code = \"Finalvalue = pd.DataFrame()\\nFinalvalue[\\\"features\\\"] = data.columns[:-1]\\nFinalvalue[\\\"benchmark_featureimportance\\\"] = benchmark_featureimportance\\nFinalvalue[\\\"importances_df\\\"] = -importances_df.feature_importance\\nFinalvalue[\\\"newScore\\\"] = benchmark_score - importances_df.feature_importance\\nFinalvalue = Finalvalue.sort_values(\\n    by=\\\"benchmark_featureimportance\\\", ascending=False\\n).reset_index(drop=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Finalvalue = pd.DataFrame()\n",
    "Finalvalue[\"features\"] = data.columns[:-1]\n",
    "Finalvalue[\"benchmark_featureimportance\"] = benchmark_featureimportance\n",
    "Finalvalue[\"importances_df\"] = -importances_df.feature_importance\n",
    "Finalvalue[\"newScore\"] = benchmark_score - importances_df.feature_importance\n",
    "Finalvalue = Finalvalue.sort_values(\n",
    "    by=\"benchmark_featureimportance\", ascending=False\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 12 artists>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"plt.rcParams[\\\"figure.figsize\\\"] = (15, 7)\\nplt.title(\\\"Feature importance\\\")\\nplt.bar(Finalvalue.features, Finalvalue.benchmark_featureimportance)\";\n",
       "                var nbb_formatted_code = \"plt.rcParams[\\\"figure.figsize\\\"] = (15, 7)\\nplt.title(\\\"Feature importance\\\")\\nplt.bar(Finalvalue.features, Finalvalue.benchmark_featureimportance)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (15, 7)\n",
    "plt.title(\"Feature importance\")\n",
    "plt.bar(Finalvalue.features, Finalvalue.benchmark_featureimportance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fa43590e80>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"plt.bar(Finalvalue.features, Finalvalue.importances_df)\\nplt.title(\\\"Accuracy Loss\\\")\\nplt.plot(Finalvalue.features, np.full((12, 1), 0.0), color=\\\"green\\\")\";\n",
       "                var nbb_formatted_code = \"plt.bar(Finalvalue.features, Finalvalue.importances_df)\\nplt.title(\\\"Accuracy Loss\\\")\\nplt.plot(Finalvalue.features, np.full((12, 1), 0.0), color=\\\"green\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(Finalvalue.features, Finalvalue.importances_df)\n",
    "plt.title(\"Accuracy Loss\")\n",
    "plt.plot(Finalvalue.features, np.full((12, 1), 0.0), color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fa4394a5b0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"plt.scatter(Finalvalue.features, Finalvalue.newScore)\\nplt.title(\\\"Accuracy Plot\\\")\\nplt.plot(Finalvalue.features, np.full((12, 1), 0.7333), color=\\\"green\\\")\";\n",
       "                var nbb_formatted_code = \"plt.scatter(Finalvalue.features, Finalvalue.newScore)\\nplt.title(\\\"Accuracy Plot\\\")\\nplt.plot(Finalvalue.features, np.full((12, 1), 0.7333), color=\\\"green\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Finalvalue.features, Finalvalue.newScore)\n",
    "plt.title(\"Accuracy Plot\")\n",
    "plt.plot(Finalvalue.features, np.full((12, 1), 0.7333), color=\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>benchmark_featureimportance</th>\n",
       "      <th>importances_df</th>\n",
       "      <th>newScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L100800</td>\n",
       "      <td>0.396264</td>\n",
       "      <td>-0.046667</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L104600</td>\n",
       "      <td>0.317464</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>0.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L101700</td>\n",
       "      <td>0.069805</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S000300</td>\n",
       "      <td>0.051339</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>0.731667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L103000</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGE</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L100700</td>\n",
       "      <td>0.027338</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.738333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SEX</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.723333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FIELD_38</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.736667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FIELD_40</td>\n",
       "      <td>0.010854</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FIELD_33</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FIELD_31</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>0.728333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    features  benchmark_featureimportance  importances_df  newScore\n",
       "0    L100800                     0.396264       -0.046667  0.686667\n",
       "1    L104600                     0.317464       -0.011667  0.721667\n",
       "2    L101700                     0.069805       -0.000000  0.733333\n",
       "3    S000300                     0.051339       -0.001667  0.731667\n",
       "4    L103000                     0.044488       -0.000000  0.733333\n",
       "5        AGE                     0.037111       -0.010000  0.723333\n",
       "6    L100700                     0.027338        0.005000  0.738333\n",
       "7        SEX                     0.018519       -0.010000  0.723333\n",
       "8   FIELD_38                     0.015621        0.003333  0.736667\n",
       "9   FIELD_40                     0.010854       -0.005000  0.728333\n",
       "10  FIELD_33                     0.008095       -0.000000  0.733333\n",
       "11  FIELD_31                     0.003100       -0.005000  0.728333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"Finalvalue\";\n",
       "                var nbb_formatted_code = \"Finalvalue\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Finalvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
