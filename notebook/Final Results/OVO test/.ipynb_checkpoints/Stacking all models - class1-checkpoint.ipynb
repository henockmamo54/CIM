{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "\n",
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 19)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"x_original = pd.read_csv(\\\"../../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_formatted_code = \"x_original = pd.read_csv(\\\"../../../dataset/XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original = pd.read_csv(\"../../../dataset/XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185843, 2)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"y_original = pd.read_csv(\\\"../../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_formatted_code = \"y_original = pd.read_csv(\\\"../../../dataset/TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_original = pd.read_csv(\"../../../dataset/TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    x_original, y_original, how=\\\"inner\\\", left_on=\\\"Unnamed: 0\\\", right_on=\\\"Unnamed: 0\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    x_original, y_original, how=\"inner\", left_on=\"Unnamed: 0\", right_on=\"Unnamed: 0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169024, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\";\n",
       "                var nbb_formatted_code = \"# filter the data set\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\nprint(data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56542, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800</th>\n",
       "      <th>L104600</th>\n",
       "      <th>L103000</th>\n",
       "      <th>S000300</th>\n",
       "      <th>L101700</th>\n",
       "      <th>L100700</th>\n",
       "      <th>FIELD_33</th>\n",
       "      <th>FIELD_38</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78.0</td>\n",
       "      <td>5.28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>50.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>86.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>86.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>87.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>340.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800  L104600  L103000  S000300  L101700  L100700  FIELD_33  FIELD_38  \\\n",
       "2      78.0     5.28     41.0     20.2     15.0      3.8       1.0       2.0   \n",
       "5      90.0     5.74     50.0     25.5     12.0      3.4       1.0       0.0   \n",
       "10     86.0     5.83     45.0     21.2     17.0      3.9       1.0       0.0   \n",
       "11     86.0     4.73     54.0     22.0     30.0      4.2       1.0       2.0   \n",
       "20     87.0     5.60    340.0     24.6     26.0      4.7       1.0       0.0   \n",
       "\n",
       "    FIELD_40  FIELD_31  SEX   AGE  CLASS  \n",
       "2        1.0       0.0  1.0  46.0      0  \n",
       "5        1.0       0.0  1.0  52.0      0  \n",
       "10       1.0       1.0  1.0  37.0      0  \n",
       "11       3.0       0.0  1.0  39.0      0  \n",
       "20       2.0       0.0  1.0  59.0      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"data = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = data[\\n    [\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data[\n",
    "    [\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downsample the majority class and upsample the minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045 17331 38166\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_formatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_formatted_code = \"diabetic_test = diabetic.sample(200, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(200, random_state=randomseed)\\nnormal_test = normal.sample(200, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_test = diabetic.sample(200, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(200, random_state=randomseed)\n",
    "normal_test = normal.sample(200, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_formatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 17131, 1: 17131, 0: 17131})\n",
      "17131 17131 17131\n",
      "(51393, 12) (51393,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "randomseed = 42\n",
    "\n",
    "sm = SMOTENC(\n",
    "    random_state=randomseed,\n",
    "    categorical_features=[6, 7, 8, 9, 10],\n",
    "    sampling_strategy=\"minority\",\n",
    ")\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate the classifier models based on the selected  features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_formatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "cols = []\n",
    "weakmodles = []\n",
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(np.arange(0, 12))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_formatted_code = \"rf_model_12 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=10,\\n    max_features=\\\"log2\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=2,\\n    min_samples_split=12,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=-1,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_12 = svmgpu(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(np.arange(0, 12))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_12 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=10,\n",
    "    max_features=\"log2\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=12,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=-1,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_12 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_12 = svmgpu(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_12 = SVC(\n",
    "    C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cols.append(np.arange(0, 12))\n",
    "\n",
    "# weakmodles.append(rf_model_12)\n",
    "# weakmodles.append(xgb_model_12)\n",
    "# weakmodles.append(scv_model_12)\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), rf_model_12))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), xgb_model_12))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=(np.arange(0, 12))), scv_model_12))\n",
    "\n",
    "\n",
    "estimators.append((\"rf_model_12\", rf_model_12))\n",
    "estimators.append((\"xgb_model_12\", xgb_model_12))\n",
    "estimators.append((\"scv_model_12\", scv_model_cpu_12))\n",
    "\n",
    "# estimators = [\n",
    "#     (\"rf_model_12\", rf_model_12),\n",
    "#     (\"xgb_model_12\", xgb_model_12),\n",
    "#     (\"scv_model_12\", scv_model_12),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), scv_model_5))\\n    \\n\\ncols.append([0,1,3,10,11])\\ncols.append([0,1,3,10,11])\\ncols.append([0,1,3,10,11])\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_formatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=[0, 1, 3, 10, 11]), scv_model_5))\\n\\n\\ncols.append([0, 1, 3, 10, 11])\\ncols.append([0, 1, 3, 10, 11])\\ncols.append([0, 1, 3, 10, 11])\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "xgb_model_5 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_5 = svmgpu(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "scv_model_cpu_5 = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# weakmodles.append(rf_model_5)\n",
    "# weakmodles.append(xgb_model_5)\n",
    "# weakmodles.append(scv_model_5)\n",
    "\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), rf_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), xgb_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=[0,1,3,10,11]), scv_model_5))\n",
    "    \n",
    "\n",
    "cols.append([0,1,3,10,11])\n",
    "cols.append([0,1,3,10,11])\n",
    "cols.append([0,1,3,10,11])\n",
    "\n",
    "estimators.append((\"rf_model_5\", rf_model_5))\n",
    "estimators.append((\"xgb_model_5\", xgb_model_5))\n",
    "estimators.append((\"scv_model_5\", scv_model_cpu_5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"top10colscomb = [\\n    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\\n    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective='binary:logistic',\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_formatted_code = \"top10colscomb = [\\n    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\\n    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"binary:logistic\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10colscomb = [\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 7, 9, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 7, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_10 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_10 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=42,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_10 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_10 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_10)\n",
    "    #     weakmodles.append(xgb_model_10)\n",
    "    #     weakmodles.append(scv_model_10)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_10\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + top10colscomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. 9 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"topcols9comb = [\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective='binary:logistic',\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_formatted_code = \"topcols9comb = [\\n    (0, 1, 2, 3, 5, 6, 8, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 2, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 7, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 8, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 8, 10, 11),\\n    (0, 1, 3, 4, 6, 7, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 7, 8, 11),\\n    (0, 1, 3, 5, 6, 8, 9, 10, 11),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"binary:logistic\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topcols9comb = [\n",
    "    (0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 6, 7, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 7, 8, 11),\n",
    "    (0, 1, 3, 5, 6, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_9 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_9 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_9 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_9 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    #     weakmodles.append(rf_model_9)\n",
    "    #     weakmodles.append(xgb_model_9)\n",
    "    #     weakmodles.append(scv_model_9)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_9\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + topcols9comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"top8colscomb = [\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective='binary:logistic',\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top8colscomb = [\\n    (0, 1, 2, 3, 5, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 6, 10, 11),\\n    (0, 1, 2, 3, 4, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 9, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 9, 11),\\n    (0, 1, 3, 4, 6, 9, 10, 11),\\n    (0, 1, 3, 4, 8, 9, 10, 11),\\n    (0, 1, 2, 6, 8, 9, 10, 11),\\n    (0, 1, 2, 3, 5, 8, 10, 11),\\n    (0, 1, 3, 4, 5, 6, 10, 11),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"binary:logistic\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top8colscomb = [\n",
    "    (0, 1, 2, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 6, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 9, 11),\n",
    "    (0, 1, 3, 4, 6, 9, 10, 11),\n",
    "    (0, 1, 3, 4, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 8, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 6, 10, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top8colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_8 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_8 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_8 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_8 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\n",
    "\n",
    "#     weakmodles.append(rf_model_8)\n",
    "#     weakmodles.append(xgb_model_8)\n",
    "#     weakmodles.append(scv_model_8)\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_8\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"top7colscomb = [\\n    (0, 1, 3, 5, 6, 10, 11),\\n    (0, 1, 3, 4, 5, 10, 11),\\n    (0, 1, 2, 3, 4, 10, 11),\\n    (0, 1, 2, 3, 5, 10, 11),\\n    (0, 1, 3, 6, 8, 10, 11),\\n    (0, 1, 6, 8, 9, 10, 11),\\n    (0, 1, 6, 7, 8, 9, 10),\\n    (0, 1, 2, 3, 8, 10, 11),\\n    (0, 1, 2, 6, 8, 10, 11),\\n    (0, 1, 3, 8, 9, 10, 11),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective='binary:logistic',\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top7colscomb = [\\n    (0, 1, 3, 5, 6, 10, 11),\\n    (0, 1, 3, 4, 5, 10, 11),\\n    (0, 1, 2, 3, 4, 10, 11),\\n    (0, 1, 2, 3, 5, 10, 11),\\n    (0, 1, 3, 6, 8, 10, 11),\\n    (0, 1, 6, 8, 9, 10, 11),\\n    (0, 1, 6, 7, 8, 9, 10),\\n    (0, 1, 2, 3, 8, 10, 11),\\n    (0, 1, 2, 6, 8, 10, 11),\\n    (0, 1, 3, 8, 9, 10, 11),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"binary:logistic\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top7colscomb = [\n",
    "    (0, 1, 3, 5, 6, 10, 11),\n",
    "    (0, 1, 3, 4, 5, 10, 11),\n",
    "    (0, 1, 2, 3, 4, 10, 11),\n",
    "    (0, 1, 2, 3, 5, 10, 11),\n",
    "    (0, 1, 3, 6, 8, 10, 11),\n",
    "    (0, 1, 6, 8, 9, 10, 11),\n",
    "    (0, 1, 6, 7, 8, 9, 10),\n",
    "    (0, 1, 2, 3, 8, 10, 11),\n",
    "    (0, 1, 2, 6, 8, 10, 11),\n",
    "    (0, 1, 3, 8, 9, 10, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top7colscomb\n",
    "\n",
    "rf_model_7 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_7 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_7 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_7 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\n",
    "\n",
    "#     weakmodles.append(rf_model_7)\n",
    "#     weakmodles.append(xgb_model_7)\n",
    "#     weakmodles.append(scv_model_7)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_7\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"top6colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective='binary:logistic',\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top6colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"binary:logistic\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top6colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top6colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_6 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_6 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_6 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_6 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\n",
    "\n",
    "#     weakmodles.append(rf_model_6)\n",
    "#     weakmodles.append(xgb_model_6)\n",
    "#     weakmodles.append(scv_model_6)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_6\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8. 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"top5colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective='binary:logistic',\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top5colscomb = [\\n    (0, 1, 8, 9, 10),\\n    (0, 1, 6, 8, 10),\\n    (0, 1, 7, 9, 10),\\n    (0, 1, 2, 8, 10),\\n    (0, 1, 5, 8, 10),\\n    (0, 1, 5, 6, 11),\\n    (0, 1, 7, 8, 10),\\n    (0, 1, 9, 10, 11),\\n    (0, 1, 5, 10, 11),\\n    (0, 1, 2, 5, 11),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"binary:logistic\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top5colscomb = [\n",
    "    (0, 1, 8, 9, 10),\n",
    "    (0, 1, 6, 8, 10),\n",
    "    (0, 1, 7, 9, 10),\n",
    "    (0, 1, 2, 8, 10),\n",
    "    (0, 1, 5, 8, 10),\n",
    "    (0, 1, 5, 6, 11),\n",
    "    (0, 1, 7, 8, 10),\n",
    "    (0, 1, 9, 10, 11),\n",
    "    (0, 1, 5, 10, 11),\n",
    "    (0, 1, 2, 5, 11),\n",
    "]\n",
    "\n",
    "cols = cols + top5colscomb\n",
    "\n",
    "rf_model_5_2 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_5_2 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_5_2 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_5_2 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    # max_mem_size=-1,   n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_5_2)\n",
    "    #     weakmodles.append(xgb_model_5_2)\n",
    "    #     weakmodles.append(scv_model_5_2)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_52\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"len(weakmodles)\";\n",
       "                var nbb_formatted_code = \"len(weakmodles)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(weakmodles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_formatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = np.array(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVO\n",
    "===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"def swapcolumns(trainval, testval, coldindexval):\\n    trainval[trainval != coldindexval] = 5\\n    testval[testval != coldindexval] = 5\\n\\n    trainval[trainval == coldindexval] = 0\\n    trainval[trainval == 5] = 1\\n\\n    testval[testval == coldindexval] = 0\\n    testval[testval == 5] = 1\\n\\n    return trainval, testval\\n\\n\\nxtrain_original = xtrain\\nxtest_original = xtest\\nytrain_original = ytrain\\nytest_original = ytest\";\n",
       "                var nbb_formatted_code = \"def swapcolumns(trainval, testval, coldindexval):\\n    trainval[trainval != coldindexval] = 5\\n    testval[testval != coldindexval] = 5\\n\\n    trainval[trainval == coldindexval] = 0\\n    trainval[trainval == 5] = 1\\n\\n    testval[testval == coldindexval] = 0\\n    testval[testval == 5] = 1\\n\\n    return trainval, testval\\n\\n\\nxtrain_original = xtrain\\nxtest_original = xtest\\nytrain_original = ytrain\\nytest_original = ytest\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def swapcolumns(trainval, testval, coldindexval):\n",
    "    trainval[trainval != coldindexval] = 5\n",
    "    testval[testval != coldindexval] = 5\n",
    "\n",
    "    trainval[trainval == coldindexval] = 0\n",
    "    trainval[trainval == 5] = 1\n",
    "\n",
    "    testval[testval == coldindexval] = 0\n",
    "    testval[testval == 5] = 1\n",
    "\n",
    "    return trainval, testval\n",
    "\n",
    "\n",
    "xtrain_original = xtrain\n",
    "xtest_original = xtest\n",
    "ytrain_original = ytrain\n",
    "ytest_original = ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Class 0\\n# ===========================\\nytrain = ytrain_original.copy()\\nytest = ytest_original.copy()\\nytrain, ytest = swapcolumns(ytrain, ytest, 0)\\n# =================================================\";\n",
       "                var nbb_formatted_code = \"# Class 0\\n# ===========================\\nytrain = ytrain_original.copy()\\nytest = ytest_original.copy()\\nytrain, ytest = swapcolumns(ytrain, ytest, 0)\\n# =================================================\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class 0\n",
    "# ===========================\n",
    "ytrain = ytrain_original.copy()\n",
    "ytest = ytest_original.copy()\n",
    "ytrain, ytest = swapcolumns(ytrain, ytest, 0)\n",
    "# ================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"clf = []\\nacc = []\\nfinalacc = []\\nypredproba_all = []\\nypredconfprob_all = []\";\n",
       "                var nbb_formatted_code = \"clf = []\\nacc = []\\nfinalacc = []\\nypredproba_all = []\\nypredconfprob_all = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = []\n",
    "acc = []\n",
    "finalacc = []\n",
    "ypredproba_all = []\n",
    "ypredconfprob_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.8109031491384433\n",
      "1\n",
      "0.8173286512555166\n",
      "2\n",
      "0.813098557883834\n",
      "3\n",
      "0.820855614973262\n",
      "4\n",
      "0.8224131502820027\n",
      "5\n",
      "0.8180147058823528\n",
      "6\n",
      "0.8177421014716476\n",
      "7\n",
      "0.8194980248489727\n",
      "8\n",
      "0.8198337449871191\n",
      "9\n",
      "0.8126673652346025\n",
      "10\n",
      "0.8140073540056169\n",
      "11\n",
      "0.8164661514354765\n",
      "12\n",
      "0.811320289783648\n",
      "13\n",
      "0.8137884140172812\n",
      "14\n",
      "0.813371854648779\n",
      "15\n",
      "0.8157743895448816\n",
      "16\n",
      "0.8210558814448904\n",
      "17\n",
      "0.8167345239343867\n",
      "18\n",
      "0.8104632071247327\n",
      "19\n",
      "0.8173286512555166\n",
      "20\n",
      "0.8247549019607844\n",
      "21\n",
      "0.8102345415778252\n",
      "22\n",
      "0.8188834536842923\n",
      "23\n",
      "0.8232013385387618\n",
      "24\n",
      "0.8157743895448816\n",
      "25\n",
      "0.820855614973262\n",
      "26\n",
      "0.8198337449871191\n",
      "27\n",
      "0.8126673652346025\n",
      "28\n",
      "0.8175381263616558\n",
      "29\n",
      "0.8146446078431372\n",
      "30\n",
      "0.8111145415251619\n",
      "31\n",
      "0.8155602143023526\n",
      "32\n",
      "0.8164661514354765\n",
      "33\n",
      "0.8126673652346025\n",
      "34\n",
      "0.8226142307973668\n",
      "35\n",
      "0.8182836628432482\n",
      "36\n",
      "0.807585660526837\n",
      "37\n",
      "0.8188834536842923\n",
      "38\n",
      "0.8229368734240726\n",
      "39\n",
      "0.819298608943112\n",
      "40\n",
      "0.8226142307973668\n",
      "41\n",
      "0.8182836628432482\n",
      "42\n",
      "0.8175381263616558\n",
      "43\n",
      "0.8226142307973668\n",
      "44\n",
      "0.819564242441674\n",
      "45\n",
      "0.8093517433803475\n",
      "46\n",
      "0.8155602143023526\n",
      "47\n",
      "0.8232013385387618\n",
      "48\n",
      "0.8163836680193581\n",
      "49\n",
      "0.820855614973262\n",
      "50\n",
      "0.8185465441064446\n",
      "51\n",
      "0.8173286512555166\n",
      "52\n",
      "0.8188834536842923\n",
      "53\n",
      "0.8247549019607844\n",
      "54\n",
      "0.8177421014716476\n",
      "55\n",
      "0.8259298526516218\n",
      "56\n",
      "0.8182836628432482\n",
      "57\n",
      "0.8194980248489727\n",
      "58\n",
      "0.8226142307973668\n",
      "59\n",
      "0.8182836628432482\n",
      "60\n",
      "0.8093517433803475\n",
      "61\n",
      "0.8171136209098296\n",
      "62\n",
      "0.821648780198003\n",
      "63\n",
      "0.8239712457553159\n",
      "64\n",
      "0.8239712457553159\n",
      "65\n",
      "0.8180147058823528\n",
      "66\n",
      "0.8202221972842555\n",
      "67\n",
      "0.8286492045750555\n",
      "68\n",
      "0.8237125133527113\n",
      "69\n",
      "0.8202221972842555\n",
      "70\n",
      "0.8179862877768402\n",
      "71\n",
      "0.8187186900054039\n",
      "72\n",
      "0.8217774296007998\n",
      "73\n",
      "0.8219948047527276\n",
      "74\n",
      "0.8198337449871191\n",
      "75\n",
      "0.8241731035848684\n",
      "76\n",
      "0.8204388278023782\n",
      "77\n",
      "0.8188034188034188\n",
      "78\n",
      "0.8168929787154453\n",
      "79\n",
      "0.8215545104959654\n",
      "80\n",
      "0.8234598625056019\n",
      "81\n",
      "0.8202221972842555\n",
      "82\n",
      "0.8286492045750555\n",
      "83\n",
      "0.8237125133527113\n",
      "84\n",
      "0.8202221972842555\n",
      "85\n",
      "0.8179862877768402\n",
      "86\n",
      "0.8187186900054039\n",
      "87\n",
      "0.8217774296007998\n",
      "88\n",
      "0.8219948047527276\n",
      "89\n",
      "0.8198337449871191\n",
      "90\n",
      "0.8241731035848684\n",
      "91\n",
      "0.8204388278023782\n",
      "92\n",
      "0.8188034188034188\n",
      "93\n",
      "0.8168929787154453\n",
      "94\n",
      "0.8215545104959654\n",
      "95\n",
      "0.8234598625056019\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"for i, classifier in enumerate(weakmodles):\\n    print(i)\\n    rf = classifier\\n    rf.fit(xtrain, ytrain)\\n    rfpred = rf.predict(xtest)\\n    print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, rfpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat.ravel() / 100)\";\n",
       "                var nbb_formatted_code = \"for i, classifier in enumerate(weakmodles):\\n    print(i)\\n    rf = classifier\\n    rf.fit(xtrain, ytrain)\\n    rfpred = rf.predict(xtest)\\n    print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, rfpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat.ravel() / 100)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, classifier in enumerate(weakmodles):\n",
    "    print(i)\n",
    "    rf = classifier\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    rfpred = rf.predict(xtest)\n",
    "    print(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "    clf.append(rf)\n",
    "    acc.append(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "    ypredproba_all.append(rf.predict_proba(xtest))\n",
    "\n",
    "    confmat = m.confusion_matrix(ytest, rfpred)\n",
    "    confsumh = np.sum(confmat, axis=1)\n",
    "    propconfmat = confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\n",
    "    ypredconfprob_all.append(propconfmat.ravel() / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columnselector',\n",
       "                 ColumnSelector(cols=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]),\n",
       "                                drop_axis=False)),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=3,\n",
       "                               min_child_weight=1, missing=None,\n",
       "                               n_estimators=100, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=42,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               seed=None, silent=None, subsample=1,\n",
       "                               verbosity=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"weakmodles[i]\";\n",
       "                var nbb_formatted_code = \"weakmodles[i]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weakmodles[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"np.array(ypredconfprob_all)[0].ravel()\\n\\npc1=0\\npnc1=0\\n\\ntempval = []\\n# for i in range(len(weakmodles)):\\nfor i in range(4):\\n    pc1 += (    ypredproba_all[i][:, 0] * ypredconfprob_all[i][0]\\n        + ypredproba_all[i][:, 1] * ypredconfprob_all[i][1]\\n    )\\n    pnc1 += (\\n        ypredproba_all[i][:, 0] * ypredconfprob_all[i][2]\\n        + ypredproba_all[i][:, 1] * ypredconfprob_all[i][3]\\n    )\";\n",
       "                var nbb_formatted_code = \"np.array(ypredconfprob_all)[0].ravel()\\n\\npc1 = 0\\npnc1 = 0\\n\\ntempval = []\\n# for i in range(len(weakmodles)):\\nfor i in range(4):\\n    pc1 += (\\n        ypredproba_all[i][:, 0] * ypredconfprob_all[i][0]\\n        + ypredproba_all[i][:, 1] * ypredconfprob_all[i][1]\\n    )\\n    pnc1 += (\\n        ypredproba_all[i][:, 0] * ypredconfprob_all[i][2]\\n        + ypredproba_all[i][:, 1] * ypredconfprob_all[i][3]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.array(ypredconfprob_all)[0].ravel()\n",
    "\n",
    "pc1=0\n",
    "pnc1=0\n",
    "\n",
    "tempval = []\n",
    "# for i in range(len(weakmodles)):\n",
    "for i in range(4):\n",
    "    pc1 += (    ypredproba_all[i][:, 0] * ypredconfprob_all[i][0]\n",
    "        + ypredproba_all[i][:, 1] * ypredconfprob_all[i][1]\n",
    "    )\n",
    "    pnc1 += (\n",
    "        ypredproba_all[i][:, 0] * ypredconfprob_all[i][2]\n",
    "        + ypredproba_all[i][:, 1] * ypredconfprob_all[i][3]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8133333333333334"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"temp = np.zeros((ytest_original.shape[0], 2))\\ntemp[:, 0] = pc1\\ntemp[:, 1] = pnc1\\nm.accuracy_score(ytest, np.argmax(temp, axis=1))\";\n",
       "                var nbb_formatted_code = \"temp = np.zeros((ytest_original.shape[0], 2))\\ntemp[:, 0] = pc1\\ntemp[:, 1] = pnc1\\nm.accuracy_score(ytest, np.argmax(temp, axis=1))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = np.zeros((ytest_original.shape[0], 2))\n",
    "temp[:, 0] = pc1\n",
    "temp[:, 1] = pnc1\n",
    "m.accuracy_score(ytest, np.argmax(temp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151,  49,  63, 337], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"m.confusion_matrix(ytest, np.argmax(temp, axis=1)).ravel()\";\n",
       "                var nbb_formatted_code = \"m.confusion_matrix(ytest, np.argmax(temp, axis=1)).ravel()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.confusion_matrix(ytest, np.argmax(temp, axis=1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"pd.DataFrame(temp).to_csv(\\\"class_1.txt\\\", index=False)\\npd.DataFrame(m.confusion_matrix(ytest, np.argmax(temp, axis=1)).ravel()\\n            ).to_csv(\\\"confusion_matrix_class_1.txt\\\", index=False)\";\n",
       "                var nbb_formatted_code = \"pd.DataFrame(temp).to_csv(\\\"class_1.txt\\\", index=False)\\npd.DataFrame(m.confusion_matrix(ytest, np.argmax(temp, axis=1)).ravel()).to_csv(\\n    \\\"confusion_matrix_class_1.txt\\\", index=False\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(temp).to_csv(\"class_1.txt\", index=False)\n",
    "pd.DataFrame(m.confusion_matrix(ytest, np.argmax(temp, axis=1)).ravel()).to_csv(\n",
    "    \"confusion_matrix_class_1.txt\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# pd.DataFrame(acc).to_csv(\\\"stackingdatatestresult/_acc.txt\\\", index=False)\\n# pd.DataFrame(ytest).to_csv(\\\"stackingdatatestresult/_ytest.txt\\\", index=False)\\n\\n\\n# pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\\n#     \\\"stackingdatatestresult/_ypredproba_all_class_0.txt\\\", index=False\\n# )\\n\\n# pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\\n#     \\\"stackingdatatestresult/_ypredproba_all_class_1.txt\\\", index=False\\n# )\\n\\n# pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\\n#     \\\"stackingdatatestresult/_ypredproba_all_class_2.txt\\\", index=False\\n# )\\n\\n# pd.DataFrame(tempval).to_csv(\\\"stackingdatatestresult/_confmatrix.txt\\\", index=False)\";\n",
       "                var nbb_formatted_code = \"# pd.DataFrame(acc).to_csv(\\\"stackingdatatestresult/_acc.txt\\\", index=False)\\n# pd.DataFrame(ytest).to_csv(\\\"stackingdatatestresult/_ytest.txt\\\", index=False)\\n\\n\\n# pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\\n#     \\\"stackingdatatestresult/_ypredproba_all_class_0.txt\\\", index=False\\n# )\\n\\n# pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\\n#     \\\"stackingdatatestresult/_ypredproba_all_class_1.txt\\\", index=False\\n# )\\n\\n# pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\\n#     \\\"stackingdatatestresult/_ypredproba_all_class_2.txt\\\", index=False\\n# )\\n\\n# pd.DataFrame(tempval).to_csv(\\\"stackingdatatestresult/_confmatrix.txt\\\", index=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pd.DataFrame(acc).to_csv(\"stackingdatatestresult/_acc.txt\", index=False)\n",
    "# pd.DataFrame(ytest).to_csv(\"stackingdatatestresult/_ytest.txt\", index=False)\n",
    "\n",
    "\n",
    "# pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\n",
    "#     \"stackingdatatestresult/_ypredproba_all_class_0.txt\", index=False\n",
    "# )\n",
    "\n",
    "# pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\n",
    "#     \"stackingdatatestresult/_ypredproba_all_class_1.txt\", index=False\n",
    "# )\n",
    "\n",
    "# pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\n",
    "#     \"stackingdatatestresult/_ypredproba_all_class_2.txt\", index=False\n",
    "# )\n",
    "\n",
    "# pd.DataFrame(tempval).to_csv(\"stackingdatatestresult/_confmatrix.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# np.std(acc)\";\n",
       "                var nbb_formatted_code = \"# np.std(acc)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# np.std(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
