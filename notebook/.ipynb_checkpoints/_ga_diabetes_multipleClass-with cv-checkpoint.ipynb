{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nfrom thundersvm import SVC as svmgpu\\nimport calculateWeightUsingGa2 as aresult\\nimport pandas as pd\\nimport itertools\\nimport random\\nfrom sklearn.ensemble import VotingClassifier\\n\\nrandomseed = 42\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nfrom thundersvm import SVC as svmgpu\\nimport calculateWeightUsingGa2 as aresult\\nimport pandas as pd\\nimport itertools\\nimport random\\nfrom sklearn.ensemble import VotingClassifier\\n\\nrandomseed = 42\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "from thundersvm import SVC as svmgpu\n",
    "import calculateWeightUsingGa2 as aresult\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "randomseed = 42\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read Dataset \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"xtest = np.array(pd.read_csv(\\\"../dataset/xtest.txt\\\"))\\nxtrain = np.array(pd.read_csv(\\\"../dataset/xtrain.txt\\\"))\\nytest_original = np.array(pd.read_csv(\\\"../dataset/ytest.txt\\\")).ravel()\\nytrain_original = np.array(pd.read_csv(\\\"../dataset/ytrain.txt\\\")).ravel()\\n\\nytrain = ytrain_original.copy()\\nytest = ytest_original.copy()\\n\\n\\nreal_xtest=xtest\\nreal_ytest=ytest_original\\n\\nx=xtrain\\ny=ytrain_original\";\n",
       "                var nbb_formatted_code = \"xtest = np.array(pd.read_csv(\\\"../dataset/xtest.txt\\\"))\\nxtrain = np.array(pd.read_csv(\\\"../dataset/xtrain.txt\\\"))\\nytest_original = np.array(pd.read_csv(\\\"../dataset/ytest.txt\\\")).ravel()\\nytrain_original = np.array(pd.read_csv(\\\"../dataset/ytrain.txt\\\")).ravel()\\n\\nytrain = ytrain_original.copy()\\nytest = ytest_original.copy()\\n\\n\\nreal_xtest = xtest\\nreal_ytest = ytest_original\\n\\nx = xtrain\\ny = ytrain_original\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtest = np.array(pd.read_csv(\"../dataset/xtest.txt\"))\n",
    "xtrain = np.array(pd.read_csv(\"../dataset/xtrain.txt\"))\n",
    "ytest_original = np.array(pd.read_csv(\"../dataset/ytest.txt\")).ravel()\n",
    "ytrain_original = np.array(pd.read_csv(\"../dataset/ytrain.txt\")).ravel()\n",
    "\n",
    "ytrain = ytrain_original.copy()\n",
    "ytest = ytest_original.copy()\n",
    "\n",
    "\n",
    "real_xtest=xtest\n",
    "real_ytest=ytest_original\n",
    "\n",
    "x=xtrain\n",
    "y=ytrain_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "************************** ==>  0\n",
      "original score 0.6799804076573547\n",
      "RF f1_score 0.6799804076573547\n",
      "RF svc 0.6829414566477141\n",
      "RF xgbc 0.7421233006475806\n",
      "[278, 445, 662, 221, 70, 484, 741, 748, 789, 503]\n",
      "0  ====================  [ 0  2  3  4  7  8 10]\n",
      "0.688485309823353\n",
      "0.7332794584683437\n",
      "1  ====================  [ 0  4  5  7  8  9 11]\n",
      "0.6878964850662964\n",
      "0.7332794584683437\n",
      "2  ====================  [ 1  4  6  7  9 10 11]\n",
      "0.659944911776227\n",
      "0.7332794584683437\n",
      "3  ====================  [ 0  1  4  6  7 10 11]\n",
      "0.6969457772926464\n",
      "0.7332794584683437\n",
      "4  ====================  [ 0  1  2  4  5 10 11]\n",
      "0.7181776561347859\n",
      "0.7332794584683437\n",
      "5  ====================  [ 1  2  3  4  6  9 10]\n",
      "0.6514581026208933\n",
      "0.7332794584683437\n",
      "6  ====================  [ 2  4  5  7  9 10 11]\n",
      "0.4054463146683723\n",
      "0.7332794584683437\n",
      "7  ====================  [ 2  4  7  8  9 10 11]\n",
      "0.45468923851488297\n",
      "0.7332794584683437\n",
      "8  ====================  [ 4  5  7  8  9 10 11]\n",
      "0.41321180007346975\n",
      "0.7332794584683437\n",
      "9  ====================  [ 1  2  3  5  6  8 11]\n",
      "0.62922968032869\n",
      "0.7332794584683437\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "11.24146352808032 [0.64127638 0.72584324 0.99694797 0.74434232 0.84577002 0.72820716\n",
      " 0.84963477 0.59082537 0.86170877 0.77238642 0.88948571 0.79728283\n",
      " 0.89249945 0.53841915 0.90245516 0.13541019 0.9027983  0.42388863\n",
      " 0.9369664  0.29757218 0.97134402 0.50183187 0.98599241]\n",
      "f1_score 0.7315084970654876\n",
      "accuracy_score 0.73\n",
      "************************** ==>  1\n",
      "original score 0.6747002805365053\n",
      "RF f1_score 0.6747002805365053\n",
      "RF svc 0.6867901462221948\n",
      "RF xgbc 0.7412993237360219\n",
      "[323, 787, 121, 372, 472, 468, 9, 104, 79, 533]\n",
      "0  ====================  [0 2 4 5 6 7 9]\n",
      "0.6732097912839753\n",
      "0.7441810057356276\n",
      "1  ====================  [ 4  5  6  7  9 10 11]\n",
      "0.41891117306164993\n",
      "0.7441810057356276\n",
      "2  ====================  [ 0  1  2  7  8  9 10]\n",
      "0.7133276508943015\n",
      "0.7441810057356276\n",
      "3  ====================  [ 0  2  6  7  8  9 10]\n",
      "0.6575084392731452\n",
      "0.7441810057356276\n",
      "4  ====================  [ 1  2  3  4  5  8 10]\n",
      "0.6583531929875401\n",
      "0.7441810057356276\n",
      "5  ====================  [1 2 3 4 5 7 9]\n",
      "0.6432145170100779\n",
      "0.7441810057356276\n",
      "6  ====================  [ 0  1  2  3  4  6 10]\n",
      "0.713403737665016\n",
      "0.7441810057356276\n",
      "7  ====================  [ 0  1  2  5  7  9 10]\n",
      "0.7045863500655773\n",
      "0.7441810057356276\n",
      "8  ====================  [ 0  1  2  4  6  9 11]\n",
      "0.7035910673830983\n",
      "0.7441810057356276\n",
      "9  ====================  [1 2 4 5 6 7 9]\n",
      "0.6453358957946242\n",
      "0.7441810057356276\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "11.946884416082538 [0.62422179 0.70144879 0.77332697 0.62071177 0.78310882 0.19644504\n",
      " 0.80337258 0.75621239 0.83909606 0.54831825 0.91827049 0.55019918\n",
      " 0.9362948  0.33707838 0.94685348 0.76989818 0.96659903 0.71912658\n",
      " 0.97350267 0.71878541 0.99118466 0.52671294 0.99970939]\n",
      "f1_score 0.7400292573759049\n",
      "accuracy_score 0.7383333333333333\n",
      "************************** ==>  2\n",
      "original score 0.6773429356581067\n",
      "RF f1_score 0.6773429356581067\n",
      "RF svc 0.6849694009271513\n",
      "RF xgbc 0.7393072272017802\n",
      "[723, 262, 573, 165, 375, 374, 173, 757, 767, 337]\n",
      "0  ====================  [ 2  3  6  7  8  9 11]\n",
      "0.41212953867112245\n",
      "0.7362259062194018\n",
      "1  ====================  [ 0  2  3  4  5  8 10]\n",
      "0.6790598682355159\n",
      "0.7362259062194018\n",
      "2  ====================  [ 1  2  5  6  8  9 10]\n",
      "0.6488941866867317\n",
      "0.7362259062194018\n",
      "3  ====================  [0 1 3 5 6 8 9]\n",
      "0.7099792836848293\n",
      "0.7362259062194018\n",
      "4  ====================  [ 0  2  6  7  9 10 11]\n",
      "0.6869680022472484\n",
      "0.7362259062194018\n",
      "5  ====================  [ 0  2  6  7  8 10 11]\n",
      "0.6836419679404522\n",
      "0.7362259062194018\n",
      "6  ====================  [ 0  1  3  5  7  8 11]\n",
      "0.7035938188505495\n",
      "0.7362259062194018\n",
      "7  ====================  [ 3  4  5  6  7  8 10]\n",
      "0.4414673147575104\n",
      "0.7362259062194018\n",
      "8  ====================  [ 3  4  5  7  8  9 11]\n",
      "0.445422855543309\n",
      "0.7362259062194018\n",
      "9  ====================  [ 0  2  4  5  7 10 11]\n",
      "0.6911156395416015\n",
      "0.7362259062194018\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10.954903839251823 [0.46656269 0.63388434 0.9950946  0.10613208 0.84153215 0.50967212\n",
      " 0.8420028  0.31689094 0.88142381 0.78978188 0.88677802 0.64368547\n",
      " 0.89976364 0.59707946 0.9176557  0.77886024 0.92326422 0.23511629\n",
      " 0.95181049 0.3048881  0.95219266 0.67115803 0.99282953]\n",
      "f1_score 0.7413972637199309\n",
      "accuracy_score 0.74\n",
      "************************** ==>  3\n",
      "original score 0.691018775833022\n",
      "RF f1_score 0.691018775833022\n",
      "RF svc 0.6812095941113174\n",
      "RF xgbc 0.7294122428969135\n",
      "[254, 541, 289, 320, 133, 612, 117, 655, 746, 690]\n",
      "0  ====================  [0 2 3 4 5 6 9]\n",
      "0.6829634417869712\n",
      "0.7319685213465631\n",
      "1  ====================  [ 1  2  4  5  6 10 11]\n",
      "0.6444636152013654\n",
      "0.7319685213465631\n",
      "2  ====================  [ 0  2  3  5  6  7 10]\n",
      "0.6814558647801958\n",
      "0.7319685213465631\n",
      "3  ====================  [ 0  2  3  7  9 10 11]\n",
      "0.6975103408185465\n",
      "0.7319685213465631\n",
      "4  ====================  [ 0  1  3  4  5  7 10]\n",
      "0.7000972586218679\n",
      "0.7319685213465631\n",
      "5  ====================  [ 1  3  4  6  7  9 11]\n",
      "0.6551724137931035\n",
      "0.7319685213465631\n",
      "6  ====================  [ 0  1  2  6  8  9 10]\n",
      "0.6971919876314261\n",
      "0.7319685213465631\n",
      "7  ====================  [ 1  4  5  7  8  9 11]\n",
      "0.6602125733012988\n",
      "0.7319685213465631\n",
      "8  ====================  [ 2  4  6  7  9 10 11]\n",
      "0.43893000454644293\n",
      "0.7319685213465631\n",
      "9  ====================  [ 2  3  4  5  8 10 11]\n",
      "0.45779309376973515\n",
      "0.7319685213465631\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10.922221653264495 [0.64170622 0.51049805 0.80700275 0.5754761  0.80900202 0.29220735\n",
      " 0.84260914 0.51718302 0.86200195 0.77970168 0.88016541 0.79641873\n",
      " 0.90101893 0.42432429 0.91698426 0.76488765 0.95350266 0.50968288\n",
      " 0.96340033 0.15995068 0.97948304 0.22903087 0.99393523]\n",
      "f1_score 0.7361028729681904\n",
      "accuracy_score 0.735\n",
      "************************** ==>  4\n",
      "original score 0.6765297679740189\n",
      "RF f1_score 0.6765297679740189\n",
      "RF svc 0.6832358226829387\n",
      "RF xgbc 0.7443720011582003\n",
      "[156, 63, 50, 611, 310, 652, 350, 676, 449, 323]\n",
      "0  ====================  [ 0  1  3  4  7 10 11]\n",
      "0.7273701298701297\n",
      "0.7350107006603003\n",
      "1  ====================  [ 0  1  2  4  5  7 10]\n",
      "0.7259314328823103\n",
      "0.7350107006603003\n",
      "2  ====================  [ 0  1  2  3  7  9 11]\n",
      "0.7045287941762177\n",
      "0.7350107006603003\n",
      "3  ====================  [ 1  3  4  6  7  9 10]\n",
      "0.6586931759345552\n",
      "0.7350107006603003\n",
      "4  ====================  [ 0  2  3  6  7  9 10]\n",
      "0.6601002650338739\n",
      "0.7350107006603003\n",
      "5  ====================  [ 1  4  5  6  8 10 11]\n",
      "0.6645543122714912\n",
      "0.7350107006603003\n",
      "6  ====================  [ 0  2  4  6  8 10 11]\n",
      "0.6816345499595053\n",
      "0.7350107006603003\n",
      "7  ====================  [2 3 4 5 6 8 9]\n",
      "0.46003203447046703\n",
      "0.7350107006603003\n",
      "8  ====================  [ 0  4  6  7  8  9 10]\n",
      "0.6691969348574263\n",
      "0.7350107006603003\n",
      "9  ====================  [0 2 4 5 6 7 9]\n",
      "0.6808081826444053\n",
      "0.7350107006603003\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "11.568431814074163 [0.47095643 0.74538015 0.99958469 0.77120505 0.78249782 0.76726397\n",
      " 0.81540602 0.76517976 0.82113628 0.35297003 0.85920476 0.3643851\n",
      " 0.87770851 0.37328006 0.90814771 0.69406549 0.93748182 0.3515962\n",
      " 0.97916067 0.46623321 0.99281745 0.53445595 0.99511362]\n",
      "f1_score 0.7400602877245018\n",
      "accuracy_score 0.7383333333333333\n",
      "************************** ==>  5\n",
      "original score 0.6671609073893565\n",
      "RF f1_score 0.6671609073893565\n",
      "RF svc 0.6815015718384989\n",
      "RF xgbc 0.7339594024620291\n",
      "[435, 551, 166, 535, 229, 251, 344, 26, 784, 406]\n",
      "0  ====================  [ 0  4  5  6  7  8 10]\n",
      "0.6631520243574573\n",
      "0.7404095045893115\n",
      "1  ====================  [ 1  2  4  5  9 10 11]\n",
      "0.6532700698767273\n",
      "0.7404095045893115\n",
      "2  ====================  [ 0  1  3  5  6  8 10]\n",
      "0.715486223134389\n",
      "0.7404095045893115\n",
      "3  ====================  [ 1  2  4  5  6  7 11]\n",
      "0.631101216460043\n",
      "0.7404095045893115\n",
      "4  ====================  [ 0  1  4  7  9 10 11]\n",
      "0.6893079971897013\n",
      "0.7404095045893115\n",
      "5  ====================  [ 0  1  7  8  9 10 11]\n",
      "0.6886455229750276\n",
      "0.7404095045893115\n",
      "6  ====================  [ 0  2  4  6  7  8 11]\n",
      "0.6810403987037931\n",
      "0.7404095045893115\n",
      "7  ====================  [0 1 2 3 5 7 8]\n",
      "0.7225619635035032\n",
      "0.7404095045893115\n",
      "8  ====================  [ 4  5  6  7  8  9 10]\n",
      "0.4034217419913844\n",
      "0.7404095045893115\n",
      "9  ====================  [ 0  3  4  6  8 10 11]\n",
      "0.6863127069009423\n",
      "0.7404095045893115\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "11.7487833538885 [0.5904752  0.6156128  0.76489477 0.58211522 0.76675448 0.54224114\n",
      " 0.81783203 0.66801597 0.82455845 0.53503492 0.83961464 0.66177327\n",
      " 0.90746026 0.63473038 0.94359973 0.60599344 0.94800475 0.6684753\n",
      " 0.96573217 0.41729322 0.98547606 0.61671318 0.99585277]\n",
      "f1_score 0.7365127365127365\n",
      "accuracy_score 0.735\n",
      "************************** ==>  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original score 0.6857235886775732\n",
      "RF f1_score 0.6857235886775732\n",
      "RF svc 0.6832358226829387\n",
      "RF xgbc 0.7318229892934472\n",
      "[605, 532, 629, 705, 683, 175, 757, 33, 598, 398]\n",
      "0  ====================  [ 1  3  4  5  8  9 11]\n",
      "0.6674378888538846\n",
      "0.7417458338125925\n",
      "1  ====================  [1 2 4 5 6 7 8]\n",
      "0.6721869392754469\n",
      "0.7417458338125925\n",
      "2  ====================  [ 1  3  5  6  8  9 10]\n",
      "0.6427928062955619\n",
      "0.7417458338125925\n",
      "3  ====================  [ 2  3  4  7  9 10 11]\n",
      "0.4601681353599512\n",
      "0.7417458338125925\n",
      "4  ====================  [ 2  3  4  5  7  8 10]\n",
      "0.44844334345052705\n",
      "0.7417458338125925\n",
      "5  ====================  [ 0  1  3  5  7  9 11]\n",
      "0.6986984276881236\n",
      "0.7417458338125925\n",
      "6  ====================  [ 3  4  5  6  7  8 10]\n",
      "0.4493601010138254\n",
      "0.7417458338125925\n",
      "7  ====================  [ 0  1  2  3  5  9 10]\n",
      "0.7176764295110462\n",
      "0.7417458338125925\n",
      "8  ====================  [1 3 4 5 7 8 9]\n",
      "0.6784636324307044\n",
      "0.7417458338125925\n",
      "9  ====================  [0 3 4 6 7 8 9]\n",
      "0.66966408574507\n",
      "0.7417458338125925\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "11.239562839364643 [0.75421496 0.746018   0.84055917 0.50572136 0.85062459 0.60639825\n",
      " 0.89402019 0.34931011 0.91580586 0.23794105 0.92818326 0.18690451\n",
      " 0.93195668 0.79412065 0.95249662 0.23667623 0.95835456 0.79793083\n",
      " 0.96176117 0.64190423 0.96784819 0.53389468 0.98511996]\n",
      "f1_score 0.7362464525998234\n",
      "accuracy_score 0.735\n",
      "************************** ==>  7\n",
      "original score 0.6774642799721772\n",
      "RF f1_score 0.6774642799721772\n",
      "RF svc 0.6849694009271513\n",
      "RF xgbc 0.7365104138658676\n",
      "[287, 479, 765, 713, 89, 222, 743, 588, 176, 512]\n",
      "0  ====================  [0 2 3 5 6 7 8]\n",
      "0.6800441459397695\n",
      "0.7419444638059267\n",
      "1  ====================  [ 1  2  3  4  6  7 10]\n",
      "0.6609644274984843\n",
      "0.7419444638059267\n",
      "2  ====================  [ 3  4  5  6  9 10 11]\n",
      "0.4141636807962523\n",
      "0.7419444638059267\n",
      "3  ====================  [ 2  3  5  6  8  9 10]\n",
      "0.4041458673733465\n",
      "0.7419444638059267\n",
      "4  ====================  [ 0  1  2  4  8 10 11]\n",
      "0.703269526163457\n",
      "0.7419444638059267\n",
      "5  ====================  [ 0  1  4  6  8  9 10]\n",
      "0.6789403148124002\n",
      "0.7419444638059267\n",
      "6  ====================  [ 2  4  6  7  8  9 10]\n",
      "0.41643289298873276\n",
      "0.7419444638059267\n",
      "7  ====================  [1 3 4 5 6 7 8]\n",
      "0.6828331745099402\n",
      "0.7419444638059267\n",
      "8  ====================  [ 0  1  3  5  7 10 11]\n",
      "0.7002385047586286\n",
      "0.7419444638059267\n",
      "9  ====================  [ 1  2  3  5  7 10 11]\n",
      "0.6675029146810084\n",
      "0.7419444638059267\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "original_scores = []\n",
    "trial1_scores = [] \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "data_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    data_cv.append([[X_train, X_test], [y_train, y_test]])\n",
    "\n",
    "\n",
    "for i in range(len(data_cv)):\n",
    "    print(\"************************** ==> \", i)\n",
    "    \n",
    "    xtrain = data_cv[i][0][0]\n",
    "    ytrain_original = data_cv[i][1][0]    \n",
    "    xtest = real_xtest  # data_cv[i][0][1]\n",
    "    ytest_original = real_ytest  # data_cv[i][1][1]    \n",
    "    \n",
    "    ytrain=ytrain_original.copy()\n",
    "    ytest=ytest_original.copy() \n",
    "    \n",
    "    # member values\n",
    "    clf = []\n",
    "    acc = []\n",
    "    finalacc = []\n",
    "    ypredproba_all = []\n",
    "    ypredconfprob_all = []\n",
    "    \n",
    "    # orginal score using random forest classifier\n",
    "    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    print(\"original score\", m.f1_score(ytest, rf.predict(xtest), average=\"weighted\"))\n",
    "    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\"weighted\"))\n",
    "    \n",
    "    \n",
    "    # generate three base classifers using RF,svm and XGBoost\n",
    "\n",
    "    #================================================= \n",
    "\n",
    "    rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "    rf.fit(xtrain,ytrain)\n",
    "    rfpred=rf.predict(xtest)\n",
    "    print('RF f1_score',m.f1_score(ytest,rfpred,average='weighted'))\n",
    "\n",
    "    clf.append(rf)\n",
    "    acc.append(m.f1_score(ytest,rfpred,average='weighted'))\n",
    "    ypredproba_all.append(rf.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,rfpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    #=================================================\n",
    "    svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\n",
    "    svc.fit(xtrain,ytrain)\n",
    "\n",
    "    svcpred=svc.predict(xtest)\n",
    "    print('RF svc',m.f1_score(ytest,svcpred,average='weighted'))\n",
    "\n",
    "    clf.append(svc)\n",
    "    acc.append(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "    ypredproba_all.append(svc.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,svcpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    #=================================================\n",
    "    xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\n",
    "    xgbc.fit(xtrain,ytrain)\n",
    "\n",
    "    xgbpred=xgbc.predict(xtest)\n",
    "    print('RF xgbc',m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "\n",
    "\n",
    "    clf.append(xgbc)\n",
    "    acc.append(m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "    ypredproba_all.append(xgbc.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,xgbpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    # =================================================\n",
    "    # =================================================\n",
    "    # generate combinations of features 12,7\n",
    "    comb = list(itertools.combinations(np.arange(0, 12, 1), 7))\n",
    "\n",
    "    # generate 10 random numbers\n",
    "    randnums = []\n",
    "    for i in range(10):\n",
    "        randnums.append(random.randrange(0, len(comb)))\n",
    "\n",
    "    print(randnums)\n",
    "\n",
    "    comb = np.array(comb)[randnums, :]\n",
    "\n",
    "\n",
    "    for i in range(len(comb)):\n",
    "        print(i, \" ==================== \", comb[i])\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\n",
    "        rf.fit(xtrain[:, comb[i]], ytrain)\n",
    "        rfpred = rf.predict(xtest[:, comb[i]])\n",
    "        print(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(rf)\n",
    "        acc.append(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\n",
    "\n",
    "        confmat = m.confusion_matrix(ytest, rfpred)\n",
    "        confsumh = np.sum(confmat, axis=0)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\n",
    "        xgbmodel.fit(xtrain, ytrain)\n",
    "        xgbmodelpred = xgbmodel.predict(xtest)\n",
    "        print(m.f1_score(ytest, xgbmodelpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(xgbmodel)\n",
    "        acc.append(m.f1_score(ytest, xgbmodelpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(xgbmodel.predict_proba(xtest))\n",
    "\n",
    "        confmat = m.confusion_matrix(ytest, xgbmodelpred)\n",
    "        confsumh = np.sum(confmat, axis=0)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "    # #=================================================\n",
    "    #Compute the weight using ga and compute the ensemble accuracy\n",
    "    import calculateWeightUsingGa2 as aresult\n",
    "    weightvalga=aresult.getbestvalues(acc)\n",
    "\n",
    "    finalval=0\n",
    "    for i in range(len(acc)):\n",
    "        finalval += weightvalga[i]*ypredproba_all[i]\n",
    "\n",
    "    print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "    print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    trial1_scores.append(m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Compute the weight using ga and compute the ensemble accuracy\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import calculateWeightUsingGa2 as aresult\n",
    "# weightvalga=aresult.getbestvalues(acc)\n",
    "\n",
    "# finalval=0\n",
    "# for i in range(len(acc)):\n",
    "#     finalval += weightvalga[i]*ypredproba_all[i]\n",
    "\n",
    "# print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "# print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. voting classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemb_clf = []\n",
    "# for i in range(len(clf)):\n",
    "#     ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\n",
    "\n",
    "# eclf3 = VotingClassifier(estimators=ensemb_clf, voting=\"soft\", flatten_transform=True)\n",
    "# eclf3 = eclf3.fit(xtrain, ytrain)\n",
    "# _acc = m.accuracy_score(ytest, eclf3.predict(xtest))\n",
    "# print(_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
