{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nfrom thundersvm import SVC as svmgpu\\nimport calculateWeightUsingGa2 as aresult\\nimport pandas as pd\\nimport itertools\\nimport random\\nfrom sklearn.ensemble import VotingClassifier\\nfrom sklearn.utils import shuffle\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.ensemble import VotingClassifier\\n\\nrandomseed = 42\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nfrom thundersvm import SVC as svmgpu\\nimport calculateWeightUsingGa2 as aresult\\nimport pandas as pd\\nimport itertools\\nimport random\\nfrom sklearn.ensemble import VotingClassifier\\nfrom sklearn.utils import shuffle\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.ensemble import VotingClassifier\\n\\nrandomseed = 42\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "from thundersvm import SVC as svmgpu\n",
    "import calculateWeightUsingGa2 as aresult\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "randomseed = 42\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read Dataset \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"data = pd.read_csv(\\\"../dataset/seeds_dataset.txt\\\", sep=\\\"\\\\t\\\", header=None)\\ndata = shuffle(data)\\n\\nle = LabelEncoder()\\ndata.iloc[:, -1] = le.fit_transform(data.iloc[:, -1])\\nx = np.array(data.iloc[:, :-1])\\ny = np.array(data.iloc[:, -1])\\n\\nprint(np.unique(y))\\n\\n# xtrain, xtest, ytrain_original, ytest_original = train_test_split(\\n#     x, y, test_size=0.3, random_state=10\\n# )\\n\\n# ytrain = ytrain_original.copy()\\n# ytest = ytest_original.copy()\";\n",
       "                var nbb_formatted_code = \"data = pd.read_csv(\\\"../dataset/seeds_dataset.txt\\\", sep=\\\"\\\\t\\\", header=None)\\ndata = shuffle(data)\\n\\nle = LabelEncoder()\\ndata.iloc[:, -1] = le.fit_transform(data.iloc[:, -1])\\nx = np.array(data.iloc[:, :-1])\\ny = np.array(data.iloc[:, -1])\\n\\nprint(np.unique(y))\\n\\n# xtrain, xtest, ytrain_original, ytest_original = train_test_split(\\n#     x, y, test_size=0.3, random_state=10\\n# )\\n\\n# ytrain = ytrain_original.copy()\\n# ytest = ytest_original.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../dataset/seeds_dataset.txt\", sep=\"\\t\", header=None)\n",
    "data = shuffle(data)\n",
    "\n",
    "le = LabelEncoder()\n",
    "data.iloc[:, -1] = le.fit_transform(data.iloc[:, -1])\n",
    "x = np.array(data.iloc[:, :-1])\n",
    "y = np.array(data.iloc[:, -1])\n",
    "\n",
    "print(np.unique(y))\n",
    "\n",
    "# xtrain, xtest, ytrain_original, ytest_original = train_test_split(\n",
    "#     x, y, test_size=0.3, random_state=10\n",
    "# )\n",
    "\n",
    "# ytrain = ytrain_original.copy()\n",
    "# ytest = ytest_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "************************** ==>  0\n",
      "original score 0.952136752136752\n",
      "RF f1_score 0.952136752136752\n",
      "RF svc 0.7833333333333334\n",
      "RF xgbc 0.8999999999999999\n",
      "[28, 25, 0, 3, 8, 12, 10, 3, 8, 34]\n",
      "0  ====================  [1 3 5 6]\n",
      "1.0\n",
      "0.8999999999999999\n",
      "1  ====================  [1 2 5 6]\n",
      "0.8999999999999999\n",
      "0.8999999999999999\n",
      "2  ====================  [0 1 2 3]\n",
      "0.8075396825396824\n",
      "0.8999999999999999\n",
      "3  ====================  [0 1 2 6]\n",
      "0.9047619047619048\n",
      "0.8999999999999999\n",
      "4  ====================  [0 1 4 6]\n",
      "0.8532356532356532\n",
      "0.8999999999999999\n",
      "5  ====================  [0 2 3 6]\n",
      "0.9521367521367521\n",
      "0.8999999999999999\n",
      "6  ====================  [0 2 3 4]\n",
      "0.9045177045177045\n",
      "0.8999999999999999\n",
      "7  ====================  [0 1 2 6]\n",
      "0.9047619047619048\n",
      "0.8999999999999999\n",
      "8  ====================  [0 1 4 6]\n",
      "0.8532356532356532\n",
      "0.8999999999999999\n",
      "9  ====================  [3 4 5 6]\n",
      "1.0\n",
      "0.8999999999999999\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.806803594733209 [0.95257059 0.27085206 0.49416326 0.99323235 0.50732433 0.50780301\n",
      " 0.51221617 0.34278511 0.66927327 0.9303316  0.73868434 0.36113844\n",
      " 0.74417135 0.97587107 0.75064331 0.92948729 0.79152451 0.93560461\n",
      " 0.81481749 0.4617755  0.81713632 0.99832644 0.89992002]\n",
      "f1_score 0.8999999999999999\n",
      "accuracy_score 0.9047619047619048\n",
      "************************** ==>  1\n",
      "original score 0.7182539682539681\n",
      "RF f1_score 0.7182539682539681\n",
      "RF svc 0.8098639455782313\n",
      "RF xgbc 0.8082010582010581\n",
      "[3, 25, 21, 13, 2, 8, 18, 0, 17, 27]\n",
      "0  ====================  [0 1 2 6]\n",
      "0.8082010582010581\n",
      "0.8082010582010581\n",
      "1  ====================  [1 2 5 6]\n",
      "0.8082010582010581\n",
      "0.8082010582010581\n",
      "2  ====================  [1 2 3 5]\n",
      "0.6717086834733893\n",
      "0.8082010582010581\n",
      "3  ====================  [0 2 4 5]\n",
      "0.8082010582010581\n",
      "0.8082010582010581\n",
      "4  ====================  [0 1 2 5]\n",
      "0.6190476190476191\n",
      "0.8082010582010581\n",
      "5  ====================  [0 1 4 6]\n",
      "0.8082010582010581\n",
      "0.8082010582010581\n",
      "6  ====================  [0 3 5 6]\n",
      "0.8082010582010581\n",
      "0.8082010582010581\n",
      "7  ====================  [0 1 2 3]\n",
      "0.6190476190476191\n",
      "0.8082010582010581\n",
      "8  ====================  [0 3 4 6]\n",
      "0.7640350877192982\n",
      "0.8082010582010581\n",
      "9  ====================  [1 3 4 6]\n",
      "0.7640350877192982\n",
      "0.8082010582010581\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "12.575026217752963 [0.34672546 0.98961949 0.56426566 0.60792262 0.6349421  0.73118666\n",
      " 0.75446633 0.28010718 0.75755618 0.82953275 0.83922467 0.2331936\n",
      " 0.86468184 0.90428857 0.91298188 0.91448221 0.95164404 0.25084669\n",
      " 0.96384567 0.42122437 0.96694127 0.49737086 0.96718853]\n",
      "f1_score 0.8082010582010581\n",
      "accuracy_score 0.8095238095238095\n",
      "************************** ==>  2\n",
      "original score 0.9523809523809523\n",
      "RF f1_score 0.9523809523809523\n",
      "RF svc 0.9523809523809523\n",
      "RF xgbc 1.0\n",
      "[8, 2, 30, 2, 32, 27, 14, 21, 33, 30]\n",
      "0  ====================  [0 1 4 6]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "1  ====================  [0 1 2 5]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "2  ====================  [2 3 4 5]\n",
      "0.9535102578580841\n",
      "0.9523809523809523\n",
      "3  ====================  [0 1 2 5]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "4  ====================  [2 3 5 6]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "5  ====================  [1 3 4 6]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "6  ====================  [0 2 4 6]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "7  ====================  [1 2 3 5]\n",
      "0.9523809523809523\n",
      "0.9523809523809523\n",
      "8  ====================  [2 4 5 6]\n",
      "1.0\n",
      "0.9523809523809523\n",
      "9  ====================  [2 3 4 5]\n",
      "0.9535102578580841\n",
      "0.9523809523809523\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.690339978136372 [0.30050653 0.33673833 0.98761029 0.44380604 0.448531   0.48512608\n",
      " 0.49756614 0.94602921 0.59513922 0.61005218 0.67978862 0.68627224\n",
      " 0.73255482 0.77709616 0.79109573 0.79725202 0.83133252 0.8379584\n",
      " 0.8639285  0.99582163 0.89889    0.9480515  0.91232359]\n",
      "f1_score 0.9523809523809523\n",
      "accuracy_score 0.9523809523809523\n",
      "************************** ==>  3\n",
      "original score 0.902721088435374\n",
      "RF f1_score 0.902721088435374\n",
      "RF svc 0.8098818474758325\n",
      "RF xgbc 0.856140350877193\n",
      "[8, 7, 9, 9, 5, 12, 15, 13, 9, 25]\n",
      "0  ====================  [0 1 4 6]\n",
      "0.9047619047619048\n",
      "0.856140350877193\n",
      "1  ====================  [0 1 4 5]\n",
      "0.8098818474758325\n",
      "0.856140350877193\n",
      "2  ====================  [0 1 5 6]\n",
      "0.856140350877193\n",
      "0.856140350877193\n",
      "3  ====================  [0 1 5 6]\n",
      "0.856140350877193\n",
      "0.856140350877193\n",
      "4  ====================  [0 1 3 5]\n",
      "0.8579431772709084\n",
      "0.856140350877193\n",
      "5  ====================  [0 2 3 6]\n",
      "0.9047619047619048\n",
      "0.856140350877193\n",
      "6  ====================  [0 2 5 6]\n",
      "0.856140350877193\n",
      "0.856140350877193\n",
      "7  ====================  [0 2 4 5]\n",
      "0.8098818474758325\n",
      "0.856140350877193\n",
      "8  ====================  [0 1 5 6]\n",
      "0.856140350877193\n",
      "0.856140350877193\n",
      "9  ====================  [1 2 5 6]\n",
      "0.856140350877193\n",
      "0.856140350877193\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.196437373602349 [0.99169405 0.23173894 0.40491873 0.99276667 0.46772576 0.26559953\n",
      " 0.54100421 0.56057776 0.60998096 0.6138669  0.68743268 0.97868497\n",
      " 0.7911958  0.99555    0.80485223 0.84443096 0.85058819 0.40085423\n",
      " 0.86482745 0.89002321 0.92707804 0.93747683 0.93766595]\n",
      "f1_score 0.856140350877193\n",
      "accuracy_score 0.8571428571428571\n",
      "************************** ==>  4\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.9055258467023173\n",
      "RF xgbc 1.0\n",
      "[19, 31, 30, 10, 20, 6, 18, 2, 15, 26]\n",
      "0  ====================  [0 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "1  ====================  [2 3 4 6]\n",
      "1.0\n",
      "1.0\n",
      "2  ====================  [2 3 4 5]\n",
      "0.9527139527139526\n",
      "1.0\n",
      "3  ====================  [0 2 3 4]\n",
      "0.9002430318219792\n",
      "1.0\n",
      "4  ====================  [1 2 3 4]\n",
      "0.9527139527139526\n",
      "1.0\n",
      "5  ====================  [0 1 3 6]\n",
      "1.0\n",
      "1.0\n",
      "6  ====================  [0 3 5 6]\n",
      "1.0\n",
      "1.0\n",
      "7  ====================  [0 1 2 5]\n",
      "0.9527139527139526\n",
      "1.0\n",
      "8  ====================  [0 2 5 6]\n",
      "1.0\n",
      "1.0\n",
      "9  ====================  [1 3 4 5]\n",
      "0.9527139527139526\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.901526331870745 [0.54187835 0.32387898 0.54193329 0.55738176 0.72599102 0.74254646\n",
      " 0.76048776 0.40587034 0.77500337 0.26261068 0.7953994  0.41708829\n",
      " 0.87181316 0.87356448 0.89778192 0.90659472 0.90776457 0.46582184\n",
      " 0.94982152 0.95678567 0.97868923 0.5078774  0.98869696]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  5\n",
      "original score 0.9047619047619048\n",
      "RF f1_score 0.9047619047619048\n",
      "RF svc 0.8584356819650937\n",
      "RF xgbc 1.0\n",
      "[3, 20, 17, 11, 33, 24, 18, 19, 25, 11]\n",
      "0  ====================  [0 1 2 6]\n",
      "1.0\n",
      "1.0\n",
      "1  ====================  [1 2 3 4]\n",
      "0.8999999999999999\n",
      "1.0\n",
      "2  ====================  [0 3 4 6]\n",
      "1.0\n",
      "1.0\n",
      "3  ====================  [0 2 3 5]\n",
      "0.9047619047619048\n",
      "1.0\n",
      "4  ====================  [2 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "5  ====================  [1 2 4 6]\n",
      "1.0\n",
      "1.0\n",
      "6  ====================  [0 3 5 6]\n",
      "1.0\n",
      "1.0\n",
      "7  ====================  [0 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "8  ====================  [1 2 5 6]\n",
      "1.0\n",
      "1.0\n",
      "9  ====================  [0 2 3 5]\n",
      "0.9047619047619048\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "16.713729178619992 [0.35987779 0.25946059 0.51688002 0.57064942 0.71322165 0.28490931\n",
      " 0.736081   0.75196011 0.81924051 0.40192981 0.81980953 0.83026547\n",
      " 0.8400889  0.87521228 0.9247743  0.94239401 0.95554751 0.95716788\n",
      " 0.9732809  0.99161528 0.99183177 0.48243394 0.99790416]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  6\n",
      "original score 0.9538926681783825\n",
      "RF f1_score 0.9538926681783825\n",
      "RF svc 0.9538926681783825\n",
      "RF xgbc 0.9538926681783825\n",
      "[12, 15, 34, 24, 25, 13, 26, 14, 32, 18]\n",
      "0  ====================  [0 2 3 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "1  ====================  [0 2 5 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "2  ====================  [3 4 5 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "3  ====================  [1 2 4 6]\n",
      "0.9538926681783825\n",
      "0.9538926681783825\n",
      "4  ====================  [1 2 5 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "5  ====================  [0 2 4 5]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "6  ====================  [1 3 4 5]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "7  ====================  [0 2 4 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "8  ====================  [2 3 5 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "9  ====================  [0 3 5 6]\n",
      "0.9095238095238096\n",
      "0.9538926681783825\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.300316768518744 [0.71781817 0.72366855 0.72908767 0.16940106 0.7489178  0.23683913\n",
      " 0.7612551  0.26255711 0.80681672 0.83160113 0.83380388 0.55611\n",
      " 0.8642498  0.64635853 0.90403801 0.64835607 0.9463994  0.64980013\n",
      " 0.9731492  0.67390187 0.97774127 0.70454828 0.99852241]\n",
      "f1_score 0.9538926681783825\n",
      "accuracy_score 0.9523809523809523\n",
      "************************** ==>  7\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF svc 1.0\n",
      "RF xgbc 1.0\n",
      "[20, 0, 6, 24, 24, 20, 33, 25, 34, 26]\n",
      "0  ====================  [1 2 3 4]\n",
      "0.9522335249889429\n",
      "1.0\n",
      "1  ====================  [0 1 2 3]\n",
      "0.9522335249889429\n",
      "1.0\n",
      "2  ====================  [0 1 3 6]\n",
      "1.0\n",
      "1.0\n",
      "3  ====================  [1 2 4 6]\n",
      "1.0\n",
      "1.0\n",
      "4  ====================  [1 2 4 6]\n",
      "1.0\n",
      "1.0\n",
      "5  ====================  [1 2 3 4]\n",
      "0.9522335249889429\n",
      "1.0\n",
      "6  ====================  [2 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "7  ====================  [1 2 5 6]\n",
      "1.0\n",
      "1.0\n",
      "8  ====================  [3 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "9  ====================  [1 3 4 5]\n",
      "0.9522335249889429\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "16.888062028336655 [0.46603653 0.52069088 0.67058218 0.2013112  0.68587351 0.30688564\n",
      " 0.70266461 0.80679457 0.83263659 0.84384083 0.86642036 0.87812445\n",
      " 0.8983607  0.33732156 0.91101643 0.9162865  0.95133386 0.95685838\n",
      " 0.95961852 0.96076958 0.98370875 0.36614825 0.99607255]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  8\n",
      "original score 0.8074074074074075\n",
      "RF f1_score 0.8074074074074075\n",
      "RF svc 0.8555866791160909\n",
      "RF xgbc 0.9028555866791163\n",
      "[27, 13, 28, 11, 7, 24, 19, 7, 14, 33]\n",
      "0  ====================  [1 3 4 6]\n",
      "0.9028555866791163\n",
      "0.9028555866791163\n",
      "1  ====================  [0 2 4 5]\n",
      "0.7596638655462185\n",
      "0.9028555866791163\n",
      "2  ====================  [1 3 5 6]\n",
      "0.9028555866791163\n",
      "0.9028555866791163\n",
      "3  ====================  [0 2 3 5]\n",
      "0.8074074074074075\n",
      "0.9028555866791163\n",
      "4  ====================  [0 1 4 5]\n",
      "0.8555866791160909\n",
      "0.9028555866791163\n",
      "5  ====================  [1 2 4 6]\n",
      "0.9028555866791163\n",
      "0.9028555866791163\n",
      "6  ====================  [0 4 5 6]\n",
      "0.9028555866791163\n",
      "0.9028555866791163\n",
      "7  ====================  [0 1 4 5]\n",
      "0.8555866791160909\n",
      "0.9028555866791163\n",
      "8  ====================  [0 2 4 6]\n",
      "0.853781512605042\n",
      "0.9028555866791163\n",
      "9  ====================  [2 4 5 6]\n",
      "0.9523809523809523\n",
      "0.9028555866791163\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.60747012370448 [0.28374498 0.38669402 0.6600415  0.75088048 0.78621154 0.15083518\n",
      " 0.80442117 0.80487875 0.82367786 0.32473084 0.83045134 0.55337972\n",
      " 0.84083908 0.8736531  0.88154504 0.90796142 0.9414713  0.6203792\n",
      " 0.95723778 0.36608921 0.97020768 0.97592662 0.97389685]\n",
      "f1_score 0.9028555866791163\n",
      "accuracy_score 0.9047619047619048\n",
      "************************** ==>  9\n",
      "original score 0.9523809523809523\n",
      "RF f1_score 0.9523809523809523\n",
      "RF svc 0.9523809523809523\n",
      "RF xgbc 1.0\n",
      "[29, 1, 23, 34, 2, 33, 3, 30, 26, 18]\n",
      "0  ====================  [1 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "1  ====================  [0 1 2 4]\n",
      "0.8568637711494854\n",
      "1.0\n",
      "2  ====================  [1 2 4 5]\n",
      "0.9523809523809523\n",
      "1.0\n",
      "3  ====================  [3 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "4  ====================  [0 1 2 5]\n",
      "0.9523809523809523\n",
      "1.0\n",
      "5  ====================  [2 4 5 6]\n",
      "0.9523809523809523\n",
      "1.0\n",
      "6  ====================  [0 1 2 6]\n",
      "0.9523809523809523\n",
      "1.0\n",
      "7  ====================  [2 3 4 5]\n",
      "0.905006105006105\n",
      "1.0\n",
      "8  ====================  [1 3 4 5]\n",
      "0.905006105006105\n",
      "1.0\n",
      "9  ====================  [0 3 5 6]\n",
      "1.0\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "16.040202742732696 [0.47178575 0.48665158 0.71523213 0.76279661 0.78834886 0.15501794\n",
      " 0.80779353 0.49805854 0.82374237 0.84407883 0.85650857 0.60403752\n",
      " 0.86656304 0.69766357 0.882575   0.71270643 0.94979022 0.22310958\n",
      " 0.95449046 0.40430992 0.97673253 0.98341748 0.98937304]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"original_scores = []\\ntrial1_scores = [] \\n\\nfrom sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(x)\\n\\nprint(kf)\\n\\ndata_cv = []\\n\\nfor train_index, test_index in kf.split(x):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    X_train, X_test = x[train_index], x[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    data_cv.append([[X_train, X_test], [y_train, y_test]])\\n\\n\\nfor i in range(len(data_cv)):\\n    print(\\\"************************** ==> \\\", i)\\n    \\n    xtrain = data_cv[i][0][0]\\n    ytrain_original = data_cv[i][1][0]    \\n    xtest = data_cv[i][0][1]\\n    ytest_original = data_cv[i][1][1]    \\n    \\n    ytrain=ytrain_original.copy()\\n    ytest=ytest_original.copy() \\n    \\n    # member values\\n    clf = []\\n    acc = []\\n    finalacc = []\\n    ypredproba_all = []\\n    ypredconfprob_all = []\\n    \\n    # orginal score using random forest classifier\\n    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain, ytrain)\\n    print(\\\"original score\\\", m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n    \\n    \\n    # generate three base classifers using RF,svm and XGBoost\\n\\n    #================================================= \\n\\n    rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain,ytrain)\\n    rfpred=rf.predict(xtest)\\n    print('RF f1_score',m.f1_score(ytest,rfpred,average='weighted'))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest,rfpred,average='weighted'))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat=m.confusion_matrix(ytest,rfpred)\\n    confsumh=np.sum(confmat,axis=1)\\n    propconfmat=confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \\n    ypredconfprob_all.append(propconfmat/100)\\n\\n    #=================================================\\n    svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\\n    svc.fit(xtrain,ytrain)\\n\\n    svcpred=svc.predict(xtest)\\n    print('RF svc',m.f1_score(ytest,svcpred,average='weighted'))\\n\\n    clf.append(svc)\\n    acc.append(m.f1_score(ytest,svcpred,average='weighted'))\\n    ypredproba_all.append(svc.predict_proba(xtest))\\n\\n    confmat=m.confusion_matrix(ytest,svcpred)\\n    confsumh=np.sum(confmat,axis=1)\\n    propconfmat=confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \\n    ypredconfprob_all.append(propconfmat/100)\\n\\n    #=================================================\\n    xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\\n    xgbc.fit(xtrain,ytrain)\\n\\n    xgbpred=xgbc.predict(xtest)\\n    print('RF xgbc',m.f1_score(ytest,xgbpred,average='weighted'))\\n\\n\\n    clf.append(xgbc)\\n    acc.append(m.f1_score(ytest,xgbpred,average='weighted'))\\n    ypredproba_all.append(xgbc.predict_proba(xtest))\\n\\n    confmat=m.confusion_matrix(ytest,xgbpred)\\n    confsumh=np.sum(confmat,axis=1)\\n    propconfmat=confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \\n    ypredconfprob_all.append(propconfmat/100)\\n\\n    # =================================================\\n    # =================================================\\n    # generate combinations of features 12,7\\n    comb = list(itertools.combinations(np.arange(0, 7, 1), 4))\\n\\n    # generate 10 random numbers\\n    randnums = []\\n    for i in range(10):\\n        randnums.append(random.randrange(0, len(comb)))\\n\\n    print(randnums)\\n\\n    comb = np.array(comb)[randnums, :]\\n\\n\\n    for i in range(len(comb)):\\n        print(i, \\\" ==================== \\\", comb[i])\\n\\n        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\\n        rf.fit(xtrain[:, comb[i]], ytrain)\\n        rfpred = rf.predict(xtest[:, comb[i]])\\n        print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n        clf.append(rf)\\n        acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\\n\\n        confmat = m.confusion_matrix(ytest, rfpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\\n        xgbmodel.fit(xtrain, ytrain)\\n        xgbmodelpred = xgbmodel.predict(xtest)\\n        print(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n\\n        clf.append(xgbmodel)\\n        acc.append(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(xgbmodel.predict_proba(xtest))\\n\\n        confmat = m.confusion_matrix(ytest, xgbmodelpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    # #=================================================\\n    #Compute the weight using ga and compute the ensemble accuracy\\n    import calculateWeightUsingGa2 as aresult\\n    weightvalga=aresult.getbestvalues(acc)\\n\\n    finalval=0\\n    for i in range(len(acc)):\\n        finalval += weightvalga[i]*ypredproba_all[i]\\n\\n    print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\\n    print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\\n    trial1_scores.append(m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\";\n",
       "                var nbb_formatted_code = \"original_scores = []\\ntrial1_scores = []\\n\\nfrom sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(x)\\n\\nprint(kf)\\n\\ndata_cv = []\\n\\nfor train_index, test_index in kf.split(x):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    X_train, X_test = x[train_index], x[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    data_cv.append([[X_train, X_test], [y_train, y_test]])\\n\\n\\nfor i in range(len(data_cv)):\\n    print(\\\"************************** ==> \\\", i)\\n\\n    xtrain = data_cv[i][0][0]\\n    ytrain_original = data_cv[i][1][0]\\n    xtest = data_cv[i][0][1]\\n    ytest_original = data_cv[i][1][1]\\n\\n    ytrain = ytrain_original.copy()\\n    ytest = ytest_original.copy()\\n\\n    # member values\\n    clf = []\\n    acc = []\\n    finalacc = []\\n    ypredproba_all = []\\n    ypredconfprob_all = []\\n\\n    # orginal score using random forest classifier\\n    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain, ytrain)\\n    print(\\\"original score\\\", m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n\\n    # generate three base classifers using RF,svm and XGBoost\\n\\n    # =================================================\\n\\n    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain, ytrain)\\n    rfpred = rf.predict(xtest)\\n    print(\\\"RF f1_score\\\", m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, rfpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n    # =================================================\\n    svc = svmgpu(random_state=randomseed, probability=True, C=100, gamma=0.0001)\\n    svc.fit(xtrain, ytrain)\\n\\n    svcpred = svc.predict(xtest)\\n    print(\\\"RF svc\\\", m.f1_score(ytest, svcpred, average=\\\"weighted\\\"))\\n\\n    clf.append(svc)\\n    acc.append(m.f1_score(ytest, svcpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(svc.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, svcpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n    # =================================================\\n    xgbc = xgb.XGBClassifier(random_state=randomseed, n_estimators=100)\\n    xgbc.fit(xtrain, ytrain)\\n\\n    xgbpred = xgbc.predict(xtest)\\n    print(\\\"RF xgbc\\\", m.f1_score(ytest, xgbpred, average=\\\"weighted\\\"))\\n\\n    clf.append(xgbc)\\n    acc.append(m.f1_score(ytest, xgbpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(xgbc.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, xgbpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n    # =================================================\\n    # =================================================\\n    # generate combinations of features 12,7\\n    comb = list(itertools.combinations(np.arange(0, 7, 1), 4))\\n\\n    # generate 10 random numbers\\n    randnums = []\\n    for i in range(10):\\n        randnums.append(random.randrange(0, len(comb)))\\n\\n    print(randnums)\\n\\n    comb = np.array(comb)[randnums, :]\\n\\n    for i in range(len(comb)):\\n        print(i, \\\" ==================== \\\", comb[i])\\n\\n        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\\n        rf.fit(xtrain[:, comb[i]], ytrain)\\n        rfpred = rf.predict(xtest[:, comb[i]])\\n        print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n        clf.append(rf)\\n        acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\\n\\n        confmat = m.confusion_matrix(ytest, rfpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\\n        xgbmodel.fit(xtrain, ytrain)\\n        xgbmodelpred = xgbmodel.predict(xtest)\\n        print(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n\\n        clf.append(xgbmodel)\\n        acc.append(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(xgbmodel.predict_proba(xtest))\\n\\n        confmat = m.confusion_matrix(ytest, xgbmodelpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    # #=================================================\\n    # Compute the weight using ga and compute the ensemble accuracy\\n    import calculateWeightUsingGa2 as aresult\\n\\n    weightvalga = aresult.getbestvalues(acc)\\n\\n    finalval = 0\\n    for i in range(len(acc)):\\n        finalval += weightvalga[i] * ypredproba_all[i]\\n\\n    print(\\n        \\\"f1_score\\\", m.f1_score(ytest, np.argmax(finalval, axis=1), average=\\\"weighted\\\")\\n    )\\n    print(\\\"accuracy_score\\\", m.accuracy_score(ytest, np.argmax(finalval, axis=1)))\\n    trial1_scores.append(\\n        m.f1_score(ytest, np.argmax(finalval, axis=1), average=\\\"weighted\\\")\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_scores = []\n",
    "trial1_scores = [] \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "data_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    data_cv.append([[X_train, X_test], [y_train, y_test]])\n",
    "\n",
    "\n",
    "for i in range(len(data_cv)):\n",
    "    print(\"************************** ==> \", i)\n",
    "    \n",
    "    xtrain = data_cv[i][0][0]\n",
    "    ytrain_original = data_cv[i][1][0]    \n",
    "    xtest = data_cv[i][0][1]\n",
    "    ytest_original = data_cv[i][1][1]    \n",
    "    \n",
    "    ytrain=ytrain_original.copy()\n",
    "    ytest=ytest_original.copy() \n",
    "    \n",
    "    # member values\n",
    "    clf = []\n",
    "    acc = []\n",
    "    finalacc = []\n",
    "    ypredproba_all = []\n",
    "    ypredconfprob_all = []\n",
    "    \n",
    "    # orginal score using random forest classifier\n",
    "    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    print(\"original score\", m.f1_score(ytest, rf.predict(xtest), average=\"weighted\"))\n",
    "    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\"weighted\"))\n",
    "    \n",
    "    \n",
    "    # generate three base classifers using RF,svm and XGBoost\n",
    "\n",
    "    #================================================= \n",
    "\n",
    "    rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "    rf.fit(xtrain,ytrain)\n",
    "    rfpred=rf.predict(xtest)\n",
    "    print('RF f1_score',m.f1_score(ytest,rfpred,average='weighted'))\n",
    "\n",
    "    clf.append(rf)\n",
    "    acc.append(m.f1_score(ytest,rfpred,average='weighted'))\n",
    "    ypredproba_all.append(rf.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,rfpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    #=================================================\n",
    "    svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\n",
    "    svc.fit(xtrain,ytrain)\n",
    "\n",
    "    svcpred=svc.predict(xtest)\n",
    "    print('RF svc',m.f1_score(ytest,svcpred,average='weighted'))\n",
    "\n",
    "    clf.append(svc)\n",
    "    acc.append(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "    ypredproba_all.append(svc.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,svcpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    #=================================================\n",
    "    xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\n",
    "    xgbc.fit(xtrain,ytrain)\n",
    "\n",
    "    xgbpred=xgbc.predict(xtest)\n",
    "    print('RF xgbc',m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "\n",
    "\n",
    "    clf.append(xgbc)\n",
    "    acc.append(m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "    ypredproba_all.append(xgbc.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,xgbpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    # =================================================\n",
    "    # =================================================\n",
    "    # generate combinations of features 12,7\n",
    "    comb = list(itertools.combinations(np.arange(0, 7, 1), 4))\n",
    "\n",
    "    # generate 10 random numbers\n",
    "    randnums = []\n",
    "    for i in range(10):\n",
    "        randnums.append(random.randrange(0, len(comb)))\n",
    "\n",
    "    print(randnums)\n",
    "\n",
    "    comb = np.array(comb)[randnums, :]\n",
    "\n",
    "\n",
    "    for i in range(len(comb)):\n",
    "        print(i, \" ==================== \", comb[i])\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\n",
    "        rf.fit(xtrain[:, comb[i]], ytrain)\n",
    "        rfpred = rf.predict(xtest[:, comb[i]])\n",
    "        print(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(rf)\n",
    "        acc.append(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\n",
    "\n",
    "        confmat = m.confusion_matrix(ytest, rfpred)\n",
    "        confsumh = np.sum(confmat, axis=0)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\n",
    "        xgbmodel.fit(xtrain, ytrain)\n",
    "        xgbmodelpred = xgbmodel.predict(xtest)\n",
    "        print(m.f1_score(ytest, xgbmodelpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(xgbmodel)\n",
    "        acc.append(m.f1_score(ytest, xgbmodelpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(xgbmodel.predict_proba(xtest))\n",
    "\n",
    "        confmat = m.confusion_matrix(ytest, xgbmodelpred)\n",
    "        confsumh = np.sum(confmat, axis=0)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "    # #=================================================\n",
    "    #Compute the weight using ga and compute the ensemble accuracy\n",
    "    import calculateWeightUsingGa2 as aresult\n",
    "    weightvalga=aresult.getbestvalues(acc)\n",
    "\n",
    "    finalval=0\n",
    "    for i in range(len(acc)):\n",
    "        finalval += weightvalga[i]*ypredproba_all[i]\n",
    "\n",
    "    print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "    print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    trial1_scores.append(m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original socre  0.9143935693935694  std  0.08406754954810602\n",
      "ga socre  0.9373470616316701  std  0.06485292795424606\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"print('original socre ',np.mean(original_scores),' std ',np.std(original_scores))\\nprint('ga socre ',np.mean(trial1_scores),' std ',np.std(trial1_scores))\";\n",
       "                var nbb_formatted_code = \"print(\\\"original socre \\\", np.mean(original_scores), \\\" std \\\", np.std(original_scores))\\nprint(\\\"ga socre \\\", np.mean(trial1_scores), \\\" std \\\", np.std(trial1_scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original socre \", np.mean(original_scores), \" std \", np.std(original_scores))\n",
    "print(\"ga socre \", np.mean(trial1_scores), \" std \", np.std(trial1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. voting classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95238095 0.95238095 0.9047619  1.         0.9047619  0.95238095\n",
      " 0.95238095 0.95238095 0.95238095 0.95238095]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"ensemb_clf = []\\nfor i in range(len(clf)):\\n    ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\\n\\neclf3 = VotingClassifier(estimators=ensemb_clf, voting=\\\"soft\\\", flatten_transform=True)\\n\\nfrom sklearn.model_selection import cross_val_score\\n\\nprint(cross_val_score(eclf3, x, y, cv=10))\";\n",
       "                var nbb_formatted_code = \"ensemb_clf = []\\nfor i in range(len(clf)):\\n    ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\\n\\neclf3 = VotingClassifier(estimators=ensemb_clf, voting=\\\"soft\\\", flatten_transform=True)\\n\\nfrom sklearn.model_selection import cross_val_score\\n\\nprint(cross_val_score(eclf3, x, y, cv=10))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemb_clf = []\n",
    "for i in range(len(clf)):\n",
    "    ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=ensemb_clf, voting=\"soft\", flatten_transform=True)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "corssvals=cross_val_score(eclf3, x, y, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corssvals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ebd05899cc4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"corssvals \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorssvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" std \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorssvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'corssvals' is not defined"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"\\nprint(\\\"corssvals \\\", np.mean(corssvals), \\\" std \\\", np.std(corssvals))\";\n",
       "                var nbb_formatted_code = \"print(\\\"corssvals \\\", np.mean(corssvals), \\\" std \\\", np.std(corssvals))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"corssvals \", np.mean(corssvals), \" std \", np.std(corssvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
