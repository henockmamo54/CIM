{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import  numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb \n",
    "from sklearn import metrics as m\n",
    "from thundersvm import SVC as svmgpu\n",
    "import calculateWeightUsingGa2 as aresult\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def swapcolumns(trainval, testval, coldindexval):\n",
    "    trainval[trainval != coldindexval] = 5\n",
    "    testval[testval != coldindexval] = 5\n",
    "\n",
    "    trainval[trainval == coldindexval] = 0\n",
    "    trainval[trainval == 5] = 1\n",
    "\n",
    "    testval[testval == coldindexval] = 0\n",
    "    testval[testval == 5] = 1\n",
    "\n",
    "    return trainval, testval\n",
    "\n",
    "\n",
    "randomseed=42\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xtest=np.array(pd.read_csv('../dataset/xtest.txt'))\n",
    "xtrain=np.array(pd.read_csv('../dataset/xtrain.txt'))\n",
    "ytest_original=np.array(pd.read_csv('../dataset/ytest.txt')).ravel()\n",
    "ytrain_original =np.array(pd.read_csv('../dataset/ytrain.txt')).ravel()\n",
    "\n",
    "# data=datasets.load_wine()\n",
    "# x=data.data\n",
    "# y=data.target\n",
    "\n",
    "# data = pd.read_csv(\"../dataset/seeds_dataset.txt\", sep=\"\\t\", header=None)\n",
    "# data = shuffle(data)\n",
    "# le = LabelEncoder()\n",
    "# data.iloc[:, -1] = le.fit_transform(data.iloc[:, -1])\n",
    "# x = data.iloc[:, :-1]\n",
    "# y = data.iloc[:, -1]\n",
    "# print(np.unique(y))\n",
    "\n",
    "# data = pd.read_csv(\"../dataset/ionosphere.data\",  header=None)\n",
    "# data = shuffle(data)\n",
    "# le = LabelEncoder()\n",
    "# data.iloc[:, -1] = le.fit_transform(data.iloc[:, -1])\n",
    "# x = data.iloc[:, :-1]\n",
    "# y = data.iloc[:, -1]\n",
    "# print(np.unique(y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xtrain,xtest,ytrain_original,ytest_original=train_test_split(x,y,random_state=randomseed,test_size=0.3) \n",
    "\n",
    "ytrain=ytrain_original.copy()\n",
    "ytest=ytest_original.copy() \n",
    "\n",
    "# ytrain, ytest = swapcolumns(ytrain, ytest, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original score 0.6765880295918836\n",
      "original score 2 0.7315606204495092\n",
      "0.6765880295918836\n",
      "0.5333333333333333\n",
      "0.7315606204495092\n",
      "[513, 29, 621, 148, 525, 444, 456, 403, 138, 268, 373, 330, 444, 255, 170, 235, 704, 419, 446, 85, 742, 649, 335, 717, 335, 467, 730, 519, 418, 298, 598, 606, 788, 122, 433, 475, 290, 316, 521, 768, 302, 132, 0, 419, 589, 246, 352, 4, 400, 561]\n",
      "0  ====================  [ 1  2  3  5  8  9 10]\n",
      "0.6556712962962963\n",
      "0.738221824835998\n",
      "1  ====================  [ 0  1  2  3  5  7 11]\n",
      "0.7030565434771402\n",
      "0.738221824835998\n",
      "2  ====================  [ 1  3  4  7  9 10 11]\n",
      "0.6614842597110264\n",
      "0.738221824835998\n",
      "3  ====================  [ 0  1  3  4  6  9 10]\n",
      "0.6946075405570086\n",
      "0.738221824835998\n",
      "4  ====================  [ 1  2  3  6  8 10 11]\n",
      "0.6432496075353218\n",
      "0.738221824835998\n",
      "5  ====================  [ 0  4  5  7  8  9 10]\n",
      "0.6480000000000001\n",
      "0.738221824835998\n",
      "6  ====================  [ 0  5  6  7  8  9 11]\n",
      "0.6717816961719403\n",
      "0.738221824835998\n",
      "7  ====================  [ 0  3  4  6  7 10 11]\n",
      "0.69892076603486\n",
      "0.738221824835998\n",
      "8  ====================  [ 0  1  3  4  5  9 10]\n",
      "0.7015160833177357\n",
      "0.738221824835998\n",
      "9  ====================  [0 2 3 4 6 7 9]\n",
      "0.6965303136634512\n",
      "0.738221824835998\n",
      "10  ====================  [ 0  2  6  7  8  9 11]\n",
      "0.6802147391292281\n",
      "0.738221824835998\n",
      "11  ====================  [ 0  2  4  5  6  9 11]\n",
      "0.6970564573375608\n",
      "0.738221824835998\n",
      "12  ====================  [ 0  4  5  7  8  9 10]\n",
      "0.6480000000000001\n",
      "0.738221824835998\n",
      "13  ====================  [ 0  2  3  4  5  6 10]\n",
      "0.6715244727667088\n",
      "0.738221824835998\n",
      "14  ====================  [ 0  1  3  5  6 10 11]\n",
      "0.7090111642743221\n",
      "0.738221824835998\n",
      "15  ====================  [ 0  1  5  6  7  9 11]\n",
      "0.7124766691738599\n",
      "0.738221824835998\n",
      "16  ====================  [ 2  3  4  7  8 10 11]\n",
      "0.5962883789412353\n",
      "0.738221824835998\n",
      "17  ====================  [ 0  3  5  6  8  9 10]\n",
      "0.6821559921871553\n",
      "0.738221824835998\n",
      "18  ====================  [ 0  4  5  7  8 10 11]\n",
      "0.6913413110442492\n",
      "0.738221824835998\n",
      "19  ====================  [ 0  1  2  4  7  9 11]\n",
      "0.7145645605497474\n",
      "0.738221824835998\n",
      "20  ====================  [ 2  4  5  8  9 10 11]\n",
      "0.5479601780019027\n",
      "0.738221824835998\n",
      "21  ====================  [ 1  4  5  6  7 10 11]\n",
      "0.654109819874471\n",
      "0.738221824835998\n",
      "22  ====================  [ 0  2  4  5  7  9 10]\n",
      "0.6832785166118499\n",
      "0.738221824835998\n",
      "23  ====================  [ 2  3  5  7  8  9 10]\n",
      "0.5393617681753275\n",
      "0.738221824835998\n",
      "24  ====================  [ 0  2  4  5  7  9 10]\n",
      "0.6832785166118499\n",
      "0.738221824835998\n",
      "25  ====================  [1 2 3 4 5 7 8]\n",
      "0.6763157894736843\n",
      "0.738221824835998\n",
      "26  ====================  [ 2  4  5  6  7  8 11]\n",
      "0.5494423131159765\n",
      "0.738221824835998\n",
      "27  ====================  [ 1  2  3  6  7  8 11]\n",
      "0.6523919753086419\n",
      "0.738221824835998\n",
      "28  ====================  [ 0  3  5  6  7 10 11]\n",
      "0.6819433674697185\n",
      "0.738221824835998\n",
      "29  ====================  [ 0  2  3  5  7  8 10]\n",
      "0.7120815429788161\n",
      "0.738221824835998\n",
      "30  ====================  [1 3 4 5 7 8 9]\n",
      "0.6763130760755514\n",
      "0.738221824835998\n",
      "31  ====================  [ 1  3  4  5  8 10 11]\n",
      "0.6654264950269118\n",
      "0.738221824835998\n",
      "32  ====================  [ 4  5  6  8  9 10 11]\n",
      "0.5466130114017438\n",
      "0.738221824835998\n",
      "33  ====================  [ 0  1  2  7  8  9 11]\n",
      "0.7133949365186689\n",
      "0.738221824835998\n",
      "34  ====================  [ 0  3  7  8  9 10 11]\n",
      "0.7020222169029319\n",
      "0.738221824835998\n",
      "35  ====================  [ 1  2  3  4  5  9 11]\n",
      "0.651452053065796\n",
      "0.738221824835998\n",
      "36  ====================  [ 0  2  3  5  6  7 11]\n",
      "0.6758577792201269\n",
      "0.738221824835998\n",
      "37  ====================  [ 0  2  3  6  9 10 11]\n",
      "0.7049526639561011\n",
      "0.738221824835998\n",
      "38  ====================  [ 1  2  3  6  7  9 11]\n",
      "0.6671622795018497\n",
      "0.738221824835998\n",
      "39  ====================  [ 3  4  5  7  8 10 11]\n",
      "0.5847768051157881\n",
      "0.738221824835998\n",
      "40  ====================  [ 0  2  3  5  7 10 11]\n",
      "0.6754004950726262\n",
      "0.738221824835998\n",
      "41  ====================  [0 1 3 4 5 7 9]\n",
      "0.7063196583839848\n",
      "0.738221824835998\n",
      "42  ====================  [0 1 2 3 4 5 6]\n",
      "0.7155502392344497\n",
      "0.738221824835998\n",
      "43  ====================  [ 0  3  5  6  8  9 10]\n",
      "0.6821559921871553\n",
      "0.738221824835998\n",
      "44  ====================  [1 3 4 5 6 7 9]\n",
      "0.6843790440783967\n",
      "0.738221824835998\n",
      "45  ====================  [ 0  1  6  7  8  9 10]\n",
      "0.6909657774380997\n",
      "0.738221824835998\n",
      "46  ====================  [ 0  2  4  7  8  9 10]\n",
      "0.6972437075936752\n",
      "0.738221824835998\n",
      "47  ====================  [ 0  1  2  3  4  5 10]\n",
      "0.7072738284457668\n",
      "0.738221824835998\n",
      "48  ====================  [ 0  3  4  6  7  8 11]\n",
      "0.7099259259259258\n",
      "0.738221824835998\n",
      "49  ====================  [ 1  2  4  6  9 10 11]\n",
      "0.6408313074979742\n",
      "0.738221824835998\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf=[]\n",
    "acc=[]\n",
    "finalacc=[]\n",
    "ypredproba_all=[]\n",
    "ypredconfprob_all=[]\n",
    "\n",
    "\n",
    "#================================================= \n",
    "\n",
    "# Class 1\n",
    "# ===========================\n",
    "ytrain = ytrain_original.copy()\n",
    "ytest = ytest_original.copy()\n",
    "ytrain,ytest= swapcolumns(ytrain,ytest,1)\n",
    "#=================================================\n",
    "\n",
    "rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "rf.fit(xtrain,ytrain)\n",
    "print('original score',m.f1_score(ytest,rf.predict(xtest),average='weighted'))\n",
    "\n",
    "\n",
    "xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\n",
    "xgbc.fit(xtrain,ytrain)\n",
    "xgbpred=xgbc.predict(xtest)\n",
    "print('original score 2',m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "\n",
    "\n",
    "#================================================= \n",
    "\n",
    "rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "rf.fit(xtrain,ytrain)\n",
    "rfpred=rf.predict(xtest)\n",
    "print(m.f1_score(ytest,rfpred,average='weighted'))\n",
    "\n",
    "clf.append(rf)\n",
    "acc.append(m.f1_score(ytest,rfpred,average='weighted'))\n",
    "ypredproba_all.append(rf.predict_proba(xtest)[:,0])\n",
    "\n",
    "confmat = m.confusion_matrix(ytest, rfpred)\n",
    "confsumh = np.sum(confmat, axis=0)\n",
    "propconfmat = confmat.copy()\n",
    "for i in range(propconfmat.shape[0]):\n",
    "    propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "ypredconfprob_all.append(propconfmat.ravel() / 100)\n",
    "\n",
    "\n",
    "#=================================================\n",
    "svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\n",
    "svc.fit(xtrain,ytrain)\n",
    "\n",
    "svcpred=svc.predict(xtest)\n",
    "print(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "\n",
    "clf.append(svc)\n",
    "acc.append(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "ypredproba_all.append(svc.predict_proba(xtest)[:,0])\n",
    "\n",
    "confmat = m.confusion_matrix(ytest, rfpred)\n",
    "confsumh = np.sum(confmat, axis=0)\n",
    "propconfmat = confmat.copy()\n",
    "for i in range(propconfmat.shape[0]):\n",
    "    propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "ypredconfprob_all.append(propconfmat.ravel() / 100)\n",
    "\n",
    "#=================================================\n",
    "xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\n",
    "xgbc.fit(xtrain,ytrain)\n",
    "\n",
    "xgbpred=xgbc.predict(xtest)\n",
    "print(m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "\n",
    "\n",
    "clf.append(xgbc)\n",
    "acc.append(m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "ypredproba_all.append(xgbc.predict_proba(xtest)[:,0])\n",
    "\n",
    "confmat = m.confusion_matrix(ytest, rfpred)\n",
    "confsumh = np.sum(confmat, axis=0)\n",
    "propconfmat = confmat.copy()\n",
    "for i in range(propconfmat.shape[0]):\n",
    "    propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "ypredconfprob_all.append(propconfmat.ravel() / 100)\n",
    "\n",
    "#=================================================\n",
    "#=================================================\n",
    "# generate combinations of features 12,6\n",
    "comb = list(itertools.combinations(np.arange(0, 12, 1), 7))\n",
    "\n",
    "# generate 50 random numbers\n",
    "randnums = []\n",
    "for i in range(50):\n",
    "    randnums.append(random.randrange(0, len(comb)))\n",
    "\n",
    "print(randnums)\n",
    "\n",
    "comb = np.array(comb)[randnums, :]\n",
    "\n",
    "\n",
    "for i in range(len(comb)):\n",
    "    print(i, \" ==================== \", comb[i])\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\n",
    "    rf.fit(xtrain[:, comb[i]], ytrain)\n",
    "    rfpred = rf.predict(xtest[:, comb[i]])\n",
    "    print(m.f1_score(ytest, rfpred,average='weighted'))\n",
    "\n",
    "    clf.append(rf)\n",
    "    acc.append(m.f1_score(ytest, rfpred,average='weighted'))\n",
    "    ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]])[:,0])\n",
    "\n",
    "    confmat = m.confusion_matrix(ytest, rfpred)\n",
    "    confsumh = np.sum(confmat, axis=0)\n",
    "    propconfmat = confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "    ypredconfprob_all.append(propconfmat.ravel() / 100)\n",
    "\n",
    "    xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\n",
    "    xgbmodel.fit(xtrain, ytrain)\n",
    "    xgbmodelpred = xgbmodel.predict(xtest)\n",
    "    print(m.f1_score(ytest, xgbmodelpred,average='weighted'))\n",
    "\n",
    "    clf.append(xgbmodel)\n",
    "    acc.append(m.f1_score(ytest, xgbmodelpred,average='weighted'))\n",
    "    ypredproba_all.append(xgbmodel.predict_proba(xtest)[:,0])\n",
    "\n",
    "    confmat = m.confusion_matrix(ytest, xgbmodelpred)\n",
    "    confsumh = np.sum(confmat, axis=0)\n",
    "    propconfmat = confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "    ypredconfprob_all.append(propconfmat.ravel() / 100)\n",
    "\n",
    "# #=================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-62d9ff9cec6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pd_clf=pd.DataFrame(list(clf))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpd_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd_ypredproba_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypredproba_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpd_ypredconfprob_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypredconfprob_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[1;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Must pass 2-d input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input"
     ]
    }
   ],
   "source": [
    "# pd_clf=pd.DataFrame(list(clf))\n",
    "pd_acc=pd.DataFrame(acc) \n",
    "pd_ypredproba_all=pd.DataFrame(np.array(ypredproba_all))\n",
    "pd_ypredconfprob_all=pd.DataFrame(ypredconfprob_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classname='class1.txt'\n",
    "# pd_acc.to_csv('pd_acc_'+classname,sep=',',index=False) \n",
    "# pd_ypredproba_all.to_csv('pd_ypredproba_all_'+classname,sep=',',index=False)\n",
    "# pd_ypredconfprob_all.to_csv('pd_ypredconfprob_all_'+classname,sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(ytrain_original).to_csv('ytrain_original.txt',sep=',',index=False)\n",
    "# pd.DataFrame(ytest).to_csv('ytest_class1.txt',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_ypredconfprob_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import calculateWeightUsingGa2 as aresult\n",
    "weightvalga=aresult.getbestvalues(acc)\n",
    "\n",
    "temp=pd.DataFrame(ypredproba_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(ypredproba_all).shape)\n",
    "print(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finalval=0\n",
    "for i in range(len(acc)):\n",
    "    \n",
    "    finalval += weightvalga[i]* np.column_stack( (temp.iloc[i,:],1- temp.iloc[i,:]))\n",
    "        \n",
    "    print(\n",
    "        m.accuracy_score(ytest, np.argmax(np.column_stack( (temp.iloc[i,:],1- temp.iloc[i,:])), axis=1)),\n",
    "        acc[i],\n",
    "    )\n",
    "    \n",
    "\n",
    "print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalval=[0,]\n",
    "# for i in range(len(acc)):\n",
    "#     finalval += [weightvalga[i]*ypredproba_all[i],weightvalga[i]* (1-ypredproba_all[i])]\n",
    "\n",
    "# print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "# print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.4],\n",
       "       [0.7, 0.4],\n",
       "       [0.2, 0.4],\n",
       "       ...,\n",
       "       [0.8, 0.8],\n",
       "       [0.7, 0.9],\n",
       "       [0.3, 0.7]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([ypredproba_all[0],(1-ypredproba_all[0])]).reshape(600,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-06db7d8563e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mypredproba_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mypredproba_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "np.column_stack( (ypredproba_all[0,:],1- ypredproba_all[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame(ypredproba_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4, 1.6],\n",
       "       [0.8, 1.2],\n",
       "       [1.4, 0.6],\n",
       "       ...,\n",
       "       [0.2, 1.8],\n",
       "       [1.4, 0.6],\n",
       "       [0.6, 1.4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack( (temp.iloc[0,:],1- temp.iloc[0,:])) + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6683333333333333 0.6765880295918836\n",
      "0.3333333333333333 0.5333333333333333\n",
      "0.7333333333333333 0.7315606204495092\n",
      "0.65 0.6556712962962963\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6966666666666667 0.7030565434771402\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.655 0.6614842597110264\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6883333333333334 0.6946075405570086\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.64 0.6432496075353218\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.64 0.6480000000000001\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6633333333333333 0.6717816961719403\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6916666666666667 0.69892076603486\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.695 0.7015160833177357\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.69 0.6965303136634512\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6733333333333333 0.6802147391292281\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.69 0.6970564573375608\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.64 0.6480000000000001\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.665 0.6715244727667088\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7033333333333334 0.7090111642743221\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7066666666666667 0.7124766691738599\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.5866666666666667 0.5962883789412353\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6766666666666666 0.6821559921871553\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.685 0.6913413110442492\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7083333333333334 0.7145645605497474\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.535 0.5479601780019027\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6466666666666666 0.654109819874471\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6766666666666666 0.6832785166118499\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.5266666666666666 0.5393617681753275\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6766666666666666 0.6832785166118499\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.67 0.6763157894736843\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.5366666666666666 0.5494423131159765\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6466666666666666 0.6523919753086419\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.675 0.6819433674697185\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.705 0.7120815429788161\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6716666666666666 0.6763130760755514\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6583333333333333 0.6654264950269118\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.5333333333333333 0.5466130114017438\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7083333333333334 0.7133949365186689\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.695 0.7020222169029319\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6433333333333333 0.651452053065796\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6666666666666666 0.6758577792201269\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6983333333333334 0.7049526639561011\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.66 0.6671622795018497\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.5733333333333334 0.5847768051157881\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6666666666666666 0.6754004950726262\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7 0.7063196583839848\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.71 0.7155502392344497\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6766666666666666 0.6821559921871553\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6783333333333333 0.6843790440783967\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6866666666666666 0.6909657774380997\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6916666666666667 0.6972437075936752\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7016666666666667 0.7072738284457668\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.7033333333333334 0.7099259259259258\n",
      "0.7416666666666667 0.738221824835998\n",
      "0.6333333333333333 0.6408313074979742\n",
      "0.7416666666666667 0.738221824835998\n",
      "f1_score 0.7415041974474262\n",
      "accuracy_score 0.7416666666666667\n"
     ]
    }
   ],
   "source": [
    "finalval=0\n",
    "for i in range(len(acc)):\n",
    "    \n",
    "    finalval += ypredproba_all[i]\n",
    "        \n",
    "    print(\n",
    "        m.accuracy_score(ytest, np.argmax(ypredproba_all[i], axis=1)),\n",
    "        acc[i],\n",
    "    )\n",
    "    \n",
    "\n",
    "print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.7, 0.3],\n",
       "       ...,\n",
       "       [0.1, 0.9],\n",
       "       [0.7, 0.3],\n",
       "       [0.3, 0.7]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ypredproba_all[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\n",
    "svc.fit(xtrain,ytrain)\n",
    "\n",
    "svcpred=svc.predict(xtest)\n",
    "print(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "\n",
    "temppp=svc.predict_proba(xtest)\n",
    "\n",
    "# clf.append(svc)\n",
    "# acc.append(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "# ypredproba_all.append(svc.predict_proba(xtest))\n",
    "\n",
    "# confmat = m.confusion_matrix(ytest, rfpred)\n",
    "# confsumh = np.sum(confmat, axis=0)\n",
    "# propconfmat = confmat.copy()\n",
    "# for i in range(propconfmat.shape[0]):\n",
    "#     propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "# ypredconfprob_all.append(propconfmat / 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(temppp,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72328657, 0.27671343],\n",
       "       [0.65977824, 0.3402218 ],\n",
       "       [0.64820737, 0.35179263],\n",
       "       ...,\n",
       "       [0.68141174, 0.31858823],\n",
       "       [0.69823307, 0.3017669 ],\n",
       "       [0.6632911 , 0.3367089 ]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
