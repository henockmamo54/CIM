{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n# !pip install nb_black\\n\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "# !pip install nb_black\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom matplotlib import pyplot as plt\\nfrom sklearn import metrics as m\\nfrom sklearn.datasets import make_classification\\nfrom imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.metrics import classification_report\\nfrom sklearn.model_selection import train_test_split\\nfrom collections import Counter\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.neighbors import KNeighborsClassifier\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.ensemble import VotingClassifier\\nimport xgboost as xgb\\nfrom sklearn.pipeline import make_pipeline\\nfrom mlxtend.feature_selection import ColumnSelector\\nfrom sklearn import model_selection\\nfrom mlxtend.classifier import StackingClassifier\\nfrom thundersvm import SVC as svmgpu\\n\\nrandomseed = 7\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics as m\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE  # doctest: +NORMALIZE_WHITESPACE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn import model_selection\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from thundersvm import SVC as svmgpu\n",
    "\n",
    "randomseed = 7\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20414, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"x_original = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_formatted_code = \"x_original = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (x_original.L100800 < 100),\\n    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\\n    (x_original.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original = x_original[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nprint(x_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original = pd.read_csv(\"../XLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original.L100800 < 100),\n",
    "    (x_original.L100800 >= 100) & (x_original.L100800 < 126),\n",
    "    (x_original.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original = x_original[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "        \"FIELD_1\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20414, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"x_original2 = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved2.txt\\\")\\n\\nconditions = [\\n    (x_original2.L100800 < 100),\\n    (x_original2.L100800 >= 100) & (x_original2.L100800 < 126),\\n    (x_original2.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original2[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original2 = x_original2[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nprint(x_original2.shape)\";\n",
       "                var nbb_formatted_code = \"x_original2 = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved2.txt\\\")\\n\\nconditions = [\\n    (x_original2.L100800 < 100),\\n    (x_original2.L100800 >= 100) & (x_original2.L100800 < 126),\\n    (x_original2.L100800 >= 126),\\n]\\nchoices = [0, 1, 2]\\nx_original2[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\nx_original2 = x_original2[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nprint(x_original2.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original2 = pd.read_csv(\"../XLable_onlyDiabeticRemoved2.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original2.L100800 < 100),\n",
    "    (x_original2.L100800 >= 100) & (x_original2.L100800 < 126),\n",
    "    (x_original2.L100800 >= 126),\n",
    "]\n",
    "choices = [0, 1, 2]\n",
    "x_original2[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "x_original2 = x_original2[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "        \"FIELD_1\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20414, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"x_original3 = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved3.txt\\\")\\n\\nconditions = [\\n    (x_original3.L100800 < 100),\\n    (x_original3.L100800 >= 100) & (x_original3.L100800 < 126),\\n    (x_original3.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\nx_original3[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\nx_original3 = x_original3[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nprint(x_original3.shape)\";\n",
       "                var nbb_formatted_code = \"x_original3 = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved3.txt\\\")\\n\\nconditions = [\\n    (x_original3.L100800 < 100),\\n    (x_original3.L100800 >= 100) & (x_original3.L100800 < 126),\\n    (x_original3.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\nx_original3[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\nx_original3 = x_original3[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nprint(x_original3.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original3 = pd.read_csv(\"../XLable_onlyDiabeticRemoved3.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original3.L100800 < 100),\n",
    "    (x_original3.L100800 >= 100) & (x_original3.L100800 < 126),\n",
    "    (x_original3.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "x_original3[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "x_original3 = x_original3[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "        \"FIELD_1\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "print(x_original3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20414, 20)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"x_original4 = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved4.txt\\\")\\n\\nconditions = [\\n    (x_original4.L100800 < 100),\\n    (x_original4.L100800 >= 100) & (x_original4.L100800 < 126),\\n    (x_original4.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\nx_original4[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\nx_original4 = x_original4[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nx_original4 = x_original4.rename(\\n    columns={\\n        \\\"Unnamed: 0\\\": \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\": \\\"L100800_z\\\",\\n        \\\"L104600\\\": \\\"L104600_z\\\",\\n        \\\"L103000\\\": \\\"L103000_z\\\",\\n        \\\"S000300\\\": \\\"S000300_z\\\",\\n        \\\"L101700\\\": \\\"L101700_z\\\",\\n        \\\"L100700\\\": \\\"L100700_z\\\",\\n        \\\"FIELD_33\\\": \\\"FIELD_33_z\\\",\\n        \\\"FIELD_38\\\": \\\"FIELD_38_z\\\",\\n        \\\"FIELD_40\\\": \\\"FIELD_40_z\\\",\\n        \\\"FIELD_31\\\": \\\"FIELD_31_z\\\",\\n        \\\"SEX\\\": \\\"SEX_z\\\",\\n        \\\"AGE\\\": \\\"AGE_z\\\",\\n        \\\"FIELD_16\\\": \\\"FIELD_16_z\\\",\\n        \\\"FIELD_23\\\": \\\"FIELD_23_z\\\",\\n        \\\"FIELD_15\\\": \\\"FIELD_15_z\\\",\\n        \\\"FIELD_22\\\": \\\"FIELD_22_z\\\",\\n        \\\"FIELD_17\\\": \\\"FIELD_17_z\\\",\\n        \\\"FIELD_24\\\": \\\"FIELD_24_z\\\",\\n        \\\"FIELD_1\\\": \\\"FIELD_1\\\",\\n    }\\n)\\n\\nprint(x_original4.shape)\";\n",
       "                var nbb_formatted_code = \"x_original4 = pd.read_csv(\\\"../XLable_onlyDiabeticRemoved4.txt\\\")\\n\\nconditions = [\\n    (x_original4.L100800 < 100),\\n    (x_original4.L100800 >= 100) & (x_original4.L100800 < 126),\\n    (x_original4.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\nx_original4[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\nx_original4 = x_original4[\\n    [\\n        \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",  #'CLASS',\\n        \\\"FIELD_16\\\",\\n        \\\"FIELD_23\\\",\\n        \\\"FIELD_15\\\",\\n        \\\"FIELD_22\\\",\\n        \\\"FIELD_17\\\",\\n        \\\"FIELD_24\\\",\\n        \\\"FIELD_1\\\",\\n    ]\\n]\\n\\nx_original4 = x_original4.rename(\\n    columns={\\n        \\\"Unnamed: 0\\\": \\\"Unnamed: 0\\\",\\n        \\\"L100800\\\": \\\"L100800_z\\\",\\n        \\\"L104600\\\": \\\"L104600_z\\\",\\n        \\\"L103000\\\": \\\"L103000_z\\\",\\n        \\\"S000300\\\": \\\"S000300_z\\\",\\n        \\\"L101700\\\": \\\"L101700_z\\\",\\n        \\\"L100700\\\": \\\"L100700_z\\\",\\n        \\\"FIELD_33\\\": \\\"FIELD_33_z\\\",\\n        \\\"FIELD_38\\\": \\\"FIELD_38_z\\\",\\n        \\\"FIELD_40\\\": \\\"FIELD_40_z\\\",\\n        \\\"FIELD_31\\\": \\\"FIELD_31_z\\\",\\n        \\\"SEX\\\": \\\"SEX_z\\\",\\n        \\\"AGE\\\": \\\"AGE_z\\\",\\n        \\\"FIELD_16\\\": \\\"FIELD_16_z\\\",\\n        \\\"FIELD_23\\\": \\\"FIELD_23_z\\\",\\n        \\\"FIELD_15\\\": \\\"FIELD_15_z\\\",\\n        \\\"FIELD_22\\\": \\\"FIELD_22_z\\\",\\n        \\\"FIELD_17\\\": \\\"FIELD_17_z\\\",\\n        \\\"FIELD_24\\\": \\\"FIELD_24_z\\\",\\n        \\\"FIELD_1\\\": \\\"FIELD_1\\\",\\n    }\\n)\\n\\nprint(x_original4.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_original4 = pd.read_csv(\"../XLable_onlyDiabeticRemoved4.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (x_original4.L100800 < 100),\n",
    "    (x_original4.L100800 >= 100) & (x_original4.L100800 < 126),\n",
    "    (x_original4.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "x_original4[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "x_original4 = x_original4[\n",
    "    [\n",
    "        \"Unnamed: 0\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",  #'CLASS',\n",
    "        \"FIELD_16\",\n",
    "        \"FIELD_23\",\n",
    "        \"FIELD_15\",\n",
    "        \"FIELD_22\",\n",
    "        \"FIELD_17\",\n",
    "        \"FIELD_24\",\n",
    "        \"FIELD_1\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "x_original4 = x_original4.rename(\n",
    "    columns={\n",
    "        \"Unnamed: 0\": \"Unnamed: 0\",\n",
    "        \"L100800\": \"L100800_z\",\n",
    "        \"L104600\": \"L104600_z\",\n",
    "        \"L103000\": \"L103000_z\",\n",
    "        \"S000300\": \"S000300_z\",\n",
    "        \"L101700\": \"L101700_z\",\n",
    "        \"L100700\": \"L100700_z\",\n",
    "        \"FIELD_33\": \"FIELD_33_z\",\n",
    "        \"FIELD_38\": \"FIELD_38_z\",\n",
    "        \"FIELD_40\": \"FIELD_40_z\",\n",
    "        \"FIELD_31\": \"FIELD_31_z\",\n",
    "        \"SEX\": \"SEX_z\",\n",
    "        \"AGE\": \"AGE_z\",\n",
    "        \"FIELD_16\": \"FIELD_16_z\",\n",
    "        \"FIELD_23\": \"FIELD_23_z\",\n",
    "        \"FIELD_15\": \"FIELD_15_z\",\n",
    "        \"FIELD_22\": \"FIELD_22_z\",\n",
    "        \"FIELD_17\": \"FIELD_17_z\",\n",
    "        \"FIELD_24\": \"FIELD_24_z\",\n",
    "        \"FIELD_1\": \"FIELD_1\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(x_original4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20414, 3)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"y_original = pd.read_csv(\\\"../TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_formatted_code = \"y_original = pd.read_csv(\\\"../TargetLable_onlyDiabeticRemoved.txt\\\")\\n\\nconditions = [\\n    (y_original.L100800 < 100),\\n    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\\n    (y_original.L100800 >= 126),\\n]\\n\\nchoices = [0, 1, 2]\\ny_original[\\\"CLASS\\\"] = np.select(conditions, choices, default=0)\\n\\ny_original = y_original[[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\", \\\"CLASS\\\"]]\\n\\nprint(y_original.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_original = pd.read_csv(\"../TargetLable_onlyDiabeticRemoved.txt\")\n",
    "\n",
    "conditions = [\n",
    "    (y_original.L100800 < 100),\n",
    "    (y_original.L100800 >= 100) & (y_original.L100800 < 126),\n",
    "    (y_original.L100800 >= 126),\n",
    "]\n",
    "\n",
    "choices = [0, 1, 2]\n",
    "y_original[\"CLASS\"] = np.select(conditions, choices, default=0)\n",
    "\n",
    "y_original = y_original[[\"Unnamed: 0\", \"FIELD_1\", \"CLASS\"]]\n",
    "\n",
    "print(y_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L104600_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>S000300_x</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>FIELD_33_x</th>\n",
       "      <th>FIELD_38_x</th>\n",
       "      <th>FIELD_40_x</th>\n",
       "      <th>...</th>\n",
       "      <th>FIELD_40_y</th>\n",
       "      <th>FIELD_31_y</th>\n",
       "      <th>SEX_y</th>\n",
       "      <th>AGE_y</th>\n",
       "      <th>FIELD_16_y</th>\n",
       "      <th>FIELD_23_y</th>\n",
       "      <th>FIELD_15_y</th>\n",
       "      <th>FIELD_22_y</th>\n",
       "      <th>FIELD_17_y</th>\n",
       "      <th>FIELD_24_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>492.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  L100800_x  L104600_x  L103000_x  S000300_x  L101700_x  \\\n",
       "0           0       78.0        NaN       92.0       23.5       13.0   \n",
       "1           1       91.0        NaN      492.0       25.4       27.0   \n",
       "2           2      121.0        NaN      131.0       23.5       94.0   \n",
       "3           3       96.0        NaN       53.0       18.3       15.0   \n",
       "4           4       84.0        5.0       84.0       19.9       11.0   \n",
       "\n",
       "   L100700_x  FIELD_33_x  FIELD_38_x  FIELD_40_x  ...  FIELD_40_y  FIELD_31_y  \\\n",
       "0        4.3         1.0         0.0         3.0  ...         3.0         0.0   \n",
       "1        4.9         1.0         0.0         0.0  ...         0.0         0.0   \n",
       "2        4.2         1.0         0.0         1.0  ...         0.0         0.0   \n",
       "3        5.2         1.0         0.0         3.0  ...         2.0         0.0   \n",
       "4        5.1         1.0         1.0         1.0  ...         2.0         0.0   \n",
       "\n",
       "   SEX_y  AGE_y  FIELD_16_y  FIELD_23_y  FIELD_15_y  FIELD_22_y  FIELD_17_y  \\\n",
       "0    1.0   68.0         0.0         0.0         0.0         0.0         1.0   \n",
       "1    1.0   58.0         0.0         0.0         0.0         0.0         0.0   \n",
       "2    1.0   60.0         0.0         0.0         1.0         1.0         1.0   \n",
       "3    1.0   17.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4    1.0   20.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   FIELD_24_y  \n",
       "0         1.0  \n",
       "1         0.0  \n",
       "2         1.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    x_original,\\n    x_original2,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    x_original,\\n    x_original2,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    x_original,\n",
    "    x_original2,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    "    right_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L104600_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>S000300_x</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>FIELD_33_x</th>\n",
       "      <th>FIELD_38_x</th>\n",
       "      <th>FIELD_40_x</th>\n",
       "      <th>...</th>\n",
       "      <th>FIELD_40</th>\n",
       "      <th>FIELD_31</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>FIELD_16</th>\n",
       "      <th>FIELD_23</th>\n",
       "      <th>FIELD_15</th>\n",
       "      <th>FIELD_22</th>\n",
       "      <th>FIELD_17</th>\n",
       "      <th>FIELD_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>492.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  L100800_x  L104600_x  L103000_x  S000300_x  L101700_x  \\\n",
       "0           0       78.0        NaN       92.0       23.5       13.0   \n",
       "1           1       91.0        NaN      492.0       25.4       27.0   \n",
       "2           2      121.0        NaN      131.0       23.5       94.0   \n",
       "3           3       96.0        NaN       53.0       18.3       15.0   \n",
       "4           4       84.0        5.0       84.0       19.9       11.0   \n",
       "\n",
       "   L100700_x  FIELD_33_x  FIELD_38_x  FIELD_40_x  ...  FIELD_40  FIELD_31  \\\n",
       "0        4.3         1.0         0.0         3.0  ...       4.0       0.0   \n",
       "1        4.9         1.0         0.0         0.0  ...       2.0       0.0   \n",
       "2        4.2         1.0         0.0         1.0  ...       0.0       0.0   \n",
       "3        5.2         1.0         0.0         3.0  ...       0.0       0.0   \n",
       "4        5.1         1.0         1.0         1.0  ...       2.0       0.0   \n",
       "\n",
       "   SEX   AGE  FIELD_16  FIELD_23  FIELD_15  FIELD_22  FIELD_17  FIELD_24  \n",
       "0  1.0  69.0       0.0       0.0       0.0       0.0       1.0       1.0  \n",
       "1  1.0  59.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2  1.0  61.0       0.0       0.0       0.0       0.0       1.0       0.0  \n",
       "3  1.0  18.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "4  1.0  21.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    data,\\n    x_original3,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    data,\\n    x_original3,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    data,\n",
    "    x_original3,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    "    right_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L104600_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>S000300_x</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>FIELD_33_x</th>\n",
       "      <th>FIELD_38_x</th>\n",
       "      <th>FIELD_40_x</th>\n",
       "      <th>...</th>\n",
       "      <th>FIELD_40_z</th>\n",
       "      <th>FIELD_31_z</th>\n",
       "      <th>SEX_z</th>\n",
       "      <th>AGE_z</th>\n",
       "      <th>FIELD_16_z</th>\n",
       "      <th>FIELD_23_z</th>\n",
       "      <th>FIELD_15_z</th>\n",
       "      <th>FIELD_22_z</th>\n",
       "      <th>FIELD_17_z</th>\n",
       "      <th>FIELD_24_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>492.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>121.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131.0</td>\n",
       "      <td>23.5</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  L100800_x  L104600_x  L103000_x  S000300_x  L101700_x  \\\n",
       "0           0       78.0        NaN       92.0       23.5       13.0   \n",
       "1           1       91.0        NaN      492.0       25.4       27.0   \n",
       "2           2      121.0        NaN      131.0       23.5       94.0   \n",
       "3           3       96.0        NaN       53.0       18.3       15.0   \n",
       "4           4       84.0        5.0       84.0       19.9       11.0   \n",
       "\n",
       "   L100700_x  FIELD_33_x  FIELD_38_x  FIELD_40_x  ...  FIELD_40_z  FIELD_31_z  \\\n",
       "0        4.3         1.0         0.0         3.0  ...         2.0         0.0   \n",
       "1        4.9         1.0         0.0         0.0  ...         0.0         0.0   \n",
       "2        4.2         1.0         0.0         1.0  ...         2.0         0.0   \n",
       "3        5.2         1.0         0.0         3.0  ...         1.0         0.0   \n",
       "4        5.1         1.0         1.0         1.0  ...         3.0         0.0   \n",
       "\n",
       "   SEX_z  AGE_z  FIELD_16_z  FIELD_23_z  FIELD_15_z  FIELD_22_z  FIELD_17_z  \\\n",
       "0    1.0   70.0         0.0         0.0         0.0         0.0         1.0   \n",
       "1    1.0   60.0         0.0         0.0         0.0         0.0         1.0   \n",
       "2    1.0   62.0         0.0         0.0         0.0         0.0         1.0   \n",
       "3    1.0   19.0         0.0         0.0         0.0         0.0         0.0   \n",
       "4    1.0   22.0         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   FIELD_24_z  \n",
       "0         1.0  \n",
       "1         0.0  \n",
       "2         1.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    data,\\n    x_original4,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    data,\\n    x_original4,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    data,\n",
    "    x_original4,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    "    right_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"data = pd.merge(\\n    data,\\n    y_original,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\";\n",
       "                var nbb_formatted_code = \"data = pd.merge(\\n    data,\\n    y_original,\\n    how=\\\"inner\\\",\\n    left_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n    right_on=[\\\"Unnamed: 0\\\", \\\"FIELD_1\\\"],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(\n",
    "    data,\n",
    "    y_original,\n",
    "    how=\"inner\",\n",
    "    left_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    "    right_on=[\"Unnamed: 0\", \"FIELD_1\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# filter the data set\\ndata = data[data.FIELD_16_x != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23_x != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[data.FIELD_16_y != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23_y != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[data.FIELD_16_z != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23_z != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15_x != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22_x != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[\\n    data.FIELD_15_y != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22_y != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[\\n    data.FIELD_15_z != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22_z != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[data.FIELD_17_x != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24_x != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\ndata = data[data.FIELD_17_y != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24_y != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\ndata = data[data.FIELD_17_z != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24_z != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\n# print(data.shape)\";\n",
       "                var nbb_formatted_code = \"# filter the data set\\ndata = data[data.FIELD_16_x != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23_x != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[data.FIELD_16_y != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23_y != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[data.FIELD_16_z != 1]  # exclude people who are diagnosed for (diabetes)\\ndata = data[data.FIELD_23_z != 1]  # exclude people who are on medication for diabetes\\n\\ndata = data[\\n    data.FIELD_15_x != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22_x != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[\\n    data.FIELD_15_y != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22_y != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[\\n    data.FIELD_15 != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22 != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[\\n    data.FIELD_15_z != 1\\n]  # exclude people who are diagnosed for (high blood pressure)\\ndata = data[\\n    data.FIELD_22_z != 1\\n]  # exclude people who are on medication for high blood pressure\\n\\n\\ndata = data[data.FIELD_17_x != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24_x != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\ndata = data[data.FIELD_17_y != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24_y != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\ndata = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24 != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\ndata = data[data.FIELD_17_z != 1]  # exclude people who are diagnosed for hyperlipidemia\\ndata = data[\\n    data.FIELD_24_z != 1\\n]  # exclude people who are on medication for hyperlipidemia\\n\\n# print(data.shape)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# filter the data set\n",
    "data = data[data.FIELD_16_x != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23_x != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[data.FIELD_16_y != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23_y != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[data.FIELD_16 != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23 != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[data.FIELD_16_z != 1]  # exclude people who are diagnosed for (diabetes)\n",
    "data = data[data.FIELD_23_z != 1]  # exclude people who are on medication for diabetes\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15_x != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22_x != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15_y != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22_y != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15 != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22 != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "\n",
    "data = data[\n",
    "    data.FIELD_15_z != 1\n",
    "]  # exclude people who are diagnosed for (high blood pressure)\n",
    "data = data[\n",
    "    data.FIELD_22_z != 1\n",
    "]  # exclude people who are on medication for high blood pressure\n",
    "\n",
    "\n",
    "data = data[data.FIELD_17_x != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24_x != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "data = data[data.FIELD_17_y != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24_y != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "data = data[data.FIELD_17 != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24 != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "data = data[data.FIELD_17_z != 1]  # exclude people who are diagnosed for hyperlipidemia\n",
    "data = data[\n",
    "    data.FIELD_24_z != 1\n",
    "]  # exclude people who are on medication for hyperlipidemia\n",
    "\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3790, 49)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L104600_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>S000300_x</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>FIELD_33_x</th>\n",
       "      <th>FIELD_38_x</th>\n",
       "      <th>FIELD_40_x</th>\n",
       "      <th>FIELD_31_x</th>\n",
       "      <th>...</th>\n",
       "      <th>S000300_z</th>\n",
       "      <th>L101700_z</th>\n",
       "      <th>L100700_z</th>\n",
       "      <th>FIELD_33_z</th>\n",
       "      <th>FIELD_38_z</th>\n",
       "      <th>FIELD_40_z</th>\n",
       "      <th>FIELD_31_z</th>\n",
       "      <th>SEX_z</th>\n",
       "      <th>AGE_z</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>118.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>91.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>45.0</td>\n",
       "      <td>21.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    L100800_x  L104600_x  L103000_x  S000300_x  L101700_x  L100700_x  \\\n",
       "4        84.0        5.0       84.0       19.9       11.0        5.1   \n",
       "5        81.0        4.9       46.0       18.4       14.0        4.1   \n",
       "6        90.0        5.2      118.0       18.7       10.0        3.5   \n",
       "9        92.0        5.4       76.0       17.4       15.0        5.6   \n",
       "14       91.0        4.8       45.0       21.6       14.0        3.4   \n",
       "\n",
       "    FIELD_33_x  FIELD_38_x  FIELD_40_x  FIELD_31_x  ...  S000300_z  L101700_z  \\\n",
       "4          1.0         1.0         1.0         0.0  ...       20.0        7.0   \n",
       "5          1.0         2.0         0.0         0.0  ...       18.9       15.0   \n",
       "6          1.0         1.0         0.0         0.0  ...       17.8        8.0   \n",
       "9          1.0         0.0         3.0         1.0  ...       16.3       17.0   \n",
       "14         1.0         1.0         2.0         0.0  ...       22.0       11.0   \n",
       "\n",
       "    L100700_z  FIELD_33_z  FIELD_38_z  FIELD_40_z  FIELD_31_z  SEX_z  AGE_z  \\\n",
       "4         4.9         1.0         1.0         3.0         0.0    1.0   22.0   \n",
       "5         4.8         1.0         4.0         0.0         0.0    1.0   22.0   \n",
       "6         3.6         1.0         0.0         0.0         0.0    1.0   23.0   \n",
       "9         5.0         1.0         0.0         0.0         0.0    1.0   23.0   \n",
       "14        3.5         1.0         0.0         0.0         0.0    1.0   25.0   \n",
       "\n",
       "    CLASS  \n",
       "4       0  \n",
       "5       0  \n",
       "6       1  \n",
       "9       0  \n",
       "14      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"data = data[\\n    [\\n        \\\"L100800_x\\\",\\n        \\\"L104600_x\\\",\\n        \\\"L103000_x\\\",\\n        \\\"S000300_x\\\",\\n        \\\"L101700_x\\\",\\n        \\\"L100700_x\\\",\\n        \\\"FIELD_33_x\\\",\\n        \\\"FIELD_38_x\\\",\\n        \\\"FIELD_40_x\\\",\\n        \\\"FIELD_31_x\\\",\\n        \\\"SEX_x\\\",\\n        \\\"AGE_x\\\",\\n        \\\"L100800_y\\\",\\n        \\\"L104600_y\\\",\\n        \\\"L103000_y\\\",\\n        \\\"S000300_y\\\",\\n        \\\"L101700_y\\\",\\n        \\\"L100700_y\\\",\\n        \\\"FIELD_33_y\\\",\\n        \\\"FIELD_38_y\\\",\\n        \\\"FIELD_40_y\\\",\\n        \\\"FIELD_31_y\\\",\\n        \\\"SEX_y\\\",\\n        \\\"AGE_y\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"L100800_z\\\",\\n        \\\"L104600_z\\\",\\n        \\\"L103000_z\\\",\\n        \\\"S000300_z\\\",\\n        \\\"L101700_z\\\",\\n        \\\"L100700_z\\\",\\n        \\\"FIELD_33_z\\\",\\n        \\\"FIELD_38_z\\\",\\n        \\\"FIELD_40_z\\\",\\n        \\\"FIELD_31_z\\\",\\n        \\\"SEX_z\\\",\\n        \\\"AGE_z\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"data = data[\\n    [\\n        \\\"L100800_x\\\",\\n        \\\"L104600_x\\\",\\n        \\\"L103000_x\\\",\\n        \\\"S000300_x\\\",\\n        \\\"L101700_x\\\",\\n        \\\"L100700_x\\\",\\n        \\\"FIELD_33_x\\\",\\n        \\\"FIELD_38_x\\\",\\n        \\\"FIELD_40_x\\\",\\n        \\\"FIELD_31_x\\\",\\n        \\\"SEX_x\\\",\\n        \\\"AGE_x\\\",\\n        \\\"L100800_y\\\",\\n        \\\"L104600_y\\\",\\n        \\\"L103000_y\\\",\\n        \\\"S000300_y\\\",\\n        \\\"L101700_y\\\",\\n        \\\"L100700_y\\\",\\n        \\\"FIELD_33_y\\\",\\n        \\\"FIELD_38_y\\\",\\n        \\\"FIELD_40_y\\\",\\n        \\\"FIELD_31_y\\\",\\n        \\\"SEX_y\\\",\\n        \\\"AGE_y\\\",\\n        \\\"L100800\\\",\\n        \\\"L104600\\\",\\n        \\\"L103000\\\",\\n        \\\"S000300\\\",\\n        \\\"L101700\\\",\\n        \\\"L100700\\\",\\n        \\\"FIELD_33\\\",\\n        \\\"FIELD_38\\\",\\n        \\\"FIELD_40\\\",\\n        \\\"FIELD_31\\\",\\n        \\\"SEX\\\",\\n        \\\"AGE\\\",\\n        \\\"L100800_z\\\",\\n        \\\"L104600_z\\\",\\n        \\\"L103000_z\\\",\\n        \\\"S000300_z\\\",\\n        \\\"L101700_z\\\",\\n        \\\"L100700_z\\\",\\n        \\\"FIELD_33_z\\\",\\n        \\\"FIELD_38_z\\\",\\n        \\\"FIELD_40_z\\\",\\n        \\\"FIELD_31_z\\\",\\n        \\\"SEX_z\\\",\\n        \\\"AGE_z\\\",\\n        \\\"CLASS\\\",\\n    ]\\n]\\ndata = data.dropna()\\nprint(data.shape)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data[\n",
    "    [\n",
    "        \"L100800_x\",\n",
    "        \"L104600_x\",\n",
    "        \"L103000_x\",\n",
    "        \"S000300_x\",\n",
    "        \"L101700_x\",\n",
    "        \"L100700_x\",\n",
    "        \"FIELD_33_x\",\n",
    "        \"FIELD_38_x\",\n",
    "        \"FIELD_40_x\",\n",
    "        \"FIELD_31_x\",\n",
    "        \"SEX_x\",\n",
    "        \"AGE_x\",\n",
    "        \"L100800_y\",\n",
    "        \"L104600_y\",\n",
    "        \"L103000_y\",\n",
    "        \"S000300_y\",\n",
    "        \"L101700_y\",\n",
    "        \"L100700_y\",\n",
    "        \"FIELD_33_y\",\n",
    "        \"FIELD_38_y\",\n",
    "        \"FIELD_40_y\",\n",
    "        \"FIELD_31_y\",\n",
    "        \"SEX_y\",\n",
    "        \"AGE_y\",\n",
    "        \"L100800\",\n",
    "        \"L104600\",\n",
    "        \"L103000\",\n",
    "        \"S000300\",\n",
    "        \"L101700\",\n",
    "        \"L100700\",\n",
    "        \"FIELD_33\",\n",
    "        \"FIELD_38\",\n",
    "        \"FIELD_40\",\n",
    "        \"FIELD_31\",\n",
    "        \"SEX\",\n",
    "        \"AGE\",\n",
    "        \"L100800_z\",\n",
    "        \"L104600_z\",\n",
    "        \"L103000_z\",\n",
    "        \"S000300_z\",\n",
    "        \"L101700_z\",\n",
    "        \"L100700_z\",\n",
    "        \"FIELD_33_z\",\n",
    "        \"FIELD_38_z\",\n",
    "        \"FIELD_40_z\",\n",
    "        \"FIELD_31_z\",\n",
    "        \"SEX_z\",\n",
    "        \"AGE_z\",\n",
    "        \"CLASS\",\n",
    "    ]\n",
    "]\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L104600_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>S000300_x</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>FIELD_33_x</th>\n",
       "      <th>FIELD_38_x</th>\n",
       "      <th>FIELD_40_x</th>\n",
       "      <th>FIELD_31_x</th>\n",
       "      <th>...</th>\n",
       "      <th>S000300_z</th>\n",
       "      <th>L101700_z</th>\n",
       "      <th>L100700_z</th>\n",
       "      <th>FIELD_33_z</th>\n",
       "      <th>FIELD_38_z</th>\n",
       "      <th>FIELD_40_z</th>\n",
       "      <th>FIELD_31_z</th>\n",
       "      <th>SEX_z</th>\n",
       "      <th>AGE_z</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16976</th>\n",
       "      <td>96.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>107.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>182.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17914</th>\n",
       "      <td>92.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>157.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>88.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>125.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>93.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       L100800_x  L104600_x  L103000_x  S000300_x  L101700_x  L100700_x  \\\n",
       "16976       96.0        5.4      140.0       25.3       21.0        3.3   \n",
       "9098       107.0        5.8      182.0       29.6       35.0        7.0   \n",
       "17914       92.0        5.5      157.0       28.7       17.0        4.2   \n",
       "6351        88.0        5.5      125.0       20.7       33.0        3.7   \n",
       "7387        93.0        5.2       66.0       24.0       15.0        6.4   \n",
       "\n",
       "       FIELD_33_x  FIELD_38_x  FIELD_40_x  FIELD_31_x  ...  S000300_z  \\\n",
       "16976         1.0         0.0         3.0         0.0  ...       25.3   \n",
       "9098          2.0         1.0         2.0         1.0  ...       29.0   \n",
       "17914         1.0         0.0         0.0         0.0  ...       27.2   \n",
       "6351          3.0         0.0         0.0         1.0  ...       22.0   \n",
       "7387          2.0         2.0         2.0         0.0  ...       24.7   \n",
       "\n",
       "       L101700_z  L100700_z  FIELD_33_z  FIELD_38_z  FIELD_40_z  FIELD_31_z  \\\n",
       "16976       20.0        3.5         1.0         0.0         0.0         0.0   \n",
       "9098        26.0        7.4         3.0         1.0         2.0         0.0   \n",
       "17914       24.0        4.4         1.0         0.0         0.0         0.0   \n",
       "6351        27.0        4.6         3.0         0.0         1.0         0.0   \n",
       "7387        20.0        5.8         2.0         2.0         0.0         0.0   \n",
       "\n",
       "       SEX_z  AGE_z  CLASS  \n",
       "16976    1.0   65.0      1  \n",
       "9098     0.0   46.0      1  \n",
       "17914    1.0   48.0      0  \n",
       "6351     0.0   44.0      0  \n",
       "7387     0.0   46.0      0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"from sklearn.utils import shuffle\\n\\ndata = shuffle(data)\\ndata.head()\";\n",
       "                var nbb_formatted_code = \"from sklearn.utils import shuffle\\n\\ndata = shuffle(data)\\ndata.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"data[\\\"L100800diff\\\"] = np.power(data.L100800_y - data.L100800_x, 1)\\ndata[\\\"L104600diff\\\"] = np.power(data.L104600_y - data.L104600_x, 1)\\ndata[\\\"L103000diff\\\"] = np.power(data.L103000_y - data.L103000_x, 1)\\ndata[\\\"S000300diff\\\"] = np.power(data.S000300_y - data.S000300_x, 1)\\ndata[\\\"L101700diff\\\"] = np.power(data.L101700_y - data.L101700_x, 1)\\ndata[\\\"L100700diff\\\"] = np.power(data.L100700_y - data.L100700_x, 1)\\n\\ndata[\\\"L100800diff1\\\"] = np.power(data.L100800 - data.L100800_y, 1)\\ndata[\\\"L104600diff1\\\"] = np.power(data.L104600 - data.L104600_y, 1)\\ndata[\\\"L103000diff1\\\"] = np.power(data.L103000 - data.L103000_y, 1)\\ndata[\\\"S000300diff1\\\"] = np.power(data.S000300 - data.S000300_y, 1)\\ndata[\\\"L101700diff1\\\"] = np.power(data.L101700 - data.L101700_y, 1)\\ndata[\\\"L100700diff1\\\"] = np.power(data.L100700 - data.L100700_y, 1)\\n\\ndata[\\\"L100800diff2\\\"] = np.power(data.L100800_z - data.L100800, 1)\\ndata[\\\"L104600diff2\\\"] = np.power(data.L104600_z - data.L104600, 1)\\ndata[\\\"L103000diff2\\\"] = np.power(data.L103000_z - data.L103000, 1)\\ndata[\\\"S000300diff2\\\"] = np.power(data.S000300_z - data.S000300, 1)\\ndata[\\\"L101700diff2\\\"] = np.power(data.L101700_z - data.L101700, 1)\\ndata[\\\"L100700diff2\\\"] = np.power(data.L100700_z - data.L100700, 1)\\n\\ndata[\\\"L100800diff2\\\"] = np.power(data.L100800_z - data.L100800_y, 1)\\ndata[\\\"L104600diff2\\\"] = np.power(data.L104600_z - data.L104600_y, 1)\\ndata[\\\"L103000diff2\\\"] = np.power(data.L103000_z - data.L103000_y, 1)\\ndata[\\\"S000300diff2\\\"] = np.power(data.S000300_z - data.S000300_y, 1)\\ndata[\\\"L101700diff2\\\"] = np.power(data.L101700_z - data.L101700_y, 1)\\ndata[\\\"L100700diff2\\\"] = np.power(data.L100700_z - data.L100700_y, 1)\\n\\ntempclass = data.CLASS\\ndata = data.drop(columns=\\\"CLASS\\\")\\ndata[\\\"CLASS\\\"] = tempclass\";\n",
       "                var nbb_formatted_code = \"data[\\\"L100800diff\\\"] = np.power(data.L100800_y - data.L100800_x, 1)\\ndata[\\\"L104600diff\\\"] = np.power(data.L104600_y - data.L104600_x, 1)\\ndata[\\\"L103000diff\\\"] = np.power(data.L103000_y - data.L103000_x, 1)\\ndata[\\\"S000300diff\\\"] = np.power(data.S000300_y - data.S000300_x, 1)\\ndata[\\\"L101700diff\\\"] = np.power(data.L101700_y - data.L101700_x, 1)\\ndata[\\\"L100700diff\\\"] = np.power(data.L100700_y - data.L100700_x, 1)\\n\\ndata[\\\"L100800diff1\\\"] = np.power(data.L100800 - data.L100800_y, 1)\\ndata[\\\"L104600diff1\\\"] = np.power(data.L104600 - data.L104600_y, 1)\\ndata[\\\"L103000diff1\\\"] = np.power(data.L103000 - data.L103000_y, 1)\\ndata[\\\"S000300diff1\\\"] = np.power(data.S000300 - data.S000300_y, 1)\\ndata[\\\"L101700diff1\\\"] = np.power(data.L101700 - data.L101700_y, 1)\\ndata[\\\"L100700diff1\\\"] = np.power(data.L100700 - data.L100700_y, 1)\\n\\ndata[\\\"L100800diff2\\\"] = np.power(data.L100800_z - data.L100800, 1)\\ndata[\\\"L104600diff2\\\"] = np.power(data.L104600_z - data.L104600, 1)\\ndata[\\\"L103000diff2\\\"] = np.power(data.L103000_z - data.L103000, 1)\\ndata[\\\"S000300diff2\\\"] = np.power(data.S000300_z - data.S000300, 1)\\ndata[\\\"L101700diff2\\\"] = np.power(data.L101700_z - data.L101700, 1)\\ndata[\\\"L100700diff2\\\"] = np.power(data.L100700_z - data.L100700, 1)\\n\\ndata[\\\"L100800diff2\\\"] = np.power(data.L100800_z - data.L100800_y, 1)\\ndata[\\\"L104600diff2\\\"] = np.power(data.L104600_z - data.L104600_y, 1)\\ndata[\\\"L103000diff2\\\"] = np.power(data.L103000_z - data.L103000_y, 1)\\ndata[\\\"S000300diff2\\\"] = np.power(data.S000300_z - data.S000300_y, 1)\\ndata[\\\"L101700diff2\\\"] = np.power(data.L101700_z - data.L101700_y, 1)\\ndata[\\\"L100700diff2\\\"] = np.power(data.L100700_z - data.L100700_y, 1)\\n\\ntempclass = data.CLASS\\ndata = data.drop(columns=\\\"CLASS\\\")\\ndata[\\\"CLASS\\\"] = tempclass\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"L100800diff\"] = np.power(data.L100800_y - data.L100800_x, 1)\n",
    "data[\"L104600diff\"] = np.power(data.L104600_y - data.L104600_x, 1)\n",
    "data[\"L103000diff\"] = np.power(data.L103000_y - data.L103000_x, 1)\n",
    "data[\"S000300diff\"] = np.power(data.S000300_y - data.S000300_x, 1)\n",
    "data[\"L101700diff\"] = np.power(data.L101700_y - data.L101700_x, 1)\n",
    "data[\"L100700diff\"] = np.power(data.L100700_y - data.L100700_x, 1)\n",
    "\n",
    "data[\"L100800diff1\"] = np.power(data.L100800 - data.L100800_y, 1)\n",
    "data[\"L104600diff1\"] = np.power(data.L104600 - data.L104600_y, 1)\n",
    "data[\"L103000diff1\"] = np.power(data.L103000 - data.L103000_y, 1)\n",
    "data[\"S000300diff1\"] = np.power(data.S000300 - data.S000300_y, 1)\n",
    "data[\"L101700diff1\"] = np.power(data.L101700 - data.L101700_y, 1)\n",
    "data[\"L100700diff1\"] = np.power(data.L100700 - data.L100700_y, 1)\n",
    "\n",
    "data[\"L100800diff2\"] = np.power(data.L100800_z - data.L100800, 1)\n",
    "data[\"L104600diff2\"] = np.power(data.L104600_z - data.L104600, 1)\n",
    "data[\"L103000diff2\"] = np.power(data.L103000_z - data.L103000, 1)\n",
    "data[\"S000300diff2\"] = np.power(data.S000300_z - data.S000300, 1)\n",
    "data[\"L101700diff2\"] = np.power(data.L101700_z - data.L101700, 1)\n",
    "data[\"L100700diff2\"] = np.power(data.L100700_z - data.L100700, 1)\n",
    "\n",
    "data[\"L100800diff2\"] = np.power(data.L100800_z - data.L100800_y, 1)\n",
    "data[\"L104600diff2\"] = np.power(data.L104600_z - data.L104600_y, 1)\n",
    "data[\"L103000diff2\"] = np.power(data.L103000_z - data.L103000_y, 1)\n",
    "data[\"S000300diff2\"] = np.power(data.S000300_z - data.S000300_y, 1)\n",
    "data[\"L101700diff2\"] = np.power(data.L101700_z - data.L101700_y, 1)\n",
    "data[\"L100700diff2\"] = np.power(data.L100700_z - data.L100700_y, 1)\n",
    "\n",
    "tempclass = data.CLASS\n",
    "data = data.drop(columns=\"CLASS\")\n",
    "data[\"CLASS\"] = tempclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L104600_x</th>\n",
       "      <th>L103000_x</th>\n",
       "      <th>S000300_x</th>\n",
       "      <th>L101700_x</th>\n",
       "      <th>L100700_x</th>\n",
       "      <th>FIELD_33_x</th>\n",
       "      <th>FIELD_38_x</th>\n",
       "      <th>FIELD_40_x</th>\n",
       "      <th>FIELD_31_x</th>\n",
       "      <th>...</th>\n",
       "      <th>S000300diff1</th>\n",
       "      <th>L101700diff1</th>\n",
       "      <th>L100700diff1</th>\n",
       "      <th>L100800diff2</th>\n",
       "      <th>L104600diff2</th>\n",
       "      <th>L103000diff2</th>\n",
       "      <th>S000300diff2</th>\n",
       "      <th>L101700diff2</th>\n",
       "      <th>L100700diff2</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16976</th>\n",
       "      <td>96.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>25.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>107.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>182.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17914</th>\n",
       "      <td>92.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>157.0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>88.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>125.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>93.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       L100800_x  L104600_x  L103000_x  S000300_x  L101700_x  L100700_x  \\\n",
       "16976       96.0        5.4      140.0       25.3       21.0        3.3   \n",
       "9098       107.0        5.8      182.0       29.6       35.0        7.0   \n",
       "17914       92.0        5.5      157.0       28.7       17.0        4.2   \n",
       "6351        88.0        5.5      125.0       20.7       33.0        3.7   \n",
       "7387        93.0        5.2       66.0       24.0       15.0        6.4   \n",
       "\n",
       "       FIELD_33_x  FIELD_38_x  FIELD_40_x  FIELD_31_x  ...  S000300diff1  \\\n",
       "16976         1.0         0.0         3.0         0.0  ...           1.1   \n",
       "9098          2.0         1.0         2.0         1.0  ...          -0.6   \n",
       "17914         1.0         0.0         0.0         0.0  ...           0.3   \n",
       "6351          3.0         0.0         0.0         1.0  ...           0.4   \n",
       "7387          2.0         2.0         2.0         0.0  ...          -0.3   \n",
       "\n",
       "       L101700diff1  L100700diff1  L100800diff2  L104600diff2  L103000diff2  \\\n",
       "16976          -1.0          -0.1           5.0          0.13          74.0   \n",
       "9098            0.0           0.1          -7.0          0.09           0.0   \n",
       "17914           3.0           0.0           5.0         -0.54         -16.0   \n",
       "6351           -1.0           0.2           4.0         -0.37         -26.0   \n",
       "7387           -3.0           0.0          21.0         -0.07          -4.0   \n",
       "\n",
       "       S000300diff2  L101700diff2  L100700diff2  CLASS  \n",
       "16976           0.4          -3.0          -0.2      1  \n",
       "9098            0.9          -3.0           0.4      1  \n",
       "17914          -1.7           7.0           0.2      0  \n",
       "6351            1.7          -1.0          -0.3      0  \n",
       "7387            0.0           2.0           0.0      0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"data.head()\";\n",
       "                var nbb_formatted_code = \"data.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"def translatecolumnIndex(val):\\n    return [val, val + 12, val + 24, val + 36]\\n\\n\\ndef translateColumnIndexList(val):\\n    finalval = []\\n    for i in val:\\n        finalval.append(translatecolumnIndex(i))\\n    return np.array(finalval).ravel()\";\n",
       "                var nbb_formatted_code = \"def translatecolumnIndex(val):\\n    return [val, val + 12, val + 24, val + 36]\\n\\n\\ndef translateColumnIndexList(val):\\n    finalval = []\\n    for i in val:\\n        finalval.append(translatecolumnIndex(i))\\n    return np.array(finalval).ravel()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def translatecolumnIndex(val):\n",
    "    return [val, val + 12, val + 24, val + 36]\n",
    "\n",
    "\n",
    "def translateColumnIndexList(val):\n",
    "    finalval = []\n",
    "    for i in val:\n",
    "        finalval.append(translatecolumnIndex(i))\n",
    "    return np.array(finalval).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 12, 24, 36,  1, 13, 25, 37,  3, 15, 27, 39, 10, 22, 34, 46, 11,\n",
       "       23, 35, 47])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"translateColumnIndexList([0, 1, 3, 10, 11])\";\n",
       "                var nbb_formatted_code = \"translateColumnIndexList([0, 1, 3, 10, 11])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translateColumnIndexList([0, 1, 3, 10, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L100800_x</th>\n",
       "      <th>L100800_y</th>\n",
       "      <th>L100800</th>\n",
       "      <th>L100800_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16976</th>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9098</th>\n",
       "      <td>107.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17914</th>\n",
       "      <td>92.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>88.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>93.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8273</th>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>100.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6676</th>\n",
       "      <td>94.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>90.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3790 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       L100800_x  L100800_y  L100800  L100800_z\n",
       "16976       96.0       93.0     94.0       98.0\n",
       "9098       107.0      104.0     99.0       97.0\n",
       "17914       92.0       95.0     98.0      100.0\n",
       "6351        88.0       87.0     87.0       91.0\n",
       "7387        93.0       88.0     93.0      109.0\n",
       "...          ...        ...      ...        ...\n",
       "8273        93.0       89.0     89.0       95.0\n",
       "12116      100.0       89.0    103.0       93.0\n",
       "3389        96.0       93.0     89.0       84.0\n",
       "6676        94.0       97.0     77.0       92.0\n",
       "1091        90.0       99.0     93.0       90.0\n",
       "\n",
       "[3790 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"data.iloc[:, translatecolumnIndex(0)]\";\n",
       "                var nbb_formatted_code = \"data.iloc[:, translatecolumnIndex(0)]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.iloc[:, translatecolumnIndex(0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Downsample the majority class and upsample the minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 1400 2314\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_formatted_code = \"diabetic = data[data.CLASS == 2]\\nprediabetic = data[data.CLASS == 1]\\nnormal = data[data.CLASS == 0]\\n\\nprint(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic = data[data.CLASS == 2]\n",
    "prediabetic = data[data.CLASS == 1]\n",
    "normal = data[data.CLASS == 0]\n",
    "\n",
    "print(diabetic.shape[0], prediabetic.shape[0], normal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"diabetic_test = diabetic.sample(16, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(16, random_state=randomseed)\\nnormal_test = normal.sample(16, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_formatted_code = \"diabetic_test = diabetic.sample(16, random_state=randomseed)\\nprediabetic_test = prediabetic.sample(16, random_state=randomseed)\\nnormal_test = normal.sample(16, random_state=randomseed)\\ntest = pd.concat([diabetic_test, prediabetic_test, normal_test])\\n\\ndiabetic_train = diabetic.drop(diabetic_test.index)\\nprediabetic_train = prediabetic.drop(prediabetic_test.index)\\n# .sample(\\n#     10 * diabetic_train.shape[0], random_state=randomseed\\n# )\\nnormal_train = normal.drop(normal_test.index).sample(\\n    prediabetic_train.shape[0],\\n    random_state=randomseed\\n    #     10 * diabetic_train.shape[0], random_state=randomseed\\n)\\ntrain = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diabetic_test = diabetic.sample(16, random_state=randomseed)\n",
    "prediabetic_test = prediabetic.sample(16, random_state=randomseed)\n",
    "normal_test = normal.sample(16, random_state=randomseed)\n",
    "test = pd.concat([diabetic_test, prediabetic_test, normal_test])\n",
    "\n",
    "diabetic_train = diabetic.drop(diabetic_test.index)\n",
    "prediabetic_train = prediabetic.drop(prediabetic_test.index)\n",
    "# .sample(\n",
    "#     10 * diabetic_train.shape[0], random_state=randomseed\n",
    "# )\n",
    "normal_train = normal.drop(normal_test.index).sample(\n",
    "    prediabetic_train.shape[0],\n",
    "    random_state=randomseed\n",
    "    #     10 * diabetic_train.shape[0], random_state=randomseed\n",
    ")\n",
    "train = pd.concat([diabetic_train, diabetic_train, prediabetic_train, normal_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 23;\n",
       "                var nbb_unformatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_formatted_code = \"xtrain = train.iloc[:, :-1]\\nytrain = train.iloc[:, -1]\\nxtest = test.iloc[:, :-1]\\nytest = test.iloc[:, -1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain = train.iloc[:, :-1]\n",
    "ytrain = train.iloc[:, -1]\n",
    "xtest = test.iloc[:, :-1]\n",
    "ytest = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_formatted_code = \"from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\nxtrain = scaler.fit_transform(xtrain)\\nxtest = scaler.transform(xtest)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({2: 1384, 1: 1384, 0: 1384})\n",
      "1384 1384 1384\n",
      "(4152, 66) (4152,)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_formatted_code = \"from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\\n\\nrandomseed = 42\\n\\nsm = SMOTENC(\\n    random_state=randomseed,\\n    categorical_features=[6, 7, 8, 9, 10],\\n    sampling_strategy=\\\"minority\\\",\\n)\\nX_res, y_res = sm.fit_resample(xtrain, ytrain)\\n\\nprint(\\\"Resampled dataset shape %s\\\" % Counter(y_res))\\nprint(\\n    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\\n)\\nprint(X_res.shape, y_res.shape)\\n\\nxtrain = X_res\\nytrain = y_res\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC  # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "randomseed = 42\n",
    "\n",
    "sm = SMOTENC(\n",
    "    random_state=randomseed,\n",
    "    categorical_features=[6, 7, 8, 9, 10],\n",
    "    sampling_strategy=\"minority\",\n",
    ")\n",
    "X_res, y_res = sm.fit_resample(xtrain, ytrain)\n",
    "\n",
    "print(\"Resampled dataset shape %s\" % Counter(y_res))\n",
    "print(\n",
    "    y_res[y_res == 0].shape[0], y_res[y_res == 1].shape[0], y_res[y_res == 2].shape[0]\n",
    ")\n",
    "print(X_res.shape, y_res.shape)\n",
    "\n",
    "xtrain = X_res\n",
    "ytrain = y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"rf_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=1000,\\n    max_depth=8,\\n    min_samples_split=5,\\n    min_samples_leaf=8,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"rf_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=1000,\\n    max_depth=8,\\n    min_samples_split=5,\\n    min_samples_leaf=8,\\n    max_features=\\\"auto\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_12 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=1000,\n",
    "    max_depth=8,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=8, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=8, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"rf_12.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"rf_12.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_12.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.6875\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"ypred = rf_12.predict(xtest)\\nprint(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"ypred = rf_12.predict(xtest)\\nprint(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = rf_12.predict(xtest)\n",
    "print(\"Accuracy = \", m.accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generate the classifier models based on the selected  features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_formatted_code = \"# generate the models based on the selected columns list and the ml classifiers\\ncols = []\\nweakmodles = []\\nestimators = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "cols = []\n",
    "weakmodles = []\n",
    "estimators = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"rf_model_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=1000,\\n    max_depth=8,\\n    min_samples_split=5,\\n    min_samples_leaf=8,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=0.5,\\n    gamma=0.0,\\n    learning_rate=0.05,\\n    max_delta_step=0,\\n    max_depth=2,\\n    min_child_weight=3,\\n    missing=None,\\n    n_estimators=175,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=0,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_12 = svmgpu(\\n    C=10,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=10,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(translateColumnIndexList(np.arange(0, 12)))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), rf_model_12\\n    )\\n)\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), xgb_model_12\\n    )\\n)\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), scv_model_12\\n    )\\n)\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_formatted_code = \"rf_model_12 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=1000,\\n    max_depth=8,\\n    min_samples_split=5,\\n    min_samples_leaf=8,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_12 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=0.5,\\n    gamma=0.0,\\n    learning_rate=0.05,\\n    max_delta_step=0,\\n    max_depth=2,\\n    min_child_weight=3,\\n    missing=None,\\n    n_estimators=175,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=0,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_12 = svmgpu(\\n    C=10,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_12 = SVC(\\n    C=10,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\ncols.append(translateColumnIndexList(np.arange(0, 12)))\\n\\n# weakmodles.append(rf_model_12)\\n# weakmodles.append(xgb_model_12)\\n# weakmodles.append(scv_model_12)\\n\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), rf_model_12\\n    )\\n)\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), xgb_model_12\\n    )\\n)\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), scv_model_12\\n    )\\n)\\n\\n\\nestimators.append((\\\"rf_model_12\\\", rf_model_12))\\nestimators.append((\\\"xgb_model_12\\\", xgb_model_12))\\nestimators.append((\\\"scv_model_12\\\", scv_model_cpu_12))\\n\\n# estimators = [\\n#     (\\\"rf_model_12\\\", rf_model_12),\\n#     (\\\"xgb_model_12\\\", xgb_model_12),\\n#     (\\\"scv_model_12\\\", scv_model_12),\\n# ]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_12 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=1000,\n",
    "    max_depth=8,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "xgb_model_12 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=0.5,\n",
    "    gamma=0.0,\n",
    "    learning_rate=0.05,\n",
    "    max_delta_step=0,\n",
    "    max_depth=2,\n",
    "    min_child_weight=3,\n",
    "    missing=None,\n",
    "    n_estimators=175,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=0,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_12 = svmgpu(\n",
    "    C=10,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_12 = SVC(\n",
    "    C=10,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "cols.append(translateColumnIndexList(np.arange(0, 12)))\n",
    "\n",
    "# weakmodles.append(rf_model_12)\n",
    "# weakmodles.append(xgb_model_12)\n",
    "# weakmodles.append(scv_model_12)\n",
    "\n",
    "weakmodles.append(\n",
    "    make_pipeline(\n",
    "        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), rf_model_12\n",
    "    )\n",
    ")\n",
    "weakmodles.append(\n",
    "    make_pipeline(\n",
    "        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), xgb_model_12\n",
    "    )\n",
    ")\n",
    "weakmodles.append(\n",
    "    make_pipeline(\n",
    "        ColumnSelector(cols=(translateColumnIndexList(np.arange(0, 12)))), scv_model_12\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "estimators.append((\"rf_model_12\", rf_model_12))\n",
    "estimators.append((\"xgb_model_12\", xgb_model_12))\n",
    "estimators.append((\"scv_model_12\", scv_model_cpu_12))\n",
    "\n",
    "# estimators = [\n",
    "#     (\"rf_model_12\", rf_model_12),\n",
    "#     (\"xgb_model_12\", xgb_model_12),\n",
    "#     (\"scv_model_12\", scv_model_12),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 59;\n",
       "                var nbb_unformatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(make_pipeline(ColumnSelector(cols=translateColumnIndexList([0,1,3,10,11])), rf_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=translateColumnIndexList([0,1,3,10,11])), xgb_model_5))\\nweakmodles.append(make_pipeline(ColumnSelector(cols=translateColumnIndexList([0,1,3,10,11])), scv_model_5))\\n    \\n\\ncols.append(translateColumnIndexList([0,1,3,10,11]))\\ncols.append(translateColumnIndexList([0,1,3,10,11]))\\ncols.append(translateColumnIndexList([0,1,3,10,11]))\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_formatted_code = \"rf_model_5 = RandomForestClassifier(\\n    random_state=randomseed,\\n    n_estimators=100,\\n    max_depth=12,\\n    min_samples_split=2,\\n    min_samples_leaf=10,\\n    max_features=\\\"auto\\\",\\n)\\n\\nxgb_model_5 = xgb.XGBClassifier(objective=\\\"binary:logistic\\\", random_state=randomseed)\\n\\nscv_model_5 = svmgpu(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\nscv_model_cpu_5 = SVC(\\n    C=70,\\n    cache_size=200,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovr\\\",\\n    degree=3,\\n    gamma=0.001,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=42,\\n    shrinking=True,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# weakmodles.append(rf_model_5)\\n# weakmodles.append(xgb_model_5)\\n# weakmodles.append(scv_model_5)\\n\\n\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=translateColumnIndexList([0, 1, 3, 10, 11])), rf_model_5\\n    )\\n)\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=translateColumnIndexList([0, 1, 3, 10, 11])), xgb_model_5\\n    )\\n)\\nweakmodles.append(\\n    make_pipeline(\\n        ColumnSelector(cols=translateColumnIndexList([0, 1, 3, 10, 11])), scv_model_5\\n    )\\n)\\n\\n\\ncols.append(translateColumnIndexList([0, 1, 3, 10, 11]))\\ncols.append(translateColumnIndexList([0, 1, 3, 10, 11]))\\ncols.append(translateColumnIndexList([0, 1, 3, 10, 11]))\\n\\nestimators.append((\\\"rf_model_5\\\", rf_model_5))\\nestimators.append((\\\"xgb_model_5\\\", xgb_model_5))\\nestimators.append((\\\"scv_model_5\\\", scv_model_cpu_5))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_model_5 = RandomForestClassifier(\n",
    "    random_state=randomseed,\n",
    "    n_estimators=100,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"auto\",\n",
    ")\n",
    "\n",
    "xgb_model_5 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=randomseed)\n",
    "\n",
    "scv_model_5 = svmgpu(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "scv_model_cpu_5 = SVC(\n",
    "    C=70,\n",
    "    cache_size=200,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovr\",\n",
    "    degree=3,\n",
    "    gamma=0.001,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    #     max_mem_size=-1,\n",
    "    #     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    shrinking=True,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# weakmodles.append(rf_model_5)\n",
    "# weakmodles.append(xgb_model_5)\n",
    "# weakmodles.append(scv_model_5)\n",
    "\n",
    "\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=translateColumnIndexList([0,1,3,10,11])), rf_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=translateColumnIndexList([0,1,3,10,11])), xgb_model_5))\n",
    "weakmodles.append(make_pipeline(ColumnSelector(cols=translateColumnIndexList([0,1,3,10,11])), scv_model_5))\n",
    "    \n",
    "\n",
    "cols.append(translateColumnIndexList([0,1,3,10,11]))\n",
    "cols.append(translateColumnIndexList([0,1,3,10,11]))\n",
    "cols.append(translateColumnIndexList([0,1,3,10,11]))\n",
    "\n",
    "estimators.append((\"rf_model_5\", rf_model_5))\n",
    "estimators.append((\"xgb_model_5\", xgb_model_5))\n",
    "estimators.append((\"scv_model_5\", scv_model_cpu_5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. 10 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 60;\n",
       "                var nbb_unformatted_code = \"top10colscomb = [\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 7, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 7, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 7, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 7, 9, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 6, 7, 9, 10, 11)),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_formatted_code = \"top10colscomb = [\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 7, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 7, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 7, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 7, 9, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 6, 7, 9, 10, 11)),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_10 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=42,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_10 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=42,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_10 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_10 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_10)\\n    #     weakmodles.append(xgb_model_10)\\n    #     weakmodles.append(scv_model_10)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_10\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_10\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\\n        )\\n    )\\n\\ncols = cols + top10colscomb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top10colscomb = [\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 6, 7, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 7, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 5, 6, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 7, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 5, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 7, 9, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 6, 7, 9, 10, 11)),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_10 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_10 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=42,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_10 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_10 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_10)\n",
    "    #     weakmodles.append(xgb_model_10)\n",
    "    #     weakmodles.append(scv_model_10)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_10)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_10\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top10colscomb[i]), rf_model_10)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), xgb_model_10)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_10\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top10colscomb[i]), scv_model_cpu_10)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + top10colscomb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. 9 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 62;\n",
       "                var nbb_unformatted_code = \"topcols9comb = [\\n    translateColumnIndexList((0, 1, 2, 3, 5, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 9, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 7, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 7, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 7, 8, 11)),\\n    translateColumnIndexList((0, 1, 3, 5, 6, 8, 9, 10, 11)),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_formatted_code = \"topcols9comb = [\\n    translateColumnIndexList((0, 1, 2, 3, 5, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 9, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 7, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 7, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 7, 8, 11)),\\n    translateColumnIndexList((0, 1, 3, 5, 6, 8, 9, 10, 11)),\\n]\\n\\n# modles used in the 12 features set\\nrf_model_9 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_9 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_9 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_9 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    #     weakmodles.append(rf_model_9)\\n    #     weakmodles.append(xgb_model_9)\\n    #     weakmodles.append(scv_model_9)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_9\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_9\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\\n        )\\n    )\\n\\ncols = cols + topcols9comb\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topcols9comb = [\n",
    "    translateColumnIndexList((0, 1, 2, 3, 5, 6, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 6, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 5, 6, 9, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 6, 7, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 6, 7, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 7, 8, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 5, 6, 8, 9, 10, 11)),\n",
    "]\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_9 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_9 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_9 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_9 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    #     weakmodles.append(rf_model_9)\n",
    "    #     weakmodles.append(xgb_model_9)\n",
    "    #     weakmodles.append(scv_model_9)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_9))\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_9\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=topcols9comb[i]), rf_model_9)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), xgb_model_9)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_9\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=topcols9comb[i]), scv_model_cpu_9)),\n",
    "        )\n",
    "    )\n",
    "\n",
    "cols = cols + topcols9comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. 8 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"top8colscomb = [\\n    translateColumnIndexList((0, 1, 2, 3, 5, 6, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 6, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 9, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 10, 11)),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top8colscomb = [\\n    translateColumnIndexList((0, 1, 2, 3, 5, 6, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 6, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 9, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 6, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 6, 10, 11)),\\n]\\n\\ncols = cols + top8colscomb\\n\\n# modles used in the 12 features set\\nrf_model_8 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_8 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_8 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=None,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_8 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\\n\\n#     weakmodles.append(rf_model_8)\\n#     weakmodles.append(xgb_model_8)\\n#     weakmodles.append(scv_model_8)\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_8\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_8\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top8colscomb = [\n",
    "    translateColumnIndexList((0, 1, 2, 3, 5, 6, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 6, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 5, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 9, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 6, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 6, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 5, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 6, 10, 11)),\n",
    "]\n",
    "\n",
    "cols = cols + top8colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_8 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_8 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_8 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=None,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_8 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_8))\n",
    "\n",
    "#     weakmodles.append(rf_model_8)\n",
    "#     weakmodles.append(xgb_model_8)\n",
    "#     weakmodles.append(scv_model_8)\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_8\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top8colscomb[i]), rf_model_8)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), xgb_model_8)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_8\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top8colscomb[i]), scv_model_cpu_8)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 7 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 64;\n",
       "                var nbb_unformatted_code = \"top7colscomb = [\\n    translateColumnIndexList((0, 1, 3, 5, 6, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 6, 7, 8, 9, 10)),\\n    translateColumnIndexList((0, 1, 2, 3, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 8, 9, 10, 11)),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top7colscomb = [\\n    translateColumnIndexList((0, 1, 3, 5, 6, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 4, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 4, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 3, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 6, 8, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 6, 7, 8, 9, 10)),\\n    translateColumnIndexList((0, 1, 2, 3, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 6, 8, 10, 11)),\\n    translateColumnIndexList((0, 1, 3, 8, 9, 10, 11)),\\n]\\n\\ncols = cols + top7colscomb\\n\\nrf_model_7 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_7 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_7 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_7 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\\n\\n#     weakmodles.append(rf_model_7)\\n#     weakmodles.append(xgb_model_7)\\n#     weakmodles.append(scv_model_7)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_7\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_7\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top7colscomb = [\n",
    "    translateColumnIndexList((0, 1, 3, 5, 6, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 4, 5, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 4, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 5, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 6, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 6, 8, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 6, 7, 8, 9, 10)),\n",
    "    translateColumnIndexList((0, 1, 2, 3, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 6, 8, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 3, 8, 9, 10, 11)),\n",
    "]\n",
    "\n",
    "cols = cols + top7colscomb\n",
    "\n",
    "rf_model_7 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_7 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_7 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_7 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_7))\n",
    "\n",
    "#     weakmodles.append(rf_model_7)\n",
    "#     weakmodles.append(xgb_model_7)\n",
    "#     weakmodles.append(scv_model_7)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_7\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_7)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_7)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_7\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_7)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. 6 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 65;\n",
       "                var nbb_unformatted_code = \"top6colscomb = [\\n    translateColumnIndexList((0, 1, 8, 9, 10)),\\n    translateColumnIndexList((0, 1, 6, 8, 10)),\\n    translateColumnIndexList((0, 1, 7, 9, 10)),\\n    translateColumnIndexList((0, 1, 2, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 6, 11)),\\n    translateColumnIndexList((0, 1, 7, 8, 10)),\\n    translateColumnIndexList((0, 1, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 5, 11)),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top6colscomb = [\\n    translateColumnIndexList((0, 1, 8, 9, 10)),\\n    translateColumnIndexList((0, 1, 6, 8, 10)),\\n    translateColumnIndexList((0, 1, 7, 9, 10)),\\n    translateColumnIndexList((0, 1, 2, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 6, 11)),\\n    translateColumnIndexList((0, 1, 7, 8, 10)),\\n    translateColumnIndexList((0, 1, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 5, 11)),\\n]\\n\\ncols = cols + top6colscomb\\n\\n# modles used in the 12 features set\\nrf_model_6 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_6 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_6 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_6 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,  # gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\\n\\n#     weakmodles.append(rf_model_6)\\n#     weakmodles.append(xgb_model_6)\\n#     weakmodles.append(scv_model_6)\\n\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_6\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_6\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top6colscomb = [\n",
    "    translateColumnIndexList((0, 1, 8, 9, 10)),\n",
    "    translateColumnIndexList((0, 1, 6, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 7, 9, 10)),\n",
    "    translateColumnIndexList((0, 1, 2, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 5, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 5, 6, 11)),\n",
    "    translateColumnIndexList((0, 1, 7, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 5, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 5, 11)),\n",
    "]\n",
    "\n",
    "cols = cols + top6colscomb\n",
    "\n",
    "# modles used in the 12 features set\n",
    "rf_model_6 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_6 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_6 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_6 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,  # gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,  # max_mem_size=-1, n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), rf_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), xgb_model_6))\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top6colscomb[i]), scv_model_6))\n",
    "\n",
    "#     weakmodles.append(rf_model_6)\n",
    "#     weakmodles.append(xgb_model_6)\n",
    "#     weakmodles.append(scv_model_6)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_6\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top7colscomb[i]), rf_model_6)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), xgb_model_6)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_6\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top7colscomb[i]), scv_model_cpu_6)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8. 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 66;\n",
       "                var nbb_unformatted_code = \"top5colscomb = [\\n    translateColumnIndexList((0, 1, 8, 9, 10)),\\n    translateColumnIndexList((0, 1, 6, 8, 10)),\\n    translateColumnIndexList((0, 1, 7, 9, 10)),\\n    translateColumnIndexList((0, 1, 2, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 6, 11)),\\n    translateColumnIndexList((0, 1, 7, 8, 10)),\\n    translateColumnIndexList((0, 1, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 5, 11)),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_formatted_code = \"top5colscomb = [\\n    translateColumnIndexList((0, 1, 8, 9, 10)),\\n    translateColumnIndexList((0, 1, 6, 8, 10)),\\n    translateColumnIndexList((0, 1, 7, 9, 10)),\\n    translateColumnIndexList((0, 1, 2, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 8, 10)),\\n    translateColumnIndexList((0, 1, 5, 6, 11)),\\n    translateColumnIndexList((0, 1, 7, 8, 10)),\\n    translateColumnIndexList((0, 1, 9, 10, 11)),\\n    translateColumnIndexList((0, 1, 5, 10, 11)),\\n    translateColumnIndexList((0, 1, 2, 5, 11)),\\n]\\n\\ncols = cols + top5colscomb\\n\\nrf_model_5_2 = RandomForestClassifier(\\n    bootstrap=True,\\n    class_weight=None,\\n    criterion=\\\"gini\\\",\\n    max_depth=12,\\n    max_features=\\\"auto\\\",\\n    max_leaf_nodes=None,\\n    min_impurity_decrease=0.0,\\n    min_impurity_split=None,\\n    min_samples_leaf=10,\\n    min_samples_split=2,\\n    min_weight_fraction_leaf=0.0,\\n    n_estimators=100,\\n    n_jobs=None,\\n    oob_score=False,\\n    random_state=randomseed,\\n    verbose=0,\\n    warm_start=False,\\n)\\n\\nxgb_model_5_2 = xgb.XGBClassifier(\\n    base_score=0.5,\\n    booster=\\\"gbtree\\\",\\n    colsample_bylevel=1,\\n    colsample_bynode=1,\\n    colsample_bytree=1,\\n    gamma=0,\\n    learning_rate=0.1,\\n    max_delta_step=0,\\n    max_depth=3,\\n    min_child_weight=1,\\n    missing=None,\\n    n_estimators=100,\\n    n_jobs=1,\\n    nthread=None,\\n    objective=\\\"multi:softprob\\\",\\n    random_state=randomseed,\\n    reg_alpha=0,\\n    reg_lambda=1,\\n    scale_pos_weight=1,\\n    seed=None,\\n    silent=None,\\n    subsample=1,\\n    verbosity=1,\\n)\\n\\nscv_model_5_2 = svmgpu(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    max_mem_size=-1,\\n    n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\nscv_model_cpu_5_2 = SVC(\\n    C=1000,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    # max_mem_size=-1,   n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\\n\\n\\n# generate the models based on the selected columns list and the ml classifiers\\nfor i in range(5):\\n\\n    #     weakmodles.append(rf_model_5_2)\\n    #     weakmodles.append(xgb_model_5_2)\\n    #     weakmodles.append(scv_model_5_2)\\n\\n    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\\n    )\\n    weakmodles.append(\\n        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\\n    )\\n\\nfor i in range(5):\\n    estimators.append(\\n        (\\n            (\\n                \\\"rf_model_52\\\" + str(i),\\n                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\\n            )\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"xgb_model_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\\n        )\\n    )\\n    estimators.append(\\n        (\\n            \\\"scv_model_cpu_52\\\" + str(i),\\n            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\\n        )\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top5colscomb = [\n",
    "    translateColumnIndexList((0, 1, 8, 9, 10)),\n",
    "    translateColumnIndexList((0, 1, 6, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 7, 9, 10)),\n",
    "    translateColumnIndexList((0, 1, 2, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 5, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 5, 6, 11)),\n",
    "    translateColumnIndexList((0, 1, 7, 8, 10)),\n",
    "    translateColumnIndexList((0, 1, 9, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 5, 10, 11)),\n",
    "    translateColumnIndexList((0, 1, 2, 5, 11)),\n",
    "]\n",
    "\n",
    "cols = cols + top5colscomb\n",
    "\n",
    "rf_model_5_2 = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    class_weight=None,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=12,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    n_estimators=100,\n",
    "    n_jobs=None,\n",
    "    oob_score=False,\n",
    "    random_state=randomseed,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    ")\n",
    "\n",
    "xgb_model_5_2 = xgb.XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    booster=\"gbtree\",\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bynode=1,\n",
    "    colsample_bytree=1,\n",
    "    gamma=0,\n",
    "    learning_rate=0.1,\n",
    "    max_delta_step=0,\n",
    "    max_depth=3,\n",
    "    min_child_weight=1,\n",
    "    missing=None,\n",
    "    n_estimators=100,\n",
    "    n_jobs=1,\n",
    "    nthread=None,\n",
    "    objective=\"multi:softprob\",\n",
    "    random_state=randomseed,\n",
    "    reg_alpha=0,\n",
    "    reg_lambda=1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=None,\n",
    "    silent=None,\n",
    "    subsample=1,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "scv_model_5_2 = svmgpu(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    max_mem_size=-1,\n",
    "    n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "scv_model_cpu_5_2 = SVC(\n",
    "    C=1000,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "    #     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "    # max_mem_size=-1,   n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "# generate the models based on the selected columns list and the ml classifiers\n",
    "for i in range(5):\n",
    "\n",
    "    #     weakmodles.append(rf_model_5_2)\n",
    "    #     weakmodles.append(xgb_model_5_2)\n",
    "    #     weakmodles.append(scv_model_5_2)\n",
    "\n",
    "    weakmodles.append(make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2))\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)\n",
    "    )\n",
    "    weakmodles.append(\n",
    "        make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_5_2)\n",
    "    )\n",
    "\n",
    "for i in range(5):\n",
    "    estimators.append(\n",
    "        (\n",
    "            (\n",
    "                \"rf_model_52\" + str(i),\n",
    "                (make_pipeline(ColumnSelector(cols=top5colscomb[i]), rf_model_5_2)),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"xgb_model_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), xgb_model_5_2)),\n",
    "        )\n",
    "    )\n",
    "    estimators.append(\n",
    "        (\n",
    "            \"scv_model_cpu_52\" + str(i),\n",
    "            (make_pipeline(ColumnSelector(cols=top5colscomb[i]), scv_model_cpu_5_2)),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"len(weakmodles)\";\n",
       "                var nbb_formatted_code = \"len(weakmodles)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(weakmodles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_formatted_code = \"cols = np.array(cols)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = np.array(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"clf = []\\nacc = []\\nfinalacc = []\\nypredproba_all = []\\nypredconfprob_all = []\";\n",
       "                var nbb_formatted_code = \"clf = []\\nacc = []\\nfinalacc = []\\nypredproba_all = []\\nypredconfprob_all = []\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = []\n",
    "acc = []\n",
    "finalacc = []\n",
    "ypredproba_all = []\n",
    "ypredconfprob_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"# for i, classifier in enumerate(weakmodles):\\n#     print(i)\\n#     rf = classifier\\n#     rf.fit(xtrain[:, cols[i]], ytrain)\\n#     rfpred = rf.predict(xtest[:, cols[i]])\\n#     print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n#     clf.append(rf)\\n#     acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n#     ypredproba_all.append(rf.predict_proba(xtest[:, cols[i]]))\\n\\n#     confmat = m.confusion_matrix(ytest, rfpred)\\n#     confsumh = np.sum(confmat, axis=0)\\n#     propconfmat = confmat.copy()\\n#     for i in range(propconfmat.shape[0]):\\n#         propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n#     ypredconfprob_all.append(propconfmat / 100)\";\n",
       "                var nbb_formatted_code = \"# for i, classifier in enumerate(weakmodles):\\n#     print(i)\\n#     rf = classifier\\n#     rf.fit(xtrain[:, cols[i]], ytrain)\\n#     rfpred = rf.predict(xtest[:, cols[i]])\\n#     print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n#     clf.append(rf)\\n#     acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n#     ypredproba_all.append(rf.predict_proba(xtest[:, cols[i]]))\\n\\n#     confmat = m.confusion_matrix(ytest, rfpred)\\n#     confsumh = np.sum(confmat, axis=0)\\n#     propconfmat = confmat.copy()\\n#     for i in range(propconfmat.shape[0]):\\n#         propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n#     ypredconfprob_all.append(propconfmat / 100)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i, classifier in enumerate(weakmodles):\n",
    "#     print(i)\n",
    "#     rf = classifier\n",
    "#     rf.fit(xtrain[:, cols[i]], ytrain)\n",
    "#     rfpred = rf.predict(xtest[:, cols[i]])\n",
    "#     print(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "#     clf.append(rf)\n",
    "#     acc.append(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "#     ypredproba_all.append(rf.predict_proba(xtest[:, cols[i]]))\n",
    "\n",
    "#     confmat = m.confusion_matrix(ytest, rfpred)\n",
    "#     confsumh = np.sum(confmat, axis=0)\n",
    "#     propconfmat = confmat.copy()\n",
    "#     for i in range(propconfmat.shape[0]):\n",
    "#         propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "#     ypredconfprob_all.append(propconfmat / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.655474297827239\n",
      "1\n",
      "0.6745230078563411\n",
      "2\n",
      "0.6533736533736533\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"for i, classifier in enumerate(weakmodles):\\n    print(i)\\n    rf = classifier\\n    rf.fit(xtrain, ytrain)\\n    rfpred = rf.predict(xtest)\\n    print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, rfpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\";\n",
       "                var nbb_formatted_code = \"for i, classifier in enumerate(weakmodles):\\n    print(i)\\n    rf = classifier\\n    rf.fit(xtrain, ytrain)\\n    rfpred = rf.predict(xtest)\\n    print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, rfpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, classifier in enumerate(weakmodles):\n",
    "    print(i)\n",
    "    rf = classifier\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    rfpred = rf.predict(xtest)\n",
    "    print(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "    clf.append(rf)\n",
    "    acc.append(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "    ypredproba_all.append(rf.predict_proba(xtest))\n",
    "\n",
    "    confmat = m.confusion_matrix(ytest, rfpred)\n",
    "    confsumh = np.sum(confmat, axis=1)\n",
    "    propconfmat = confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\n",
    "    ypredconfprob_all.append(propconfmat / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ypredconfprob_all)[0].ravel()\n",
    "\n",
    "tempval = []\n",
    "for i in range(96):\n",
    "    tempval.append(np.array(ypredconfprob_all)[i].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(acc).to_csv(\"stackingdatatestresult/_acc.txt\", index=False)\n",
    "pd.DataFrame(ytest).to_csv(\"stackingdatatestresult/_ytest.txt\", index=False)\n",
    "\n",
    "\n",
    "pd.DataFrame(np.array(ypredproba_all)[:, :, 0]).to_csv(\n",
    "    \"stackingdatatestresult/_ypredproba_all_class_0.txt\", index=False\n",
    ")\n",
    "\n",
    "pd.DataFrame(np.array(ypredproba_all)[:, :, 1]).to_csv(\n",
    "    \"stackingdatatestresult/_ypredproba_all_class_1.txt\", index=False\n",
    ")\n",
    "\n",
    "pd.DataFrame(np.array(ypredproba_all)[:, :, 2]).to_csv(\n",
    "    \"stackingdatatestresult/_ypredproba_all_class_2.txt\", index=False\n",
    ")\n",
    "\n",
    "pd.DataFrame(tempval).to_csv(\"stackingdatatestresult/_confmatrix.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"sclf = StackingClassifier(classifiers=weakmodles,verbose=2,\\n                           meta_classifier=RandomForestClassifier(n_estimators=500))\";\n",
       "                var nbb_formatted_code = \"sclf = StackingClassifier(\\n    classifiers=weakmodles,\\n    verbose=2,\\n    meta_classifier=RandomForestClassifier(n_estimators=500),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclf = StackingClassifier(classifiers=weakmodles,verbose=2,\n",
    "                           meta_classifier=RandomForestClassifier(n_estimators=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 96 classifiers...\n",
      "Fitting classifier1: randomforestclassifier (1/96)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=12,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=-1, oob_score=False, random_state=42, verbose=1,\n",
      "                       warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier2: xgbclassifier (2/96)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier3: svc (3/96)\n",
      "SVC(C=100, cache_size=100, class_weight={}, coef0=0.0,\n",
      "    decision_function_shape='ovo', degree=3, gamma=0.1, gpu_id=0,\n",
      "    kernel='linear', max_iter=-1, max_mem_size=-1, n_jobs=-1, probability=False,\n",
      "    random_state=42, shrinking=False, tol=0.001, verbose=False)\n",
      "Fitting classifier4: randomforestclassifier (4/96)\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Fitting classifier5: xgbclassifier (5/96)\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='binary:logistic', random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)\n",
      "Fitting classifier6: svc (6/96)\n",
      "SVC(C=70, cache_size=200, class_weight={}, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, gpu_id=0,\n",
      "    kernel='linear', max_iter=-1, max_mem_size=-1, n_jobs=-1, probability=True,\n",
      "    random_state=42, shrinking=True, tol=0.001, verbose=False)\n",
      "Fitting classifier7: pipeline (7/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier8: pipeline (8/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier9: pipeline (9/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier10: pipeline (10/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier11: pipeline (11/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier12: pipeline (12/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier13: pipeline (13/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier14: pipeline (14/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier15: pipeline (15/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 7, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier16: pipeline (16/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier17: pipeline (17/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier18: pipeline (18/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier19: pipeline (19/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier20: pipeline (20/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier21: pipeline (21/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier22: pipeline (22/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier23: pipeline (23/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier24: pipeline (24/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 8, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier25: pipeline (25/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier26: pipeline (26/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier27: pipeline (27/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier28: pipeline (28/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier29: pipeline (29/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier30: pipeline (30/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier31: pipeline (31/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier32: pipeline (32/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier33: pipeline (33/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 6, 7, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier34: pipeline (34/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier35: pipeline (35/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier36: pipeline (36/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 8, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier37: pipeline (37/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier38: pipeline (38/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier39: pipeline (39/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier40: pipeline (40/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier41: pipeline (41/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier42: pipeline (42/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 6, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier43: pipeline (43/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier44: pipeline (44/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier45: pipeline (45/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier46: pipeline (46/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier47: pipeline (47/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier48: pipeline (48/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 9, 10, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier49: pipeline (49/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier50: pipeline (50/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier51: pipeline (51/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 6, 9, 11),\n",
      "                                drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=None,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier52: pipeline (52/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier53: pipeline (53/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier54: pipeline (54/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 5, 6, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier55: pipeline (55/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier56: pipeline (56/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier57: pipeline (57/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 4, 5, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier58: pipeline (58/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier59: pipeline (59/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier60: pipeline (60/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 4, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier61: pipeline (61/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier62: pipeline (62/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier63: pipeline (63/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 3, 5, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier64: pipeline (64/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier65: pipeline (65/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier66: pipeline (66/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 3, 6, 8, 10, 11), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier67: pipeline (67/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier68: pipeline (68/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier69: pipeline (69/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier70: pipeline (70/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier71: pipeline (71/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier72: pipeline (72/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier73: pipeline (73/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier74: pipeline (74/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier75: pipeline (75/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier76: pipeline (76/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier77: pipeline (77/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier78: pipeline (78/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier79: pipeline (79/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier80: pipeline (80/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier81: pipeline (81/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier82: pipeline (82/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier83: pipeline (83/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier84: pipeline (84/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 8, 9, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier85: pipeline (85/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier86: pipeline (86/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier87: pipeline (87/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 6, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier88: pipeline (88/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier89: pipeline (89/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier90: pipeline (90/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 7, 9, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier91: pipeline (91/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier92: pipeline (92/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier93: pipeline (93/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 2, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "Fitting classifier94: pipeline (94/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
      "                                        criterion='gini', max_depth=12,\n",
      "                                        max_features='auto',\n",
      "                                        max_leaf_nodes=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=10,\n",
      "                                        min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=42,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier95: pipeline (95/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=3,\n",
      "                               min_child_weight=1, missing=None,\n",
      "                               n_estimators=100, n_jobs=1, nthread=None,\n",
      "                               objective='multi:softprob', random_state=42,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "                               seed=None, silent=None, subsample=1,\n",
      "                               verbosity=1))],\n",
      "         verbose=False)\n",
      "Fitting classifier96: pipeline (96/96)\n",
      "Pipeline(memory=None,\n",
      "         steps=[('columnselector',\n",
      "                 ColumnSelector(cols=(0, 1, 5, 8, 10), drop_axis=False)),\n",
      "                ('svc',\n",
      "                 SVC(C=1000, cache_size=100, class_weight={}, coef0=0.0,\n",
      "                     decision_function_shape='ovo', degree=3, gamma=0.1,\n",
      "                     gpu_id=0, kernel='linear', max_iter=-1, max_mem_size=-1,\n",
      "                     n_jobs=-1, probability=False, random_state=42,\n",
      "                     shrinking=False, tol=0.001, verbose=False))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(average_probas=False,\n",
       "                   classifiers=[RandomForestClassifier(bootstrap=True,\n",
       "                                                       class_weight=None,\n",
       "                                                       criterion='gini',\n",
       "                                                       max_depth=10,\n",
       "                                                       max_features='log2',\n",
       "                                                       max_leaf_nodes=None,\n",
       "                                                       min_impurity_decrease=0.0,\n",
       "                                                       min_impurity_split=None,\n",
       "                                                       min_samples_leaf=2,\n",
       "                                                       min_samples_split=12,\n",
       "                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                       n_estimators=100,\n",
       "                                                       n_jobs=-1,\n",
       "                                                       oob_score=False,\n",
       "                                                       random_st...\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=500,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                   store_train_meta_features=False, use_clones=True,\n",
       "                   use_features_in_secondary=False, use_probas=False,\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"sclf.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"sclf.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sclf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>145</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>60</td>\n",
       "      <td>129</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          145           55         0\n",
       "Prediabetes      60          129        11\n",
       "diabetes          3           36       161"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"ypred = sclf.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"ypred = sclf.predict((xtest))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = sclf.predict((xtest))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       200\n",
      "           1       0.59      0.65      0.61       200\n",
      "           2       0.94      0.81      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.72      0.73       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the performance of each model of the sclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# for i in range(len(sclf.clfs_)):\\n#     ypred = sclf.clfs_[i].predict((xtest))\\n#     print(type(sclf.clfs_[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"# for i in range(len(sclf.clfs_)):\\n#     ypred = sclf.clfs_[i].predict((xtest))\\n#     print(type(sclf.clfs_[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(len(sclf.clfs_)):\n",
    "#     ypred = sclf.clfs_[i].predict((xtest))\n",
    "#     print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      56          124        20\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "0\n",
      "<class 'xgboost.sklearn.XGBClassifier'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      59          116        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'thundersvm.thundersvm.SVC'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "2\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "3\n",
      "<class 'xgboost.sklearn.XGBClassifier'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      59          116        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "4\n",
      "<class 'thundersvm.thundersvm.SVC'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           25       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       200\n",
      "           1       0.62      0.61      0.61       200\n",
      "           2       0.87      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "5\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.64      0.63       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "6\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "7\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.555\n",
      "Accuracy =  0.555\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           41         9\n",
      "Prediabetes      54          128        18\n",
      "diabetes          4          141        55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.41      0.64      0.50       200\n",
      "           2       0.67      0.28      0.39       200\n",
      "\n",
      "    accuracy                           0.56       600\n",
      "   macro avg       0.60      0.56      0.54       600\n",
      "weighted avg       0.60      0.56      0.54       600\n",
      "\n",
      "8\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          131        15\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.61      0.66      0.63       200\n",
      "           2       0.92      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "9\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "10\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      56          116        28\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "11\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           32       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.65      0.62       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "12\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      56          119        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "13\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      56          117        27\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "14\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7283333333333334\n",
      "Accuracy =  0.7283333333333334\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      56          125        19\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.89      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "15\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      55          119        26\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "16\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "17\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      57          127        16\n",
      "diabetes          3           34       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.91      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "18\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "19\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "20\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7266666666666667\n",
      "Accuracy =  0.7266666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          146           53         1\n",
      "Prediabetes      56          127        17\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "21\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "22\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      53          120        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.60      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "23\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "24\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "25\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      53          119        28\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "26\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          129        14\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.92      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "27\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          121        26\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.74      0.75      0.75       600\n",
      "weighted avg       0.74      0.75      0.75       600\n",
      "\n",
      "28\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "29\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           32       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.60      0.63      0.61       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "30\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          123        23\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "31\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.63      0.58      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "32\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      57          124        19\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.90      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "33\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      56          119        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "34\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           23       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "35\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      54          130        16\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.60      0.65      0.63       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "36\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7533333333333333\n",
      "Accuracy =  0.7533333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.65      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "37\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      52          120        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       200\n",
      "           1       0.63      0.60      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "38\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      56          126        18\n",
      "diabetes          4           26       170\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.62      0.63      0.62       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "39\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "40\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "41\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "42\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      54          122        24\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "43\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "44\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      59          125        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "45\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "46\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          117        29\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.85      0.88      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "47\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7266666666666667\n",
      "Accuracy =  0.7266666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      59          125        16\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.91      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "48\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "49\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      53          120        27\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.65      0.60      0.62       200\n",
      "           2       0.86      0.89      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "50\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          130        18\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "51\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "52\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      52          120        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "53\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "54\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "55\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "56\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "57\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "59\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           52         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "60\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "61\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "62\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          127        21\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "63\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "64\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.73      0.74      0.74       600\n",
      "weighted avg       0.73      0.74      0.74       600\n",
      "\n",
      "65\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      53          128        19\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.64      0.63       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "66\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      51          125        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       200\n",
      "           1       0.62      0.62      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "67\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.6033333333333334\n",
      "Accuracy =  0.6033333333333334\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           21        25\n",
      "Prediabetes      48           45       107\n",
      "diabetes          3           34       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.45      0.23      0.30       200\n",
      "           2       0.55      0.81      0.66       200\n",
      "\n",
      "    accuracy                           0.60       600\n",
      "   macro avg       0.58      0.60      0.57       600\n",
      "weighted avg       0.58      0.60      0.57       600\n",
      "\n",
      "68\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      53          131        16\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.66      0.64       200\n",
      "           2       0.91      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "69\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      50          126        24\n",
      "diabetes          3           24       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.63      0.63      0.63       200\n",
      "           2       0.88      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "70\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7516666666666667\n",
      "Accuracy =  0.7516666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       200\n",
      "           1       0.64      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "71\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          130        15\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.65      0.64       200\n",
      "           2       0.92      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "72\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          123        23\n",
      "diabetes          3           26       171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "73\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           47         3\n",
      "Prediabetes      51          119        30\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       200\n",
      "           1       0.64      0.59      0.62       200\n",
      "           2       0.84      0.89      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "74\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      55          125        20\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.62      0.62       200\n",
      "           2       0.89      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "75\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      53          123        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "76\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.58\n",
      "Accuracy =  0.58\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152            7        41\n",
      "Prediabetes      53           18       129\n",
      "diabetes          3           19       178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.41      0.09      0.15       200\n",
      "           2       0.51      0.89      0.65       200\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.55      0.58      0.51       600\n",
      "weighted avg       0.55      0.58      0.51       600\n",
      "\n",
      "77\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           53         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "78\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      52          123        25\n",
      "diabetes          3           25       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.87      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "79\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "80\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      53          128        19\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.64      0.63       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "81\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      51          125        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       200\n",
      "           1       0.62      0.62      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "82\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.6033333333333334\n",
      "Accuracy =  0.6033333333333334\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           21        25\n",
      "Prediabetes      48           45       107\n",
      "diabetes          3           34       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.45      0.23      0.30       200\n",
      "           2       0.55      0.81      0.66       200\n",
      "\n",
      "    accuracy                           0.60       600\n",
      "   macro avg       0.58      0.60      0.57       600\n",
      "weighted avg       0.58      0.60      0.57       600\n",
      "\n",
      "83\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      53          131        16\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.66      0.64       200\n",
      "           2       0.91      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "84\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      50          126        24\n",
      "diabetes          3           24       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.63      0.63      0.63       200\n",
      "           2       0.88      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "85\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7516666666666667\n",
      "Accuracy =  0.7516666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       200\n",
      "           1       0.64      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "86\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          130        15\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.65      0.64       200\n",
      "           2       0.92      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "87\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          123        23\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "88\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           47         3\n",
      "Prediabetes      51          119        30\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74       200\n",
      "           1       0.64      0.59      0.62       200\n",
      "           2       0.84      0.89      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "89\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      55          125        20\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.62      0.62       200\n",
      "           2       0.89      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "90\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      53          123        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "91\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.58\n",
      "Accuracy =  0.58\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152            7        41\n",
      "Prediabetes      53           18       129\n",
      "diabetes          3           19       178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.41      0.09      0.15       200\n",
      "           2       0.51      0.89      0.65       200\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.55      0.58      0.51       600\n",
      "weighted avg       0.55      0.58      0.51       600\n",
      "\n",
      "92\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           53         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "93\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      52          123        25\n",
      "diabetes          3           25       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.87      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "94\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "95\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"stackedmodels = sclf.clfs_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(sclf.clfs_[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_formatted_code = \"stackedmodels = sclf.clfs_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(sclf.clfs_[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stackedmodels = sclf.clfs_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Generate Votting Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"votingclf = VotingClassifier(estimators=estimators, voting=\\\"hard\\\")\";\n",
       "                var nbb_formatted_code = \"votingclf = VotingClassifier(estimators=estimators, voting=\\\"hard\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf = VotingClassifier(estimators=estimators, voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf_model_12',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=10,\n",
       "                                                     max_features='log2',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=12,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=42, ve...\n",
       "                                               ColumnSelector(cols=(0, 1, 2, 3,\n",
       "                                                                    4, 5, 6, 9,\n",
       "                                                                    11),\n",
       "                                                              drop_axis=False)),\n",
       "                                              ('svc',\n",
       "                                               SVC(C=1000, cache_size=100,\n",
       "                                                   class_weight={}, coef0=0.0,\n",
       "                                                   decision_function_shape='ovo',\n",
       "                                                   degree=3, gamma=0.1,\n",
       "                                                   kernel='linear', max_iter=-1,\n",
       "                                                   probability=True,\n",
       "                                                   random_state=42,\n",
       "                                                   shrinking=False, tol=0.001,\n",
       "                                                   verbose=False))],\n",
       "                                       verbose=False)), ...],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"votingclf.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"votingclf.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7483333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>52</td>\n",
       "      <td>124</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          150           50         0\n",
       "Prediabetes      52          124        24\n",
       "diabetes          4           21       175"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"ypred = votingclf.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"ypred = votingclf.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = votingclf.predict(xtest.astype(float))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.64      0.62      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      56          124        20\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "0\n",
      "<class 'xgboost.sklearn.XGBClassifier'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      59          116        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'thundersvm.thundersvm.SVC'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "2\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "3\n",
      "<class 'xgboost.sklearn.XGBClassifier'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      59          116        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "4\n",
      "<class 'thundersvm.thundersvm.SVC'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "5\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.64      0.63       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "6\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "7\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "8\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          131        15\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.61      0.66      0.63       200\n",
      "           2       0.92      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "9\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "10\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "11\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           32       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.65      0.62       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "12\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      56          119        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "13\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "14\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7283333333333334\n",
      "Accuracy =  0.7283333333333334\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      56          125        19\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.89      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "15\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      55          119        26\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           23       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "17\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      57          127        16\n",
      "diabetes          3           34       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.91      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "18\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "19\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "20\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7266666666666667\n",
      "Accuracy =  0.7266666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          146           53         1\n",
      "Prediabetes      56          127        17\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "21\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "22\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "23\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "24\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "25\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "26\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          129        14\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.92      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "27\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          121        26\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.74      0.75      0.75       600\n",
      "weighted avg       0.74      0.75      0.75       600\n",
      "\n",
      "28\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      55          118        27\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "29\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           32       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.60      0.63      0.61       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "30\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          123        23\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      55          118        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "32\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      57          124        19\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.90      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "33\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      56          119        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "34\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           23       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "35\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      54          130        16\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.60      0.65      0.63       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "36\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7533333333333333\n",
      "Accuracy =  0.7533333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.65      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "37\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      52          121        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "38\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      56          126        18\n",
      "diabetes          4           26       170\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.62      0.63      0.62       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "39\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "40\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "41\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "42\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      54          122        24\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "43\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.87      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "44\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      59          125        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "45\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          117        29\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.58      0.60       200\n",
      "           2       0.85      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.73      0.74      0.73       600\n",
      "weighted avg       0.73      0.74      0.73       600\n",
      "\n",
      "47\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7266666666666667\n",
      "Accuracy =  0.7266666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      59          125        16\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.91      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "48\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "49\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.59      0.62       200\n",
      "           2       0.86      0.89      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "50\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          130        18\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "51\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "52\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      52          121        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "53\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "54\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "55\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "56\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "57\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "58\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "59\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           52         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "60\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "62\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          127        21\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "63\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "64\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.60      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "65\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          130        18\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "66\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "67\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      52          121        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "68\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "69\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "70\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "71\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "72\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "73\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "74\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           52         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "75\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "77\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          127        21\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "78\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "79\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.60      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "80\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      53          128        19\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.64      0.63       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "81\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      51          125        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       200\n",
      "           1       0.62      0.62      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "82\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      48          125        27\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.64       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "83\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      53          131        16\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.66      0.64       200\n",
      "           2       0.91      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "84\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      50          126        24\n",
      "diabetes          3           24       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.63      0.63      0.63       200\n",
      "           2       0.88      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "85\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7516666666666667\n",
      "Accuracy =  0.7516666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       200\n",
      "           1       0.64      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "86\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          130        15\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.65      0.64       200\n",
      "           2       0.92      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "87\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          123        23\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "88\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      52          119        29\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.59      0.62       200\n",
      "           2       0.86      0.89      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.74      0.75      0.74       600\n",
      "weighted avg       0.74      0.75      0.74       600\n",
      "\n",
      "89\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      55          125        20\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.62      0.62       200\n",
      "           2       0.89      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "90\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      53          123        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      53          120        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "92\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           53         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "93\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      52          123        25\n",
      "diabetes          3           25       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.87      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "94\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "95\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"stackedmodels = votingclf.estimators_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(sclf.clfs_[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_formatted_code = \"stackedmodels = votingclf.estimators_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(sclf.clfs_[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stackedmodels = votingclf.estimators_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(sclf.clfs_[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6  Generate Votting Classifer soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"\\nscv_model_cpu_withProb = SVC(\\n  C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n#     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n#     max_mem_size=-1,\\n#     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_formatted_code = \"scv_model_cpu_withProb = SVC(\\n    C=100,\\n    cache_size=100,\\n    class_weight={},\\n    coef0=0.0,\\n    decision_function_shape=\\\"ovo\\\",\\n    degree=3,\\n    gamma=0.1,\\n    #     gpu_id=0,\\n    kernel=\\\"linear\\\",\\n    max_iter=-1,\\n    #     max_mem_size=-1,\\n    #     n_jobs=-1,\\n    probability=True,\\n    random_state=randomseed,\\n    shrinking=False,\\n    tol=0.001,\\n    verbose=False,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "scv_model_cpu_withProb = SVC(\n",
    "  C=100,\n",
    "    cache_size=100,\n",
    "    class_weight={},\n",
    "    coef0=0.0,\n",
    "    decision_function_shape=\"ovo\",\n",
    "    degree=3,\n",
    "    gamma=0.1,\n",
    "#     gpu_id=0,\n",
    "    kernel=\"linear\",\n",
    "    max_iter=-1,\n",
    "#     max_mem_size=-1,\n",
    "#     n_jobs=-1,\n",
    "    probability=True,\n",
    "    random_state=randomseed,\n",
    "    shrinking=False,\n",
    "    tol=0.001,\n",
    "    verbose=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"votingclf2 = VotingClassifier(\\n    estimators=estimators, \\n    voting=\\\"soft\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"votingclf2 = VotingClassifier(estimators=estimators, voting=\\\"soft\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf2 = VotingClassifier(estimators=estimators, voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  77 out of 100 | elapsed:    2.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf_model_12',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=10,\n",
       "                                                     max_features='log2',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=2,\n",
       "                                                     min_samples_split=12,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=100,\n",
       "                                                     n_jobs=-1, oob_score=False,\n",
       "                                                     random_state=42, ve...\n",
       "                                               ColumnSelector(cols=(0, 1, 2, 3,\n",
       "                                                                    4, 5, 6, 9,\n",
       "                                                                    11),\n",
       "                                                              drop_axis=False)),\n",
       "                                              ('svc',\n",
       "                                               SVC(C=1000, cache_size=100,\n",
       "                                                   class_weight={}, coef0=0.0,\n",
       "                                                   decision_function_shape='ovo',\n",
       "                                                   degree=3, gamma=0.1,\n",
       "                                                   kernel='linear', max_iter=-1,\n",
       "                                                   probability=True,\n",
       "                                                   random_state=42,\n",
       "                                                   shrinking=False, tol=0.001,\n",
       "                                                   verbose=False))],\n",
       "                                       verbose=False)), ...],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"votingclf2.fit(xtrain, ytrain)\";\n",
       "                var nbb_formatted_code = \"votingclf2.fit(xtrain, ytrain)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "votingclf2.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy \t 0.7416666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Normal</th>\n",
       "      <th>Prediabetes</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prediabetes</th>\n",
       "      <td>53</td>\n",
       "      <td>123</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Normal  Prediabetes  diabetes\n",
       "Normal          150           50         0\n",
       "Prediabetes      53          123        24\n",
       "diabetes          4           24       172"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"ypred = votingclf2.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_formatted_code = \"ypred = votingclf2.predict(xtest.astype(float))\\n\\nprint(\\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\nconfmatrx = pd.DataFrame(\\n    m.confusion_matrix(ytest, ypred),\\n    columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n)\\nconfmatrx.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ypred = votingclf2.predict(xtest.astype(float))\n",
    "\n",
    "print(\"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "confmatrx = pd.DataFrame(\n",
    "    m.confusion_matrix(ytest, ypred),\n",
    "    columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    ")\n",
    "confmatrx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_formatted_code = \"print(classification_report(ytest, ypred))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(classification_report(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      56          124        20\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "0\n",
      "<class 'xgboost.sklearn.XGBClassifier'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      59          116        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "1\n",
      "<class 'sklearn.svm.classes.SVC'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "2\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "3\n",
      "<class 'xgboost.sklearn.XGBClassifier'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      59          116        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "4\n",
      "<class 'sklearn.svm.classes.SVC'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "5\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.64      0.63       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "6\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "7\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "8\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          131        15\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.61      0.66      0.63       200\n",
      "           2       0.92      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "9\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "10\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           24       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "11\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           32       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.61      0.65      0.62       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "12\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      56          119        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "14\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7283333333333334\n",
      "Accuracy =  0.7283333333333334\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      56          125        19\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.89      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "15\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      55          119        26\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "16\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          119        26\n",
      "diabetes          4           23       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.59      0.61       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "17\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      57          127        16\n",
      "diabetes          3           34       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.91      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "18\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "19\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "20\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7266666666666667\n",
      "Accuracy =  0.7266666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          146           53         1\n",
      "Prediabetes      56          127        17\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "21\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "22\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "23\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "24\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "25\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "26\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          129        14\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.92      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "27\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          121        26\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.74      0.75      0.75       600\n",
      "weighted avg       0.74      0.75      0.75       600\n",
      "\n",
      "28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      55          118        27\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "29\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           32       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.60      0.63      0.61       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "30\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      54          123        23\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.64      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "31\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           48         1\n",
      "Prediabetes      55          118        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "32\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      57          124        19\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.90      0.81      0.85       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "33\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      56          119        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.74       200\n",
      "           1       0.64      0.59      0.61       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "34\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           23       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "35\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      54          130        16\n",
      "diabetes          3           33       164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.60      0.65      0.63       200\n",
      "           2       0.91      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "36\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7533333333333333\n",
      "Accuracy =  0.7533333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.65      0.61      0.63       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "37\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      52          121        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "38\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      56          126        18\n",
      "diabetes          4           26       170\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.73       200\n",
      "           1       0.62      0.63      0.62       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "39\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "40\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7433333333333333\n",
      "Accuracy =  0.7433333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "41\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7333333333333333\n",
      "Accuracy =  0.7333333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           51         1\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.90      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "42\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      54          122        24\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      55          117        28\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.62      0.58      0.60       200\n",
      "           2       0.86      0.87      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.73      0.73      0.73       600\n",
      "weighted avg       0.73      0.73      0.73       600\n",
      "\n",
      "44\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.73\n",
      "Accuracy =  0.73\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      59          125        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "45\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "46\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          117        29\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.58      0.60       200\n",
      "           2       0.85      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.73      0.74      0.73       600\n",
      "weighted avg       0.73      0.74      0.73       600\n",
      "\n",
      "47\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7266666666666667\n",
      "Accuracy =  0.7266666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          148           52         0\n",
      "Prediabetes      59          125        16\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72       200\n",
      "           1       0.60      0.62      0.61       200\n",
      "           2       0.91      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "48\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "49\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           46         1\n",
      "Prediabetes      54          119        27\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.59      0.62       200\n",
      "           2       0.86      0.89      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "50\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          130        18\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "51\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "52\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      52          121        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "53\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "54\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "55\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "56\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "57\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "59\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           52         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "60\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "61\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "62\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          127        21\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "63\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "64\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.60      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "65\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          130        18\n",
      "diabetes          4           33       163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.90      0.81      0.86       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "66\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "67\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      52          121        27\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "68\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          129        16\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       200\n",
      "           1       0.61      0.65      0.63       200\n",
      "           2       0.91      0.82      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.74       600\n",
      "weighted avg       0.75      0.74      0.74       600\n",
      "\n",
      "69\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "70\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.60      0.61       200\n",
      "           2       0.87      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "71\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      57          126        17\n",
      "diabetes          4           30       166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       200\n",
      "           1       0.61      0.63      0.62       200\n",
      "           2       0.91      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "72\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           48         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          3           21       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           49         1\n",
      "Prediabetes      53          121        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "74\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7316666666666667\n",
      "Accuracy =  0.7316666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           52         1\n",
      "Prediabetes      55          127        18\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72       200\n",
      "           1       0.60      0.64      0.62       200\n",
      "           2       0.90      0.82      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.73       600\n",
      "weighted avg       0.74      0.73      0.73       600\n",
      "\n",
      "75\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.75\n",
      "Accuracy =  0.75\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           46         0\n",
      "Prediabetes      54          121        25\n",
      "diabetes          4           21       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.60      0.62       200\n",
      "           2       0.88      0.88      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "76\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          118        28\n",
      "diabetes          4           20       176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.63      0.59      0.61       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "77\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      52          127        21\n",
      "diabetes          4           31       165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.89      0.82      0.85       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "78\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          153           47         0\n",
      "Prediabetes      53          122        25\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.77      0.75       200\n",
      "           1       0.64      0.61      0.62       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "79\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7383333333333333\n",
      "Accuracy =  0.7383333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           50         1\n",
      "Prediabetes      54          120        26\n",
      "diabetes          4           22       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.62      0.60      0.61       200\n",
      "           2       0.87      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "80\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      53          128        19\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       200\n",
      "           1       0.63      0.64      0.63       200\n",
      "           2       0.90      0.85      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "81\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      51          125        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       200\n",
      "           1       0.62      0.62      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.75      0.74      0.75       600\n",
      "weighted avg       0.75      0.74      0.75       600\n",
      "\n",
      "82\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      48          125        27\n",
      "diabetes          3           23       174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.64       200\n",
      "           2       0.86      0.87      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "83\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      53          131        16\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.66      0.64       200\n",
      "           2       0.91      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "84\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      50          126        24\n",
      "diabetes          3           24       173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74       200\n",
      "           1       0.63      0.63      0.63       200\n",
      "           2       0.88      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "85\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7516666666666667\n",
      "Accuracy =  0.7516666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       200\n",
      "           1       0.64      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "86\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7483333333333333\n",
      "Accuracy =  0.7483333333333333\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      55          130        15\n",
      "diabetes          3           28       169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.65      0.64       200\n",
      "           2       0.92      0.84      0.88       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.75      0.75      0.75       600\n",
      "weighted avg       0.75      0.75      0.75       600\n",
      "\n",
      "87\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          150           50         0\n",
      "Prediabetes      54          123        23\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7466666666666667\n",
      "Accuracy =  0.7466666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      52          119        29\n",
      "diabetes          3           20       177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.64      0.59      0.62       200\n",
      "           2       0.86      0.89      0.87       200\n",
      "\n",
      "    accuracy                           0.75       600\n",
      "   macro avg       0.74      0.75      0.74       600\n",
      "weighted avg       0.74      0.75      0.74       600\n",
      "\n",
      "89\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.735\n",
      "Accuracy =  0.735\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      55          125        20\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       200\n",
      "           1       0.61      0.62      0.62       200\n",
      "           2       0.89      0.83      0.86       200\n",
      "\n",
      "    accuracy                           0.73       600\n",
      "   macro avg       0.74      0.73      0.74       600\n",
      "weighted avg       0.74      0.73      0.74       600\n",
      "\n",
      "90\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7416666666666667\n",
      "Accuracy =  0.7416666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          151           49         0\n",
      "Prediabetes      53          123        24\n",
      "diabetes          3           26       171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.88      0.85      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "91\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.745\n",
      "Accuracy =  0.745\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          152           47         1\n",
      "Prediabetes      53          120        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.75       200\n",
      "           1       0.63      0.60      0.62       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "92\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.7366666666666667\n",
      "Accuracy =  0.7366666666666667\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          147           53         0\n",
      "Prediabetes      54          128        18\n",
      "diabetes          3           30       167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.73      0.73       200\n",
      "           1       0.61      0.64      0.62       200\n",
      "           2       0.90      0.83      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "93\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.74\n",
      "Accuracy =  0.74\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          149           51         0\n",
      "Prediabetes      52          123        25\n",
      "diabetes          3           25       172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.74       200\n",
      "           1       0.62      0.61      0.62       200\n",
      "           2       0.87      0.86      0.87       200\n",
      "\n",
      "    accuracy                           0.74       600\n",
      "   macro avg       0.74      0.74      0.74       600\n",
      "weighted avg       0.74      0.74      0.74       600\n",
      "\n",
      "94\n",
      "<class 'sklearn.pipeline.Pipeline'> accuracy \t 0.755\n",
      "Accuracy =  0.755\n",
      "             Normal  Prediabetes  diabetes\n",
      "Normal          154           45         1\n",
      "Prediabetes      49          124        27\n",
      "diabetes          3           22       175\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       200\n",
      "           1       0.65      0.62      0.63       200\n",
      "           2       0.86      0.88      0.87       200\n",
      "\n",
      "    accuracy                           0.76       600\n",
      "   macro avg       0.75      0.76      0.75       600\n",
      "weighted avg       0.75      0.76      0.75       600\n",
      "\n",
      "95\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"stackedmodels = votingclf2.estimators_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(stackedmodels[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_formatted_code = \"stackedmodels = votingclf2.estimators_\\nfor i in range(len(stackedmodels)):\\n    ypred = stackedmodels[i].predict(xtest)\\n    print(type(stackedmodels[i]), \\\"accuracy \\\\t\\\", m.accuracy_score(ytest, ypred))\\n    print(\\\"Accuracy = \\\", m.accuracy_score(ytest, ypred))\\n\\n    confmatrx = pd.DataFrame(\\n        m.confusion_matrix(ytest, ypred),\\n        columns=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n        index=[\\\"Normal\\\", \\\"Prediabetes\\\", \\\"diabetes\\\"],\\n    )\\n    print(confmatrx.head())\\n\\n    print(m.classification_report(ytest, ypred))\\n\\n    print(i)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stackedmodels = votingclf2.estimators_\n",
    "for i in range(len(stackedmodels)):\n",
    "    ypred = stackedmodels[i].predict(xtest)\n",
    "    print(type(stackedmodels[i]), \"accuracy \\t\", m.accuracy_score(ytest, ypred))\n",
    "    print(\"Accuracy = \", m.accuracy_score(ytest, ypred))\n",
    "\n",
    "    confmatrx = pd.DataFrame(\n",
    "        m.confusion_matrix(ytest, ypred),\n",
    "        columns=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "        index=[\"Normal\", \"Prediabetes\", \"diabetes\"],\n",
    "    )\n",
    "    print(confmatrx.head())\n",
    "\n",
    "    print(m.classification_report(ytest, ypred))\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
