{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nfrom thundersvm import SVC as svmgpu\\nimport calculateWeightUsingGa2 as aresult\\nimport pandas as pd\\nimport itertools\\nimport random\\nfrom sklearn.ensemble import VotingClassifier\\nfrom sklearn.utils import shuffle\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.ensemble import VotingClassifier\\n\\nrandomseed = 42\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nfrom sklearn import datasets\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.svm import SVC\\nimport xgboost as xgb\\nfrom sklearn import metrics as m\\nfrom thundersvm import SVC as svmgpu\\nimport calculateWeightUsingGa2 as aresult\\nimport pandas as pd\\nimport itertools\\nimport random\\nfrom sklearn.ensemble import VotingClassifier\\nfrom sklearn.utils import shuffle\\nfrom sklearn.preprocessing import LabelEncoder\\nfrom sklearn.ensemble import VotingClassifier\\n\\nrandomseed = 42\\nnp.random.seed(randomseed)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics as m\n",
    "from thundersvm import SVC as svmgpu\n",
    "import calculateWeightUsingGa2 as aresult\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import random\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "randomseed = 42\n",
    "np.random.seed(randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read Dataset \n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"data = datasets.load_wine()\\nx = data.data\\ny = data.target\\n\\nprint(np.unique(y))\\n\\nxtrain, xtest, ytrain_original, ytest_original = train_test_split(\\n    x, y, test_size=0.3, random_state=10\\n)\\n\\nytrain = ytrain_original.copy()\\nytest = ytest_original.copy()\";\n",
       "                var nbb_formatted_code = \"data = datasets.load_wine()\\nx = data.data\\ny = data.target\\n\\nprint(np.unique(y))\\n\\nxtrain, xtest, ytrain_original, ytest_original = train_test_split(\\n    x, y, test_size=0.3, random_state=10\\n)\\n\\nytrain = ytrain_original.copy()\\nytest = ytest_original.copy()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = datasets.load_wine()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "print(np.unique(y))\n",
    "\n",
    "xtrain, xtest, ytrain_original, ytest_original = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=10\n",
    ")\n",
    "\n",
    "ytrain = ytrain_original.copy()\n",
    "ytest = ytest_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "************************** ==>  0\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.9453941120607787\n",
      "RF xgbc 0.9423280423280423\n",
      "[34, 21, 33, 9, 1, 13, 17, 5, 3, 20]\n",
      "0  ====================  [3 4 5 6]\n",
      "0.7757736091069425\n",
      "0.9423280423280423\n",
      "1  ====================  [1 2 3 5]\n",
      "0.7744539411206077\n",
      "0.9423280423280423\n",
      "2  ====================  [2 4 5 6]\n",
      "0.8867724867724868\n",
      "0.9423280423280423\n",
      "3  ====================  [0 1 5 6]\n",
      "0.8888888888888888\n",
      "0.9423280423280423\n",
      "4  ====================  [0 1 2 4]\n",
      "0.8907407407407406\n",
      "0.9423280423280423\n",
      "5  ====================  [0 2 4 5]\n",
      "1.0\n",
      "0.9423280423280423\n",
      "6  ====================  [0 3 4 6]\n",
      "0.8888888888888888\n",
      "0.9423280423280423\n",
      "7  ====================  [0 1 3 5]\n",
      "0.9453941120607787\n",
      "0.9423280423280423\n",
      "8  ====================  [0 1 2 6]\n",
      "0.8888888888888888\n",
      "0.9423280423280423\n",
      "9  ====================  [1 2 3 4]\n",
      "0.751388888888889\n",
      "0.9423280423280423\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.989298897972308 [0.96913138 0.96157576 0.61016313 0.43342966 0.61645653 0.26037585\n",
      " 0.73015698 0.45874249 0.73442723 0.56583021 0.82367583 0.60374113\n",
      " 0.84333984 0.99939421 0.86850791 0.58919452 0.86917851 0.96383738\n",
      " 0.88662926 0.59586345 0.88876269 0.2029396  0.96053744]\n",
      "f1_score 0.9423280423280423\n",
      "accuracy_score 0.9444444444444444\n",
      "************************** ==>  1\n",
      "original score 0.9441595441595442\n",
      "RF f1_score 0.9441595441595442\n",
      "RF svc 0.8867724867724868\n",
      "RF xgbc 1.0\n",
      "[28, 17, 25, 6, 28, 15, 20, 2, 8, 15]\n",
      "0  ====================  [1 3 5 6]\n",
      "0.9441595441595442\n",
      "1.0\n",
      "1  ====================  [0 3 4 6]\n",
      "1.0\n",
      "1.0\n",
      "2  ====================  [1 2 5 6]\n",
      "0.8324786324786325\n",
      "1.0\n",
      "3  ====================  [0 1 3 6]\n",
      "0.9441595441595442\n",
      "1.0\n",
      "4  ====================  [1 3 5 6]\n",
      "0.9441595441595442\n",
      "1.0\n",
      "5  ====================  [0 2 5 6]\n",
      "0.9441595441595442\n",
      "1.0\n",
      "6  ====================  [1 2 3 4]\n",
      "0.8773148148148148\n",
      "1.0\n",
      "7  ====================  [0 1 2 5]\n",
      "1.0\n",
      "1.0\n",
      "8  ====================  [0 1 4 6]\n",
      "1.0\n",
      "1.0\n",
      "9  ====================  [0 2 5 6]\n",
      "0.9441595441595442\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.879567183685335 [0.4016691  0.39300097 0.70699892 0.4266598  0.75755579 0.76532252\n",
      " 0.81887782 0.1816872  0.84291348 0.504585   0.84839324 0.55209421\n",
      " 0.87624609 0.67082802 0.89792723 0.29698628 0.92501051 0.93029767\n",
      " 0.94582994 0.96536614 0.97824973 0.67293999 0.99011956]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  2\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.9448329448329448\n",
      "RF xgbc 1.0\n",
      "[14, 16, 9, 17, 17, 18, 6, 22, 29, 31]\n",
      "0  ====================  [0 2 4 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "1  ====================  [0 3 4 5]\n",
      "0.8393162393162393\n",
      "1.0\n",
      "2  ====================  [0 1 5 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "3  ====================  [0 3 4 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "4  ====================  [0 3 4 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "5  ====================  [0 3 5 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "6  ====================  [0 1 3 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "7  ====================  [1 2 3 6]\n",
      "0.8847222222222223\n",
      "1.0\n",
      "8  ====================  [1 4 5 6]\n",
      "0.8847222222222223\n",
      "1.0\n",
      "9  ====================  [2 3 4 6]\n",
      "0.9448329448329448\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "16.270924863994356 [0.69971834 0.67842975 0.81865244 0.58730476 0.83031238 0.05957413\n",
      " 0.86566023 0.59716847 0.90196745 0.63668737 0.93074886 0.64888116\n",
      " 0.93159878 0.65231303 0.93436068 0.67564914 0.94755297 0.38885028\n",
      " 0.94804275 0.5192604  0.9810535  0.68603681 0.9872737 ]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  3\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.7802469135802469\n",
      "RF xgbc 1.0\n",
      "[5, 19, 33, 34, 11, 21, 7, 29, 17, 16]\n",
      "0  ====================  [0 1 3 5]\n",
      "0.8916022249355583\n",
      "1.0\n",
      "1  ====================  [0 4 5 6]\n",
      "0.9444444444444444\n",
      "1.0\n",
      "2  ====================  [2 4 5 6]\n",
      "0.8875661375661374\n",
      "1.0\n",
      "3  ====================  [3 4 5 6]\n",
      "0.8875661375661374\n",
      "1.0\n",
      "4  ====================  [0 2 3 5]\n",
      "0.8339743589743589\n",
      "1.0\n",
      "5  ====================  [1 2 3 5]\n",
      "0.7188552188552187\n",
      "1.0\n",
      "6  ====================  [0 1 4 5]\n",
      "0.8339743589743589\n",
      "1.0\n",
      "7  ====================  [1 4 5 6]\n",
      "0.8330095830095829\n",
      "1.0\n",
      "8  ====================  [0 3 4 6]\n",
      "0.9434947768281101\n",
      "1.0\n",
      "9  ====================  [0 3 4 5]\n",
      "0.7677045177045176\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.501104968602126 [0.74190089 0.40296966 0.87127599 0.63642382 0.88283513 0.64513584\n",
      " 0.90126329 0.5766024  0.91705661 0.6310785  0.9281217  0.48544407\n",
      " 0.9439929  0.33909406 0.94944527 0.55794722 0.9642398  0.4414485\n",
      " 0.97387926 0.63954265 0.98454767 0.3659121  0.98753018]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  4\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.8987891737891738\n",
      "RF xgbc 1.0\n",
      "[9, 2, 9, 15, 13, 11, 27, 25, 5, 26]\n",
      "0  ====================  [0 1 5 6]\n",
      "0.9444444444444444\n",
      "0.9444444444444444\n",
      "1  ====================  [0 1 2 5]\n",
      "0.8888888888888888\n",
      "0.9444444444444444\n",
      "2  ====================  [0 1 5 6]\n",
      "0.9444444444444444\n",
      "0.9444444444444444\n",
      "3  ====================  [0 2 5 6]\n",
      "0.8867724867724867\n",
      "0.9444444444444444\n",
      "4  ====================  [0 2 4 5]\n",
      "0.9405228758169935\n",
      "0.9444444444444444\n",
      "5  ====================  [0 2 3 5]\n",
      "0.891005291005291\n",
      "0.9444444444444444\n",
      "6  ====================  [1 3 4 6]\n",
      "0.9465608465608466\n",
      "0.9444444444444444\n",
      "7  ====================  [1 2 5 6]\n",
      "0.8250152625152626\n",
      "0.9444444444444444\n",
      "8  ====================  [0 1 3 5]\n",
      "0.891005291005291\n",
      "0.9444444444444444\n",
      "9  ====================  [1 3 4 5]\n",
      "0.7777777777777778\n",
      "0.9444444444444444\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.048686784683937 [0.99310969 0.6238107  0.99737016 0.66658498 0.69181302 0.39139806\n",
      " 0.70509331 0.80856621 0.82493605 0.32726603 0.82638878 0.66223604\n",
      " 0.83442759 0.48110218 0.85717313 0.9683874  0.89998408 0.2607237\n",
      " 0.91980723 0.55899113 0.92662586 0.21201426 0.94535726]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  5\n",
      "original score 0.9467787114845938\n",
      "RF f1_score 0.9467787114845938\n",
      "RF svc 0.8305681246857718\n",
      "RF xgbc 0.8880494505494506\n",
      "[11, 3, 27, 14, 31, 27, 20, 31, 5, 5]\n",
      "0  ====================  [0 2 3 5]\n",
      "0.7203654188948306\n",
      "0.8880494505494506\n",
      "1  ====================  [0 1 2 6]\n",
      "0.9467787114845938\n",
      "0.8880494505494506\n",
      "2  ====================  [1 3 4 6]\n",
      "0.8958333333333334\n",
      "0.8880494505494506\n",
      "3  ====================  [0 2 4 6]\n",
      "0.8323996265172736\n",
      "0.8880494505494506\n",
      "4  ====================  [2 3 4 6]\n",
      "0.8958333333333334\n",
      "0.8880494505494506\n",
      "5  ====================  [1 3 4 6]\n",
      "0.8958333333333334\n",
      "0.8880494505494506\n",
      "6  ====================  [1 2 3 4]\n",
      "0.7777777777777778\n",
      "0.8880494505494506\n",
      "7  ====================  [2 3 4 6]\n",
      "0.8958333333333334\n",
      "0.8880494505494506\n",
      "8  ====================  [0 1 3 5]\n",
      "0.7203654188948306\n",
      "0.8880494505494506\n",
      "9  ====================  [0 1 3 5]\n",
      "0.7203654188948306\n",
      "0.8880494505494506\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.128669986736305 [0.9920777  0.4230577  0.60711919 0.27063344 0.62017625 0.99770077\n",
      " 0.63114965 0.93924352 0.66442585 0.59909663 0.68018103 0.96195375\n",
      " 0.76231493 0.96729743 0.7623719  0.41807351 0.79303225 0.99018498\n",
      " 0.84511125 0.33236779 0.91065364 0.36523201 0.91664903]\n",
      "f1_score 0.8880494505494506\n",
      "accuracy_score 0.8888888888888888\n",
      "************************** ==>  6\n",
      "original score 0.944947209653092\n",
      "RF f1_score 0.944947209653092\n",
      "RF svc 0.8912231559290382\n",
      "RF xgbc 0.9467787114845938\n",
      "[31, 9, 19, 0, 25, 19, 2, 22, 24, 12]\n",
      "0  ====================  [2 3 4 6]\n",
      "1.0\n",
      "0.944947209653092\n",
      "1  ====================  [0 1 5 6]\n",
      "0.941025641025641\n",
      "0.944947209653092\n",
      "2  ====================  [0 4 5 6]\n",
      "0.941025641025641\n",
      "0.944947209653092\n",
      "3  ====================  [0 1 2 3]\n",
      "0.8893916540975364\n",
      "0.944947209653092\n",
      "4  ====================  [1 2 5 6]\n",
      "0.8297258297258296\n",
      "0.944947209653092\n",
      "5  ====================  [0 4 5 6]\n",
      "0.941025641025641\n",
      "0.944947209653092\n",
      "6  ====================  [0 1 2 5]\n",
      "0.941025641025641\n",
      "0.944947209653092\n",
      "7  ====================  [1 2 3 6]\n",
      "0.9458874458874457\n",
      "0.944947209653092\n",
      "8  ====================  [1 2 4 6]\n",
      "0.9458874458874457\n",
      "0.944947209653092\n",
      "9  ====================  [0 2 3 6]\n",
      "0.941025641025641\n",
      "0.944947209653092\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "15.899655659099233 [0.69788612 0.44753274 0.99324131 0.99853345 0.73118484 0.5546456\n",
      " 0.73230053 0.55789983 0.77135349 0.27283101 0.79376098 0.15658735\n",
      " 0.84427063 0.65776302 0.85002535 0.66531724 0.85853286 0.95891226\n",
      " 0.88075489 0.96906919 0.94486232 0.67784222 0.94507512]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  7\n",
      "original score 0.8858024691358024\n",
      "RF f1_score 0.8858024691358024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF svc 0.7764041514041514\n",
      "RF xgbc 0.9439416792357969\n",
      "[25, 30, 13, 32, 34, 32, 15, 33, 24, 5]\n",
      "0  ====================  [1 2 5 6]\n",
      "0.7716049382716048\n",
      "0.9439416792357969\n",
      "1  ====================  [2 3 4 5]\n",
      "0.7155067155067155\n",
      "0.9439416792357969\n",
      "2  ====================  [0 2 4 5]\n",
      "0.7197083961789844\n",
      "0.9439416792357969\n",
      "3  ====================  [2 3 5 6]\n",
      "0.7716049382716048\n",
      "0.9439416792357969\n",
      "4  ====================  [3 4 5 6]\n",
      "0.7504594820384294\n",
      "0.9439416792357969\n",
      "5  ====================  [2 3 5 6]\n",
      "0.7716049382716048\n",
      "0.9439416792357969\n",
      "6  ====================  [0 2 5 6]\n",
      "0.8858024691358024\n",
      "0.9439416792357969\n",
      "7  ====================  [2 4 5 6]\n",
      "0.7006573673240339\n",
      "0.9439416792357969\n",
      "8  ====================  [1 2 4 6]\n",
      "0.8207471540804874\n",
      "0.9439416792357969\n",
      "9  ====================  [0 1 3 5]\n",
      "0.8318250377073907\n",
      "0.9439416792357969\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.016246684568566 [0.79590722 0.51938461 0.8154823  0.4431039  0.83218438 0.36221602\n",
      " 0.83876147 0.41358797 0.85004488 0.45606299 0.85566811 0.43557475\n",
      " 0.87328975 0.4571509  0.93478469 0.81133477 0.94250917 0.31116387\n",
      " 0.97134817 0.60984102 0.98427061 0.70296441 0.99264614]\n",
      "f1_score 0.9439416792357969\n",
      "accuracy_score 0.9444444444444444\n",
      "************************** ==>  8\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.8836601307189542\n",
      "RF xgbc 1.0\n",
      "[32, 20, 13, 0, 34, 33, 29, 7, 9, 8]\n",
      "0  ====================  [2 3 5 6]\n",
      "0.9424836601307189\n",
      "1.0\n",
      "1  ====================  [1 2 3 4]\n",
      "0.9424836601307189\n",
      "1.0\n",
      "2  ====================  [0 2 4 5]\n",
      "0.9411764705882353\n",
      "1.0\n",
      "3  ====================  [0 1 2 3]\n",
      "0.8169934640522875\n",
      "1.0\n",
      "4  ====================  [3 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "5  ====================  [2 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "6  ====================  [1 4 5 6]\n",
      "1.0\n",
      "1.0\n",
      "7  ====================  [0 1 4 5]\n",
      "0.8836601307189542\n",
      "1.0\n",
      "8  ====================  [0 1 5 6]\n",
      "0.9424836601307189\n",
      "1.0\n",
      "9  ====================  [0 1 4 6]\n",
      "0.9424836601307189\n",
      "1.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "16.214047910618497 [0.67686067 0.35875856 0.70345387 0.55180258 0.74742173 0.55912185\n",
      " 0.76348627 0.51752314 0.77300424 0.27182278 0.78842358 0.82131174\n",
      " 0.82380395 0.87062025 0.88256887 0.88558889 0.97559844 0.45139855\n",
      " 0.98037232 0.65364164 0.98378813 0.66261674 0.99781052]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n",
      "************************** ==>  9\n",
      "original score 1.0\n",
      "RF f1_score 1.0\n",
      "RF svc 0.8823529411764706\n",
      "RF xgbc 1.0\n",
      "[13, 4, 3, 31, 16, 19, 29, 16, 1, 32]\n",
      "0  ====================  [0 2 4 5]\n",
      "1.0\n",
      "0.9438301636444052\n",
      "1  ====================  [0 1 3 4]\n",
      "0.9411764705882353\n",
      "0.9438301636444052\n",
      "2  ====================  [0 1 2 6]\n",
      "0.8123249299719888\n",
      "0.9438301636444052\n",
      "3  ====================  [2 3 4 6]\n",
      "0.7266615737203972\n",
      "0.9438301636444052\n",
      "4  ====================  [0 3 4 5]\n",
      "0.9428964568283454\n",
      "0.9438301636444052\n",
      "5  ====================  [0 4 5 6]\n",
      "0.8823529411764706\n",
      "0.9438301636444052\n",
      "6  ====================  [1 4 5 6]\n",
      "0.8123249299719888\n",
      "0.9438301636444052\n",
      "7  ====================  [0 3 4 5]\n",
      "0.9428964568283454\n",
      "0.9438301636444052\n",
      "8  ====================  [0 1 2 4]\n",
      "0.8913091552410438\n",
      "0.9438301636444052\n",
      "9  ====================  [2 3 5 6]\n",
      "0.6235294117647059\n",
      "0.9438301636444052\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "14.678824555319522 [0.97139997 0.46502732 0.97460311 0.97880498 0.74128975 0.60188167\n",
      " 0.76701277 0.31099177 0.83804785 0.31034488 0.84532804 0.6559258\n",
      " 0.85681589 0.47477621 0.871971   0.44352985 0.87753832 0.70844342\n",
      " 0.93802316 0.51126115 0.96012495 0.25272515 0.96785021]\n",
      "f1_score 1.0\n",
      "accuracy_score 1.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"original_scores = []\\ntrial1_scores = [] \\n\\nfrom sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(x)\\n\\nprint(kf)\\n\\ndata_cv = []\\n\\nfor train_index, test_index in kf.split(x):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    X_train, X_test = x[train_index], x[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    data_cv.append([[X_train, X_test], [y_train, y_test]])\\n\\n\\nfor i in range(len(data_cv)):\\n    print(\\\"************************** ==> \\\", i)\\n    \\n    xtrain = data_cv[i][0][0]\\n    ytrain_original = data_cv[i][1][0]    \\n    xtest = data_cv[i][0][1]\\n    ytest_original = data_cv[i][1][1]    \\n    \\n    ytrain=ytrain_original.copy()\\n    ytest=ytest_original.copy() \\n    \\n    # member values\\n    clf = []\\n    acc = []\\n    finalacc = []\\n    ypredproba_all = []\\n    ypredconfprob_all = []\\n    \\n    # orginal score using random forest classifier\\n    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain, ytrain)\\n    print(\\\"original score\\\", m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n    \\n    \\n    # generate three base classifers using RF,svm and XGBoost\\n\\n    #================================================= \\n\\n    rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain,ytrain)\\n    rfpred=rf.predict(xtest)\\n    print('RF f1_score',m.f1_score(ytest,rfpred,average='weighted'))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest,rfpred,average='weighted'))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat=m.confusion_matrix(ytest,rfpred)\\n    confsumh=np.sum(confmat,axis=1)\\n    propconfmat=confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \\n    ypredconfprob_all.append(propconfmat/100)\\n\\n    #=================================================\\n    svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\\n    svc.fit(xtrain,ytrain)\\n\\n    svcpred=svc.predict(xtest)\\n    print('RF svc',m.f1_score(ytest,svcpred,average='weighted'))\\n\\n    clf.append(svc)\\n    acc.append(m.f1_score(ytest,svcpred,average='weighted'))\\n    ypredproba_all.append(svc.predict_proba(xtest))\\n\\n    confmat=m.confusion_matrix(ytest,svcpred)\\n    confsumh=np.sum(confmat,axis=1)\\n    propconfmat=confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \\n    ypredconfprob_all.append(propconfmat/100)\\n\\n    #=================================================\\n    xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\\n    xgbc.fit(xtrain,ytrain)\\n\\n    xgbpred=xgbc.predict(xtest)\\n    print('RF xgbc',m.f1_score(ytest,xgbpred,average='weighted'))\\n\\n\\n    clf.append(xgbc)\\n    acc.append(m.f1_score(ytest,xgbpred,average='weighted'))\\n    ypredproba_all.append(xgbc.predict_proba(xtest))\\n\\n    confmat=m.confusion_matrix(ytest,xgbpred)\\n    confsumh=np.sum(confmat,axis=1)\\n    propconfmat=confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \\n    ypredconfprob_all.append(propconfmat/100)\\n\\n    # =================================================\\n    # =================================================\\n    # generate combinations of features 12,7\\n    comb = list(itertools.combinations(np.arange(0, 7, 1), 4))\\n\\n    # generate 10 random numbers\\n    randnums = []\\n    for i in range(10):\\n        randnums.append(random.randrange(0, len(comb)))\\n\\n    print(randnums)\\n\\n    comb = np.array(comb)[randnums, :]\\n\\n\\n    for i in range(len(comb)):\\n        print(i, \\\" ==================== \\\", comb[i])\\n\\n        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\\n        rf.fit(xtrain[:, comb[i]], ytrain)\\n        rfpred = rf.predict(xtest[:, comb[i]])\\n        print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n        clf.append(rf)\\n        acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\\n\\n        confmat = m.confusion_matrix(ytest, rfpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\\n        xgbmodel.fit(xtrain, ytrain)\\n        xgbmodelpred = xgbmodel.predict(xtest)\\n        print(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n\\n        clf.append(xgbmodel)\\n        acc.append(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(xgbmodel.predict_proba(xtest))\\n\\n        confmat = m.confusion_matrix(ytest, xgbmodelpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    # #=================================================\\n    #Compute the weight using ga and compute the ensemble accuracy\\n    import calculateWeightUsingGa2 as aresult\\n    weightvalga=aresult.getbestvalues(acc)\\n\\n    finalval=0\\n    for i in range(len(acc)):\\n        finalval += weightvalga[i]*ypredproba_all[i]\\n\\n    print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\\n    print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\\n    trial1_scores.append(m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\";\n",
       "                var nbb_formatted_code = \"original_scores = []\\ntrial1_scores = []\\n\\nfrom sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\\nkf.get_n_splits(x)\\n\\nprint(kf)\\n\\ndata_cv = []\\n\\nfor train_index, test_index in kf.split(x):\\n    # print(\\\"TRAIN:\\\", train_index, \\\"TEST:\\\", test_index)\\n    X_train, X_test = x[train_index], x[test_index]\\n    y_train, y_test = y[train_index], y[test_index]\\n    data_cv.append([[X_train, X_test], [y_train, y_test]])\\n\\n\\nfor i in range(len(data_cv)):\\n    print(\\\"************************** ==> \\\", i)\\n\\n    xtrain = data_cv[i][0][0]\\n    ytrain_original = data_cv[i][1][0]\\n    xtest = data_cv[i][0][1]\\n    ytest_original = data_cv[i][1][1]\\n\\n    ytrain = ytrain_original.copy()\\n    ytest = ytest_original.copy()\\n\\n    # member values\\n    clf = []\\n    acc = []\\n    finalacc = []\\n    ypredproba_all = []\\n    ypredconfprob_all = []\\n\\n    # orginal score using random forest classifier\\n    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain, ytrain)\\n    print(\\\"original score\\\", m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\\\"weighted\\\"))\\n\\n    # generate three base classifers using RF,svm and XGBoost\\n\\n    # =================================================\\n\\n    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\\n    rf.fit(xtrain, ytrain)\\n    rfpred = rf.predict(xtest)\\n    print(\\\"RF f1_score\\\", m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n    clf.append(rf)\\n    acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(rf.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, rfpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n    # =================================================\\n    svc = svmgpu(random_state=randomseed, probability=True, C=100, gamma=0.0001)\\n    svc.fit(xtrain, ytrain)\\n\\n    svcpred = svc.predict(xtest)\\n    print(\\\"RF svc\\\", m.f1_score(ytest, svcpred, average=\\\"weighted\\\"))\\n\\n    clf.append(svc)\\n    acc.append(m.f1_score(ytest, svcpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(svc.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, svcpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n    # =================================================\\n    xgbc = xgb.XGBClassifier(random_state=randomseed, n_estimators=100)\\n    xgbc.fit(xtrain, ytrain)\\n\\n    xgbpred = xgbc.predict(xtest)\\n    print(\\\"RF xgbc\\\", m.f1_score(ytest, xgbpred, average=\\\"weighted\\\"))\\n\\n    clf.append(xgbc)\\n    acc.append(m.f1_score(ytest, xgbpred, average=\\\"weighted\\\"))\\n    ypredproba_all.append(xgbc.predict_proba(xtest))\\n\\n    confmat = m.confusion_matrix(ytest, xgbpred)\\n    confsumh = np.sum(confmat, axis=1)\\n    propconfmat = confmat.copy()\\n    for i in range(propconfmat.shape[0]):\\n        propconfmat[i] = 100 * propconfmat[i] / confsumh[i]\\n    ypredconfprob_all.append(propconfmat / 100)\\n\\n    # =================================================\\n    # =================================================\\n    # generate combinations of features 12,7\\n    comb = list(itertools.combinations(np.arange(0, 7, 1), 4))\\n\\n    # generate 10 random numbers\\n    randnums = []\\n    for i in range(10):\\n        randnums.append(random.randrange(0, len(comb)))\\n\\n    print(randnums)\\n\\n    comb = np.array(comb)[randnums, :]\\n\\n    for i in range(len(comb)):\\n        print(i, \\\" ==================== \\\", comb[i])\\n\\n        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\\n        rf.fit(xtrain[:, comb[i]], ytrain)\\n        rfpred = rf.predict(xtest[:, comb[i]])\\n        print(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n\\n        clf.append(rf)\\n        acc.append(m.f1_score(ytest, rfpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\\n\\n        confmat = m.confusion_matrix(ytest, rfpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\\n        xgbmodel.fit(xtrain, ytrain)\\n        xgbmodelpred = xgbmodel.predict(xtest)\\n        print(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n\\n        clf.append(xgbmodel)\\n        acc.append(m.f1_score(ytest, xgbmodelpred, average=\\\"weighted\\\"))\\n        ypredproba_all.append(xgbmodel.predict_proba(xtest))\\n\\n        confmat = m.confusion_matrix(ytest, xgbmodelpred)\\n        confsumh = np.sum(confmat, axis=0)\\n        propconfmat = confmat.copy()\\n        for i in range(propconfmat.shape[0]):\\n            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\\n        ypredconfprob_all.append(propconfmat / 100)\\n\\n    # #=================================================\\n    # Compute the weight using ga and compute the ensemble accuracy\\n    import calculateWeightUsingGa2 as aresult\\n\\n    weightvalga = aresult.getbestvalues(acc)\\n\\n    finalval = 0\\n    for i in range(len(acc)):\\n        finalval += weightvalga[i] * ypredproba_all[i]\\n\\n    print(\\n        \\\"f1_score\\\", m.f1_score(ytest, np.argmax(finalval, axis=1), average=\\\"weighted\\\")\\n    )\\n    print(\\\"accuracy_score\\\", m.accuracy_score(ytest, np.argmax(finalval, axis=1)))\\n    trial1_scores.append(\\n        m.f1_score(ytest, np.argmax(finalval, axis=1), average=\\\"weighted\\\")\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_scores = []\n",
    "trial1_scores = [] \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=randomseed, shuffle=True)\n",
    "kf.get_n_splits(x)\n",
    "\n",
    "print(kf)\n",
    "\n",
    "data_cv = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    data_cv.append([[X_train, X_test], [y_train, y_test]])\n",
    "\n",
    "\n",
    "for i in range(len(data_cv)):\n",
    "    print(\"************************** ==> \", i)\n",
    "    \n",
    "    xtrain = data_cv[i][0][0]\n",
    "    ytrain_original = data_cv[i][1][0]    \n",
    "    xtest = data_cv[i][0][1]\n",
    "    ytest_original = data_cv[i][1][1]    \n",
    "    \n",
    "    ytrain=ytrain_original.copy()\n",
    "    ytest=ytest_original.copy() \n",
    "    \n",
    "    # member values\n",
    "    clf = []\n",
    "    acc = []\n",
    "    finalacc = []\n",
    "    ypredproba_all = []\n",
    "    ypredconfprob_all = []\n",
    "    \n",
    "    # orginal score using random forest classifier\n",
    "    rf = RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    print(\"original score\", m.f1_score(ytest, rf.predict(xtest), average=\"weighted\"))\n",
    "    original_scores.append(m.f1_score(ytest, rf.predict(xtest), average=\"weighted\"))\n",
    "    \n",
    "    \n",
    "    # generate three base classifers using RF,svm and XGBoost\n",
    "\n",
    "    #================================================= \n",
    "\n",
    "    rf=RandomForestClassifier(random_state=randomseed, n_estimators=10)\n",
    "    rf.fit(xtrain,ytrain)\n",
    "    rfpred=rf.predict(xtest)\n",
    "    print('RF f1_score',m.f1_score(ytest,rfpred,average='weighted'))\n",
    "\n",
    "    clf.append(rf)\n",
    "    acc.append(m.f1_score(ytest,rfpred,average='weighted'))\n",
    "    ypredproba_all.append(rf.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,rfpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    #=================================================\n",
    "    svc=svmgpu(random_state=randomseed,probability=True,C=100,gamma=0.0001)\n",
    "    svc.fit(xtrain,ytrain)\n",
    "\n",
    "    svcpred=svc.predict(xtest)\n",
    "    print('RF svc',m.f1_score(ytest,svcpred,average='weighted'))\n",
    "\n",
    "    clf.append(svc)\n",
    "    acc.append(m.f1_score(ytest,svcpred,average='weighted'))\n",
    "    ypredproba_all.append(svc.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,svcpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    #=================================================\n",
    "    xgbc=xgb.XGBClassifier(random_state=randomseed,n_estimators=100)\n",
    "    xgbc.fit(xtrain,ytrain)\n",
    "\n",
    "    xgbpred=xgbc.predict(xtest)\n",
    "    print('RF xgbc',m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "\n",
    "\n",
    "    clf.append(xgbc)\n",
    "    acc.append(m.f1_score(ytest,xgbpred,average='weighted'))\n",
    "    ypredproba_all.append(xgbc.predict_proba(xtest))\n",
    "\n",
    "    confmat=m.confusion_matrix(ytest,xgbpred)\n",
    "    confsumh=np.sum(confmat,axis=1)\n",
    "    propconfmat=confmat.copy()\n",
    "    for i in range(propconfmat.shape[0]):\n",
    "        propconfmat[i]= 100*propconfmat[i]/confsumh[i] \n",
    "    ypredconfprob_all.append(propconfmat/100)\n",
    "\n",
    "    # =================================================\n",
    "    # =================================================\n",
    "    # generate combinations of features 12,7\n",
    "    comb = list(itertools.combinations(np.arange(0, 7, 1), 4))\n",
    "\n",
    "    # generate 10 random numbers\n",
    "    randnums = []\n",
    "    for i in range(10):\n",
    "        randnums.append(random.randrange(0, len(comb)))\n",
    "\n",
    "    print(randnums)\n",
    "\n",
    "    comb = np.array(comb)[randnums, :]\n",
    "\n",
    "\n",
    "    for i in range(len(comb)):\n",
    "        print(i, \" ==================== \", comb[i])\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=randomseed, n_estimators=50)\n",
    "        rf.fit(xtrain[:, comb[i]], ytrain)\n",
    "        rfpred = rf.predict(xtest[:, comb[i]])\n",
    "        print(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(rf)\n",
    "        acc.append(m.f1_score(ytest, rfpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(rf.predict_proba(xtest[:, comb[i]]))\n",
    "\n",
    "        confmat = m.confusion_matrix(ytest, rfpred)\n",
    "        confsumh = np.sum(confmat, axis=0)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "        xgbmodel = xgb.XGBClassifier(random_state=randomseed, n_estimators=50)\n",
    "        xgbmodel.fit(xtrain, ytrain)\n",
    "        xgbmodelpred = xgbmodel.predict(xtest)\n",
    "        print(m.f1_score(ytest, xgbmodelpred, average=\"weighted\"))\n",
    "\n",
    "        clf.append(xgbmodel)\n",
    "        acc.append(m.f1_score(ytest, xgbmodelpred, average=\"weighted\"))\n",
    "        ypredproba_all.append(xgbmodel.predict_proba(xtest))\n",
    "\n",
    "        confmat = m.confusion_matrix(ytest, xgbmodelpred)\n",
    "        confsumh = np.sum(confmat, axis=0)\n",
    "        propconfmat = confmat.copy()\n",
    "        for i in range(propconfmat.shape[0]):\n",
    "            propconfmat[:, i] = 100 * propconfmat[:, i] / confsumh[i]\n",
    "        ypredconfprob_all.append(propconfmat / 100)\n",
    "\n",
    "    # #=================================================\n",
    "    #Compute the weight using ga and compute the ensemble accuracy\n",
    "    import calculateWeightUsingGa2 as aresult\n",
    "    weightvalga=aresult.getbestvalues(acc)\n",
    "\n",
    "    finalval=0\n",
    "    for i in range(len(acc)):\n",
    "        finalval += weightvalga[i]*ypredproba_all[i]\n",
    "\n",
    "    print('f1_score',m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "    print('accuracy_score',m.accuracy_score(ytest,np.argmax(finalval,axis=1)))\n",
    "    trial1_scores.append(m.f1_score(ytest,np.argmax(finalval,axis=1),average='weighted'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original socre  0.9721687934433032  std  0.03778463610537326\n",
      "ga socre  0.977431917211329  std  0.03729387609693471\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"print(\\\"original socre \\\", np.mean(original_scores), \\\" std \\\", np.std(original_scores))\\nprint(\\\"ga socre \\\", np.mean(trial1_scores), \\\" std \\\", np.std(trial1_scores))\";\n",
       "                var nbb_formatted_code = \"print(\\\"original socre \\\", np.mean(original_scores), \\\" std \\\", np.std(original_scores))\\nprint(\\\"ga socre \\\", np.mean(trial1_scores), \\\" std \\\", np.std(trial1_scores))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original socre \", np.mean(original_scores), \" std \", np.std(original_scores))\n",
    "print(\"ga socre \", np.mean(trial1_scores), \" std \", np.std(trial1_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. voting classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"ensemb_clf = []\\nfor i in range(len(clf)):\\n    ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\\n\\neclf3 = VotingClassifier(estimators=ensemb_clf, voting=\\\"soft\\\", flatten_transform=True)\\n\\nfrom sklearn.model_selection import cross_val_score\\ncorssvals=cross_val_score(eclf3, x, y, cv=10)\";\n",
       "                var nbb_formatted_code = \"ensemb_clf = []\\nfor i in range(len(clf)):\\n    ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\\n\\neclf3 = VotingClassifier(estimators=ensemb_clf, voting=\\\"soft\\\", flatten_transform=True)\\n\\nfrom sklearn.model_selection import cross_val_score\\n\\ncorssvals = cross_val_score(eclf3, x, y, cv=10)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ensemb_clf = []\n",
    "for i in range(len(clf)):\n",
    "    ensemb_clf.append([str(type(clf[i])) + str(i), clf[i]])\n",
    "\n",
    "eclf3 = VotingClassifier(estimators=ensemb_clf, voting=\"soft\", flatten_transform=True)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "corssvals=cross_val_score(eclf3, x, y, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corssvals  0.9666666666666666  std  0.036851386559504457\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"print(\\\"corssvals \\\", np.mean(corssvals), \\\" std \\\", np.std(corssvals))\";\n",
       "                var nbb_formatted_code = \"print(\\\"corssvals \\\", np.mean(corssvals), \\\" std \\\", np.std(corssvals))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"corssvals \", np.mean(corssvals), \" std \", np.std(corssvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
